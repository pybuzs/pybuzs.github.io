<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Java并发面试题</title>
    <url>/2025/07/09/Interview/Java%E5%B9%B6%E5%8F%91%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[Java 并发面试题基础什么是 java 中的线程安全查看答案在 Java 中，线程安全是指一个类或对象在多线程环境下能够正确执行，不会出现数据不一致或其他异常。其核心在于处理共享可变状态的访问。


说说线程的几种创建方式查看答案
继承Thread类：

重写 run() 方法。

创建子类对象并调用 start() 方法启动线程。



实现Runnable接口

实现 run() 方法。

将实现类对象作为参数传递给 Thread 构造器，调用 start() 启动线程。



实现 Callable 接口 + FutureTask

实现 Callable&lt;V&gt; 接口，指定返回值类型。
实现 call() 方法，该方法有返回值。
使用 FutureTask&lt;V&gt; 包装 Callable 对象。
将 FutureTask 对象作为参数传递给 Thread 构造器，调用 start() 启动线程。
通过 FutureTask.get() 获取线程执行结果（可能阻塞）。


使用线程池（ExecutorService）

创建线程池（如 Executors.newFixedThreadPool()）。
提交 Runnable 或 Callable 任务到线程池。
通过 Future 获取任务结果（若有）。
关闭线程池。





线程的生命周期查看答案Java 线程的生命周期分为 6 种状态，由 Thread.State 枚举定义：



状态名称
说明



NEW（新建）
线程对象已创建，但未调用 start() 方法（未启动）。


RUNNABLE（可运行）
线程已调用 start() 方法，正在 JVM 中运行，或等待 CPU 调度（包含 “就绪” 和 “运行中” 两种情况）。


BLOCKED（阻塞）
线程因竞争 对象锁 而阻塞（如进入 synchronized 块 &#x2F; 方法时未获取到锁）。


WAITING（无限等待）
线程无超时地等待其他线程的特定操作（如 wait()、join() 等）。


TIMED_WAITING（超时等待）
线程有超时时间地等待（如 sleep(1000)、wait(1000) 等，超时后自动唤醒）。


TERMINATED（终止）
线程执行完毕（run() 方法结束）或因异常退出。




什么是线程上下文切换查看答案线程上下文切换是操作系统实现多线程并发的基础，通过保存和恢复线程状态，让 CPU 能在多个线程间快速切换。但它存在固有开销，合理控制线程数量、减少不必要的阻塞（如避免频繁 I&#x2F;O、优化锁竞争）是降低切换开销、提升并发性能的关键。


线程间有哪些通讯方式查看答案在Java中，线程之间的通讯就是指多个线程协同工作。
线程之间传递信息的方式有多种，比如说使用 volatile 和 synchronized 关键字共享对象、使用 wait() 和 notify() 方法实现生产者-消费者模式、使用 Exchanger 进行数据交换、使用 Condition 实现线程间的协调等。


说说 sleep 和 wait 的区别查看答案


维度
sleep()
wait()



所属类
Thread.sleep()（静态方法）
Object.wait()（实例方法）


释放锁
❌ 不释放持有的锁
✅ 释放持有的对象锁（需在synchronized中调用）


唤醒方式
时间到期自动唤醒，或被interrupt()中断
需其他线程调用notify()&#x2F;notifyAll()唤醒


使用场景
单纯暂停线程执行（如模拟耗时操作）
线程间协作（如生产者 - 消费者模型中的条件等待）


调用位置
可在任何代码中调用
必须在synchronized块 &#x2F; 方法中调用




ThreadLocalThreadLocal 是什么？查看答案ThreadLocal 是多线程编程中的一个特殊工具，用于为每个使用它的线程都独立存储一份数据副本。每个线程都可以独立地修改自己的副本，而不会影响其他线程的数据，从而实现线程间的数据隔离。


说说对 ThreadLocal  的理解查看答案
每个 Thread 对象内部持有 ThreadLocalMap （哈希表结构）成员变量（threadLocals）。
ThreadLocalMap 是 ThreadLocal 的一个静态内部类，它内部维护了一个Entry数组，Entry 继承了 WeakReference。
Key 为 ThreadLocal 实例（弱引用），Value 为线程变量副本（强引用）。
数据访问：
调用 threadLocal.set(value) 时，以当前 ThreadLocal 实例为 Key，存入当前线程的 ThreadLocalMap。
调用 threadLocal.get() 时，从当前线程的 Map 中通过 Key 取出 Value。


哈希优化：Key 的哈希值由黄金分割数 0x61c88647 生成，减少哈希冲突。
冲突解决：采用 开放定址法（线性探测），而非链表。



说说  ThreadLocal   的内存泄漏问题查看答案
原因：Entry 的 Key（ThreadLocal）是弱引用，但 Value 是强引用。如果 ThreadLocal 实例不再被任何强引用指向，垃圾回收器会在下次 GC 时回收该实例，导致 ThreadLocalMap 中对应的 key 变为 null，但 Value 仍被线程强引用。
后果：若线程长期运行（如线程池场景）， Value 无法回收，会导致内存泄漏。
解决方案：
每次使用后 **必须调用 remove()**（在 finally 块中）；
将 ThreadLocal 声明为 static final，避免实例被回收。”





如何跨线程传递 ThreadLocal 的值？查看答案 ThreadLocal 无法直接跨线程传递值，因为 ThreadLocal 变量存储在每个线程的 ThreadLocalMap 中。
我们可以使用 InheritableThreadLocal来解决这个问题。
InheritableThreadLocal：

是 ThreadLocal 的子类，专门用于在父子线程间传递值。当子线程被创建时，会自动复制父线程中 InheritableThreadLocal 的值。
public class InheritableThreadLocalDemo &#123;    private static final InheritableThreadLocal&lt;String&gt; context = new InheritableThreadLocal&lt;&gt;();    public static void main(String[] args) &#123;        // 在主线程中设置值        context.set(&quot;主线程数据&quot;);        // 创建子线程        Thread childThread = new Thread(() -&gt; &#123;            // 子线程可以获取到父线程设置的值            System.out.println(&quot;子线程获取值: &quot; + context.get()); // 输出: 主线程数据        &#125;);        childThread.start();    &#125;&#125;

局限性
仅适用于直接创建的子线程：如果使用线程池（如 ExecutorService），由于线程是复用的，无法自动复制 InheritableThreadLocal 的值。
值复制是单向的：子线程无法修改父线程中的值，反之亦然。





Java内存模型说说对Java内存模型的理解查看答案Java 内存模型（Java Memory Model, JMM）是一种抽象规范，用于定义多线程环境下变量的访问规则，解决以下问题：

内存可见性：确保一个线程对共享变量的修改能及时被其他线程看到。
指令重排序：编译器和 CPU 会对指令重排序优化，导致代码执行顺序与编写顺序不一致。
原子性：简单的读写操作（如 i++）在底层可能被拆分为多条指令，多线程同时执行时导致结果错误。



什么是Java中的原子性、可见性和有序性？查看答案
原子性（Atomicity）：保证操作不被中断（要么全执行，要么全不执行），对应解决 “操作被拆分导致的数据不一致” 问题，由synchronized、原子类等保证。
可见性（Visibility）：保证变量修改被其他线程及时看到，对应解决 “工作内存与主内存同步延迟” 问题，由volatile、synchronized等保证。
有序性（Ordering）：保证指令执行顺序符合逻辑，对应解决 “指令重排序导致的多线程逻辑错误” 问题，由volatile、Happens-Before 规则等保证。



i++是原子操作吗?查看答案
i++ 看似是一个简单的操作，但实际上包含三个独立的步骤：

读取变量值：从主内存或缓存中读取 i 的当前值。
执行加 1 操作：在 CPU 中对读取的值进行加 1 计算。
写回新值：将计算结果写回主内存或缓存。

这三个步骤不是一个不可分割的整体，在多线程环境下可能被其他线程打断。

多线程下会出现错误
假设有两个线程同时执行 i++，初始值 i = 0，期望结果：两个线程执行后，i应该为2。但可能的执行顺序如下：

线程 A 读取 i 的值为 0。
线程 B 读取 i 的值为 0（此时线程 A 还未写入新值）。
线程 A 执行加 1 操作，得到结果 1。
线程 B 执行加 1 操作，得到结果 1（因为 B 读取的是旧值 0）。
线程 A 将结果 1 写回主内存。
线程 B 将结果 1 写回主内存。

最终结果：i 的值为 1，而不是预期的 2。

解决方案
使用原子类（推荐）private AtomicInteger count = new AtomicInteger(0);public void increment() &#123;    count.incrementAndGet(); // 原子操作&#125;


原理：通过 CPU 的 CAS（Compare-And-Swap） 指令实现原子性。


加锁（synchronized&#x2F;Lock）public synchronized void increment() &#123;    count++;&#125;


性能可能会降低，牺牲性能换取安全。


volatile 无法解决此类问题（仅解决可见性，不解决原子性）






说说什么是指令重排查看答案指令重排（Instruction Reordering） 是计算机系统中为提升执行效率而对指令执行顺序进行优化的技术。

为什么会发生指令重排？
指令重排的核心目的是提高程序运行效率。

编译器优化：Java 的 JIT（即时编译器）在编译字节码为机器码时，可能会调整指令顺序，比如将没有依赖关系的指令重新排序，减少 CPU 的等待时间。
处理器优化：现代 CPU 支持 “乱序执行”（Out-of-Order Execution），如果前一条指令需要等待内存读写（耗时操作），CPU 会先执行后面没有依赖关系的指令，充分利用 CPU 资源。


多线程下的问题：重排导致逻辑错误
多线程环境中，指令重排可能打破线程间的逻辑依赖，导致错误。因为重排只保证单线程结果正确，不考虑多线程间的交互。
最经典的例子是双重检查锁定（DCL）的单例模式。
public class Singleton &#123;    private static Singleton instance; // 未用volatile    public static Singleton getInstance() &#123;        if (instance == null) &#123; // 第一次检查            synchronized (Singleton.class) &#123;                if (instance == null) &#123; // 第二次检查                    instance = new Singleton(); // 可能被重排序                &#125;            &#125;        &#125;        return instance;    &#125;&#125;

instance = new Singleton()可拆分为三步：

分配内存空间（memory &#x3D; allocate ()）
初始化对象（ctorInstance (memory)）
把 instance 指向内存空间（instance &#x3D; memory）

编译器可能重排序为 1→3→2。若线程 A 执行到 3（未执行 2）时，线程 B 进入第一次检查，发现instance != null，直接返回未初始化的对象，导致错误。给 instance 变量加上 volatile 关键字，可以禁止指令重排。
private static volatile Singleton instance; // 使用volatile

如何禁止指令重排?

volatile关键字：通过插入内存屏障（禁止特定类型的重排序）阻止指令重排序。例如，对volatile变量的写操作前插入 StoreStore 屏障，写操作后插入 StoreLoad 屏障，避免其前后的指令被重排序。
**synchronized&#x2F;Lock**：同一时间只有一个线程执行同步代码块，天然保证了代码块内的指令按顺序执行。
happens-before 规则：JMM 定义的一套有序性规则，例如 “程序顺序规则”（单线程内指令按代码顺序执行）、“volatile 规则”（volatile 写先行发生于 volatile 读）、“锁规则”（解锁先行发生于加锁）等，通过这些规则保证多线程环境下的有序性。





as-if-serial了解吗查看答案单线程环境中，指令重排不会影响程序的最终结果，这是因为编译器和处理器遵循as-if-serial 语义—— 即 “不管怎么重排，单线程程序的执行结果都要和按代码顺序执行的结果一致”。
举个栗子：
int a = 1;    // 指令1int b = 2;    // 指令2int c = a + b; // 指令3

指令 1 和指令 2 没有依赖关系（互不影响结果），编译器可能先执行指令 2 再执行指令 1，但指令 3 必须在 1 和 2 之后（依赖它们的结果），因此最终c的结果一定是 3，单线程下完全没问题。


说说对volatile的理解查看答案volatile 是 Java 中用于修饰变量的关键字，是一种轻量级的同步机制，主要用于解决多线程环境下变量的可见性和有序性问题，但不保证原子性。它的设计目标是提供比 synchronized 更低开销的同步方案，适用于特定场景。
volatile 的核心作用

保证可见性
可见性指：当一个线程修改了 volatile 变量的值后，其他线程能立即看到该变量的最新值。

原理：未被 volatile 修饰的变量，线程会从 “工作内存”（CPU 缓存）读取和修改，修改后不会立即同步到 “主内存”；其他线程可能一直使用旧的工作内存值，导致数据不一致。而 volatile 变量的读写会强制通过 “主内存” 进行：
写操作：线程修改 volatile 变量后，会立即将新值刷新到主内存。
读操作：线程读取 volatile 变量时，会先清空工作内存，再从主内存重新加载最新值。




禁止指令重排
指令重排是编译器或 CPU 为优化性能，对代码执行顺序的调整（不影响单线程结果，但可能破坏多线程正确性）。volatile 通过内存屏障（Memory Barrier）禁止指令重排，保证代码执行顺序与预期一致。

原理：JVM 会在 volatile 变量的读写操作前后插入内存屏障，限制重排范围：
禁止 volatile 变量写操作前的代码被重排到写操作之后；
禁止 volatile 变量读操作后的代码被重排到读操作之前。


典型场景：单例模式的双重检查锁


不保证原子性
volatile 无法保证复合操作的原子性（即多线程下的 “读 - 改 - 写” 步骤可能被打断）。


volatile 的实现原理：内存屏障
JVM 通过插入内存屏障（特殊指令）保证 volatile 的可见性和有序性：

StoreStore 屏障：在 volatile 写操作前插入，确保之前的普通写操作已刷新到主内存。
StoreLoad 屏障：在 volatile 写操作后插入，防止写操作与后续的读操作重排。
LoadLoad 屏障：在 volatile 读操作后插入，防止后续读操作与该读操作重排。
LoadStore 屏障：在 volatile 读操作后插入，防止后续写操作与该读操作重排。

这些屏障强制 CPU 缓存与主内存同步，禁止指令重排，从而保证可见性和有序性。


volatile 与 synchronized 的区别查看答案


特性
volatile
synchronized



原子性
不保证（仅可见性 &#x2F; 有序性）
保证（同步块内操作原子）


可见性
保证
保证（解锁时刷新主内存）


有序性
保证（禁止重排）
保证（同步块内顺序执行）


开销
轻量（无锁）
较重（可能阻塞线程）


适用场景
状态标记、禁止重排
复杂同步逻辑（需原子性）




说说happens-before 规则查看答案在 Java 内存模型（JMM）中，Happens-Before 规则是一组用于确定跨线程操作之间可见性的核心规则。它定义了 前一个操作的结果对后一个操作可见 的条件，是 JMM 保证多线程有序性和可见性的基础。
Happens-Before 的核心规则

程序顺序规则（Program Order Rule）
单线程内，每个操作Happens-Before后续的所有操作。
int a = 1;  // 操作1int b = 2;  // 操作2int sum = a + b;  // 操作3

单线程下，操作 1 Happens-Before 操作 2，操作 2 Happens-Before 操作 3。但编译器可能重排操作 1 和 2 的顺序（只要不影响最终结果），因此多线程下不能依赖此规则。

监视器锁规则（Monitor Lock Rule）
对一个锁的解锁操作 Happens-Before 后续对同一锁的加锁操作。
public class MonitorExample &#123;    private int x = 0;    public void writer() &#123;        synchronized (this) &#123;  // 加锁            x = 1;  // 操作1        &#125;  // 解锁    &#125;  // 操作1 Happens-Before 后续其他线程的加锁    public void reader() &#123;        synchronized (this) &#123;  // 加锁（必须等待前面的解锁）            int y = x;  // 操作2        &#125;  // 解锁    &#125;&#125;

线程 A 解锁后，线程 B 加锁时能看到 A 对 x 的修改（x&#x3D;1）。

volatile 变量规则（Volatile Variable Rule）
对一个volatile变量的写操作 Happens-Before 后续对同一变量的读操作。
private volatile boolean flag = false;// 线程Apublic void writer() &#123;    flag = true;  // 写操作&#125;  // 写操作Happens-Before 线程B的读操作// 线程Bpublic void reader() &#123;    while (!flag) &#123;  // 读操作（保证看到最新值）        // 循环等待    &#125;&#125;

volatile通过内存屏障禁止重排，确保写操作的结果对读操作可见。

线程启动规则（Thread Start Rule）
线程的start()方法 Happens-Before 此线程的任意操作。
Thread t = new Thread(() -&gt; &#123;    // 线程t的操作    System.out.println(&quot;线程t启动&quot;);  // 操作1&#125;);t.start();  // 主线程调用start()// start() Happens-Before 操作1

主线程调用start()后，线程 t 的操作能看到主线程在start()前的所有修改。

线程终止规则（Thread Termination Rule）
线程的所有操作 Happens-Before 其他线程检测到该线程已终止（如通过Thread.join()返回、Thread.isAlive()返回false）。
Thread t = new Thread(() -&gt; &#123;    // 线程t的操作    System.out.println(&quot;线程t即将结束&quot;);  // 操作1&#125;);t.start();t.join();  // 主线程等待t终止// 操作1 Happens-Before t.join()返回System.out.println(&quot;线程t已结束&quot;);

主线程能看到线程 t 的所有操作结果。

中断规则（Interruption Rule）
线程 A 调用threadB.interrupt() Happens-Before 线程 B 检测到中断（如通过Thread.interrupted()或Thread.isInterrupted()）。
Thread t = new Thread(() -&gt; &#123;    while (!Thread.currentThread().isInterrupted()) &#123;        // 循环    &#125;    System.out.println(&quot;线程t被中断&quot;);  // 操作1&#125;);t.start();t.interrupt();  // 主线程中断t// interrupt() Happens-Before 操作1

线程 t 能看到主线程调用interrupt()的结果。

对象终结规则（Finalizer Rule）
对象的初始化完成（构造函数执行结束） Happens-Before 它的finalize()方法开始。
public class Resource &#123;    public Resource() &#123;        // 初始化操作        System.out.println(&quot;Resource初始化完成&quot;);  // 操作1    &#125;    @Override    protected void finalize() throws Throwable &#123;        // 对象销毁前的清理        System.out.println(&quot;Resource finalize()开始&quot;);  // 操作2    &#125;&#125;// 操作1 Happens-Before 操作2

确保对象初始化完成后才会执行finalize()。

传递性规则 (Transitivity)
如果操作 A Happens-Before 操作 B，操作 B Happens-Before 操作 C，则操作 A Happens-Before 操作 C。
// 线程Apublic void writer() &#123;    a = 1;         // 操作1    flag = true;   // 操作2（volatile写）&#125;// 线程Bpublic void reader() &#123;    while (!flag) &#123; // 操作3（volatile读）        // 循环    &#125;    int b = a;     // 操作4&#125;

根据规则：

操作 1 Happens-Before 操作 2（程序顺序规则）。
操作 2 Happens-Before 操作 3（volatile 变量规则）。
操作 3 Happens-Before 操作 4（程序顺序规则）。通过传递性，操作 1 Happens-Before 操作 4，因此线程 B 能看到线程 A 对a的修改（a=1）。





锁什么是乐观锁和悲观锁查看答案在并发编程中，乐观锁和悲观锁是两种不同的锁策略，用于解决多线程环境下对共享资源的访问冲突。它们的核心区别在于对数据冲突的预期态度和处理方式。



特性
悲观锁
乐观锁



核心假设
假设冲突概率高
假设冲突概率低


加锁时机
先加锁，再操作
先操作，后验证


实现方式
synchronized、ReentrantLock、数据库行锁（SELECT … FOR UPDATE）
CAS、版本号机制


性能
写操作多时性能较差（锁竞争开销大）
读操作多时性能较好（无锁开销）


冲突处理
线程阻塞等待
重试或放弃操作


典型场景
库存扣减、金融交易
缓存更新、统计数据




什么是Java的CAS?查看答案在 Java 里，CAS即Compare-And-Swap（比较并交换），它是一种无锁的原子操作，作用是实现多线程环境下的变量同步。CAS操作主要依赖于底层硬件（像 CPU 指令）来保证操作的原子性，避免了使用传统锁（例如synchronized）带来的线程阻塞和上下文切换开销。
CAS 操作包含三个参数：

V：要更新的变量(var)
E：预期值(expected)
N：新值(new)

如果变量 V 的值等于 E ,则将 V 的值变为 N；如果不相等则说明有其他线程在操作，放弃更新。整个过程由 CPU 保证原子性。
Java 中的实现
Java 通过Unsafe类和java.util.concurrent.atomic包提供 CAS 支持。

① Unsafe类（底层实现）
Unsafe类提供了硬件级别的原子操作，例如：
public final native boolean compareAndSwapInt(Object o, long offset, int expected, int x);


o：需要修改的对象。
offset：对象中变量的内存偏移量。
expected：预期值。
x：新值。


② 原子类（Atomic Classes）
基于Unsafe封装的原子类，如AtomicInteger、AtomicLong等：
import java.util.concurrent.atomic.AtomicInteger;public class CASDemo &#123;    private static AtomicInteger counter = new AtomicInteger(0);    public static void increment() &#123;        // 自增操作 = getAndAdd(1) = CAS循环        counter.incrementAndGet();    &#125;&#125;

优点：

无锁性能：避免了线程阻塞和上下文切换，在竞争不激烈时性能远高于synchronized。
原子性保障：硬件级别的原子操作，无需依赖操作系统的锁机制。



CAS会有什么问题查看答案
ABA 问题
若变量 V 的值从 A 变为 B，再变回 A，CAS 会认为值未变化，但实际已被修改。解决方法：使用AtomicStampedReference（带版本号的原子引用）。他加入了预期标志和更新后标志两个字段，更新时不光检查值，还要检查当前的标志是否等于预期标志，全部相等的话才会更新。

自旋开销
竞争激烈时，线程频繁重试 CAS 会消耗大量 CPU 资源。解决方法：限制重试次数或使用锁（如ReentrantLock）。

只能保证单个变量的原子性
CAS 只能对单个变量操作，如需原子操作多个变量，需将它们封装成一个对象（使用AtomicReference）。




什么是Java的 AQS?查看答案AQS 是 Java 并发编程的基础框架，它通过一个volatile int类型的state变量表示锁状态，并用 CLH 队列管理等待线程。例如，ReentrantLock用state记录重入次数，Semaphore用state表示可用许可数。子类需要通过 CAS 操作修改state，并实现tryAcquire和tryRelease方法来控制锁的获取与释放。
在 JUC 中的典型应用

**ReentrantLock**：公平锁和非公平锁的差异在于入队策略。非公平锁会先尝试 CAS 获取锁，失败后才入队；公平锁则直接入队等待。
**Semaphore**：当线程调用acquire()时，若state大于 0，则获取许可并减少state；否则阻塞。release()增加state并唤醒等待线程。
**CountDownLatch**：初始化时state为指定计数，线程调用countDown()时通过 CAS 减少state，当state减为 0 时，唤醒所有等待线程。
**ReentrantReadWriteLock**：使用两个 AQS 子类分别管理读锁和写锁，支持多读单写。

优缺点

优点
代码复用：避免重复实现队列管理和线程阻塞 &#x2F; 唤醒逻辑。
灵活性：通过模板方法支持多种锁语义（如公平锁、读写锁）。
高性能：CAS 和 CLH 队列在无竞争时效率高。


缺点
实现复杂：需要深入理解 AQS 的模板方法和状态管理。
只能支持独占或共享模式中的一种（子类需选择其一）。





AQS的核心原理查看答案AQS 的核心是通过state变量和 CLH 队列实现线程同步。当线程竞争锁时：

获取锁：线程调用acquire()方法，尝试通过 CAS 将state从 0 改为 1。若成功，则获取锁；否则放入队列。
入队等待：线程被封装成Node，通过 CAS 插入队尾，并通过LockSupport.park()阻塞。
释放锁：持有锁的线程调用release()方法，将state置为 0，并通过LockSupport.unpark()唤醒后继节点。

AQS 支持两种同步方式：

独占模式：如ReentrantLock，同一时间只有一个线程能持有锁，state表示重入次数。获取锁时，tryAcquire需判断state是否为 0（未锁定）或当前线程是否已持有锁（可重入）。
核心方法：

acquire：获取锁，失败进入等待队列
release：释放锁，唤醒等待队列中的线程


共享模式：如 Semaphore 和 CountDownLatch，state表示可用许可数。调用acquireShared时，若state大于 0，则 CAS 减少state并获取许可；否则入队等待。释放时，releaseShared增加state并唤醒后续节点。
核心方法：

acquireShared：共享模式获取锁
releaseShared：共享模式释放锁





AQS 如何处理线程中断和超时？查看答案
线程中断：
acquireInterruptibly()：可中断获取锁，被中断时抛出InterruptedException。
lockInterruptibly()：如ReentrantLock的可中断锁实现。


超时机制：
tryAcquireNanos()：指定时间内尝试获取锁，超时则返回false。





说说Java中ReentrantLock的实现原理？查看答案
在 Java 中，ReentrantLock是一个可重入的互斥锁，它位于java.util.concurrent.locks包下，实现了 Lock 接口，功能类似于synchronized关键字，但更加灵活。例如：

可重入：线程可多次调用 lock() 而不阻塞自己（需对应次数的 unlock()）。
公平锁：按请求顺序获取锁，避免 “线程饥饿”（但性能开销大）。
可中断锁：通过 lockInterruptibly() 允许线程在等待锁时响应中断。


ReentrantLock的实现基于AQS（AbstractQueuedSynchronizer） 和CAS（Compare-And-Swap） 操作：

AQS：作为同步器的基础框架，线程队列和管理锁状态（state）记录锁的持有次数。
state = 0：锁未被持有。
state &gt; 0：锁被持有，数值表示当前线程的重入次数。线程通过 CAS 操作尝试修改 state，成功则获取锁，失败则进入 AQS 队列等待。


CAS：用于原子性地更新锁状态，避免使用传统锁的开销。


公平锁 vs 非公平锁（如何实现？）



特性
公平锁
非公平锁



获取顺序
遵循请求顺序，先到先得（FIFO）。
允许插队，新请求可能比等待中的线程优先获取锁。是随机或者按照其他优先级排序


调度开销
较高，因为需要维护严格的队列顺序。
较低，因为减少了线程切换的开销。


吞吐量
可能较低，尤其在锁持有时间短的场景。
通常较高，因为减少了线程挂起和唤醒的次数。


饥饿可能性
几乎不会出现，每个线程都能按序获得锁。
存在可能，等待中的线程可能长时间无法获取锁。



公平锁：适用于需要保证线程执行顺序的场景，比如资源分配、定时任务执行等。
非公平锁：适合对吞吐量要求高、锁持有时间短的场景，像大多数的 RPC 调用、缓存更新操作等。

为什么默认是非公平锁？

非公平锁性能更高，因为省去了检查队列的开销。大多数场景下，线程的执行顺序对结果无影响，此时非公平锁的吞吐量更好。


可重入性实现
ReentrantLock通过 AQS 的state变量记录锁的重入次数：

当state为 0 时，表示锁未被任何线程持有。

当state大于 0 时，表示锁已被持有，且数值等于当前线程的重入次数。
protected final boolean tryAcquire(int acquires) &#123;    final Thread current = Thread.currentThread();    int c = getState();    if (c == 0) &#123;        // 锁未被持有，尝试获取        if (compareAndSetState(0, acquires)) &#123;            setExclusiveOwnerThread(current);            return true;        &#125;    &#125;    else if (current == getExclusiveOwnerThread()) &#123;        // 当前线程已持有锁，增加重入次数        int nextc = c + acquires;        if (nextc &lt; 0) // overflow            throw new Error(&quot;Maximum lock count exceeded&quot;);        setState(nextc);        return true;    &#125;    return false;&#125;


锁释放流程
释放锁时，每次调用unlock()会减少state的值：

当state减为 0 时，表示锁完全释放，唤醒队列中的下一个线程。
如果state仍大于 0，表示锁仍被当前线程持有（重入未完全释放）。

protected final boolean tryRelease(int releases) &#123;    int c = getState() - releases;    if (Thread.currentThread() != getExclusiveOwnerThread())        throw new IllegalMonitorStateException();    boolean free = false;    if (c == 0) &#123;        free = true;        setExclusiveOwnerThread(null);    &#125;    setState(c);    return free;&#125;



说说Java中synchronized的实现原理查看答案在 Java 里，synchronized关键字的主要作用是实现线程同步，保证同一时刻只有一个线程能够访问被它修饰的代码块或者方法。
synchronized 是基于Java对象头**（Object Header）**和 **Monitor**（监视器，也称为管程）实现的线程同步机制。使用的时候不用手动去 lock 和 unlock，JVM 会自动加锁和解锁。

对象头（Mark Word）：在对象的头部，有一部分空间用于存储锁的状态信息，比如偏向锁、轻量级锁、重量级锁这些标记。
Monitor（监视器）：这是 Java 对象所拥有的一个内置锁，其实现依赖于底层操作系统的互斥量（Mutex）。


Monitor（监视器）机制
Monitor 是 Java 中实现同步的基础，每个对象在内存中都有一个对象头——Mark Word，用于存储锁的状态，以及 Monitor 对象的指针。当一个线程尝试访问被 synchronized 修饰的代码块或方法时：

获取锁：线程必须先获得对象的 Monitor。如果 Monitor 已被其他线程持有，则当前线程会被阻塞，进入 Monitor 的等待队列。
释放锁：持有 Monitor 的线程执行完同步代码后释放锁，唤醒等待队列中的其他线程竞争锁。

底层实现：Monitor 依赖于操作系统的互斥量（Mutex）实现，这涉及用户态与内核态的切换，因此重量级锁的性能开销较大。
在 Hotspot 虚拟机中，Monitor 由 ObjectMonitor 实现，其核心结构如下：
ObjectMonitor &#123;    _header       = NULL;     // Mark Word 副本    _count        = 0;        // 重入次数    _waiters      = 0;        // 等待线程数    _recursions   = 0;        // 锁重入次数    _owner        = NULL;     // 持有锁的线程    _WaitSet      = NULL;     // 等待队列（wait() 的线程）    _cxq          = NULL;     // 竞争队列    _EntryList    = NULL;     // 阻塞队列&#125;

对象头（Object Header）：锁的存储基础
Java 对象在内存中分为三部分：

对象头（Header）：存储锁状态、GC 分代年龄、哈希码等。
实例数据（Instance Data）：对象的字段值。
对齐填充（Padding）：补齐内存对齐。

其中，对象头中的 Mark Word 存储了锁的状态信息。
Mark Word 结构：

Mark Word 是一个动态数据结构，根据锁状态不同存储不同信息。以 64 位 JVM 为例：
无锁状态：Mark Word存储对象哈希码、CG分代信息。
偏向锁：Mark Word存储偏向线程 ID、时间戳等。
轻量级锁：Mark Word存储线程栈帧中的锁记录指针。
重量级锁：Mark Word存储指向 Monitor 对象的指针。




锁升级过程
JDK 6 之后引入锁升级机制，避免直接使用重量级锁，优化了性能：
① 偏向锁（Biased Locking）
适用场景：
只有一个线程访问同步块。

原理：当第一个线程获取锁时，会在 Mark Word 中记录该线程的 ID（偏向锁状态）。此后该线程再次进入同步块时，无需任何同步操作，直接获取锁。

优点：
无竞争下几乎无开销。

升级触发：
当其他线程尝试竞争该锁时，偏向锁升级为轻量级锁。


② 轻量级锁（Lightweight Locking）
适用场景：
多个线程交替访问同步块（无竞争）。

原理：

线程在进入同步块前，会在栈帧中创建用于存储锁记录（Lock Record）的空间。
然后通过 CAS（Compare-and-Swap）操作，尝试将对象头的 Mark Word 复制到锁记录中，并将对象头指向锁记录的地址。
如果 CAS 操作成功，线程就获取到了锁；若失败，则表示有其他线程正在持有锁，当前线程会进行自旋等待，避免上下文切换。


升级触发：
当多个线程同时竞争锁时（CAS 失败多次），轻量级锁升级为重量级锁。


③ 重量级锁（Heavyweight Lock）
适用场景：
多个线程同时竞争锁。

原理：Mark Word 指向操作系统的 Monitor 对象，竞争失败的线程会被阻塞（进入内核态），锁释放后需唤醒线程（从内核态恢复）。

缺点：
线程阻塞和唤醒的开销大。





总结synchronized 的核心原理是通过对象头的 Mark Word 标记锁状态，并利用 Monitor 实现线程同步。锁升级机制（偏向锁 → 轻量级锁 → 重量级锁）在不同竞争程度下平衡了性能和安全性，使得它在大多数场景下成为首选的同步方式。



说说synchronized和ReentrantLock的区别查看答案


特性
synchronized
ReentrantLock



实现方式
JVM 内置关键字
JUC 包下的类


锁的释放
自动释放
手动释放


公平性
非公平锁
支持公平 &#x2F; 非公平锁


可中断性
不可中断
可中断


超时机制
不支持
支持


锁状态判断
不支持
支持


性能
优化后接近 ReentrantLock
竞争激烈时更灵活



优先使用 synchronized，因为它简洁易用，且 JVM 对其进行了优化。
当需要高级锁特性（如可中断锁、公平锁、超时机制）时，选择 ReentrantLock。



什么是线程死锁查看答案两个或多个线程在执行过程中，由于互相持有对方需要的资源（通常是锁），并无限期地等待对方释放资源，从而导致所有线程都无法继续执行下去的一种永久性阻塞状态。


死锁发生的条件是什么？如何解决？查看答案
死锁产生的 4 个必要条件（缺一不可）

互斥条件：资源（如锁）具有排他性，同一时间只能被一个线程持有（例如synchronized锁、ReentrantLock都是互斥的）。
持有并等待条件：线程持有至少一个资源，同时又在等待获取其他线程持有的资源。
不可剥夺条件：线程已持有的资源不能被其他线程强制剥夺，只能由线程主动释放（例如锁只能由持有者主动释放）。
循环等待条件：多个线程形成闭环等待链，每个线程都在等待下一个线程持有的资源（例如线程 1 等线程 2 的资源，线程 2 等线程 1 的资源）。


如何避免死锁？

破坏 “循环等待” 条件
给所有资源定义统一的获取顺序，所有线程必须按顺序获取资源。例如：规定 “必须先获取 LOCK_A，再获取 LOCK_B”，避免交叉获取。

破坏 “持有并等待” 条件
线程获取资源时，一次性获取所有所需资源（若获取不全则释放已持有的资源，重新尝试）。

破坏 “不可剥夺” 条件
使用可中断的锁（如ReentrantLock的tryLock(timeout)），若超时未获取到锁，则主动释放已持有的资源。

减少锁的持有时间
同步块只包含必要的代码，避免长时间持有锁，降低交叉等待的概率。






如何检测死锁？查看答案
在 Linux 生产环境中
可以先使用 top ps 等命令查看进程状态，看看是否有进程占用了过多的资源。

使用 JDK 自带工具（生产环境常用）
使用 jps -l 查看当前进程，然后使用 jstack 进程号 查看当前进程的线程堆栈信息，看看是否有线程在等待锁资源。

图形化工具：jconsole 或 VisualVM
可视化工具，查看线程状态和死锁。




并发工具类什么是Java的CountDownLatch?查看答案CountDownLatch 是 Java 并发包（java.util.concurrent）中的一个同步工具类，用于让一个或多个线程等待其他线程完成操作后再继续执行。它通过一个计数器实现，初始时设置计数器值，线程完成操作后调用 countDown() 方法递减计数器，等待线程通过 await() 方法阻塞，直到计数器值为 0。
	int workerCount = 3;   CountDownLatch latch = new CountDownLatch(workerCount);   // 创建并启动3个工作线程   for (int i = 0; i &lt; workerCount; i++) &#123;       final int taskId = i;       new Thread(() -&gt; &#123;           try &#123;               System.out.println(&quot;任务&quot; + taskId + &quot;开始执行&quot;);               Thread.sleep((long) (Math.random() * 1000));               System.out.println(&quot;任务&quot; + taskId + &quot;执行完成&quot;);           &#125; catch (InterruptedException e) &#123;               Thread.currentThread().interrupt();           &#125; finally &#123;               latch.countDown(); // 任务完成，计数器减1           &#125;       &#125;).start();   &#125;   // 主线程等待所有工作线程完成   latch.await();   System.out.println(&quot;所有任务已完成，主线程继续执行&quot;);//执行结果//任务0开始执行   //任务1开始执行   //任务2开始执行   //任务0执行完成   //任务2执行完成   //任务1执行完成   //所有任务已完成，主线程继续执行


什么是Java的CyclicBarrier？查看答案CyclicBarrier 是 Java 并发包（java.util.concurrent）中的一个同步工具类，用于让一组线程在到达某个屏障点（Barrier）时相互等待，直到所有线程都到达该点后，再继续执行后续操作。与 CountDownLatch 不同，CyclicBarrier 的计数器可以循环使用（重置后可再次等待），因此适用于需要多轮协作的场景。
// 创建一个屏障，等待3个线程CyclicBarrier barrier = new CyclicBarrier(3, () -&gt; &#123;    System.out.println(&quot;所有人都到齐了，一起出发！&quot;);&#125;);// 启动3个线程（模拟3个人）for (int i = 0; i &lt; 3; i++) &#123;    new Thread(() -&gt; &#123;        try &#123;          	System.out.println(Thread.currentThread().getName()+&quot;到餐厅了，等待其他人...&quot;);            barrier.await(); // 等待其他线程            System.out.println(Thread.currentThread().getName()+&quot;到电影院了，等待其他人...&quot;);            barrier.await(); // 可以循环使用，等待下一轮        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125;    &#125;).start();&#125;//执行结果//Thread-0到餐厅了，等待其他人...//Thread-2到餐厅了，等待其他人...//Thread-1到餐厅了，等待其他人...//所有人都到齐了，一起出发！//Thread-2到电影院了，等待其他人...//Thread-0到电影院了，等待其他人...//Thread-1到电影院了，等待其他人...//所有人都到齐了，一起出发！


CountDownLatch和CyclicBarrier的区别查看答案


特性
CountDownLatch
CyclicBarrier



使用次数
计数器减到 0 后无法重置，只能用一次。
支持循环使用（通过 reset() 方法）。


计数方向
递减（countDown）
递增（await）


等待方向
主线程等待子线程
线程互相等待


重置功能
❌ 不可重置
✅ 可重置


回调功能
❌ 无
✅ 全员到齐后执行指定任务


适用场景
启动前初始化，结束前收尾
计算任务拆分，所有线程都到达后才能继续


异常处理
计数不受影响，需要处理 InterruptedException。
需要处理 BrokenBarrierException（如某个线程中断导致屏障破坏）。



CyclicBarrier：像团队爬山，所有人在每个山顶等待，到齐后一起出发下一段路，可重复使用。
CountDownLatch：像火箭发射倒计时，各部门完成准备后计数减 1，倒计时结束后发射（且只发射一次）。



什么是Java的Semaphore?查看答案Semaphore（信号量）是 Java 并发包（java.util.concurrent）中的一个同步工具类，用于控制同时访问某个资源的线程数量。它通过维护一个许可证（permit）计数器，线程在访问资源前必须先获取许可证，使用完后释放许可证，从而限制并发访问的线程上限。
Semaphore semaphore = new Semaphore(3);for (int i = 1; i &lt;= 6; i++) &#123;    new Thread(() -&gt; &#123;        try &#123;            // 先获取许可证            semaphore.acquire();            // 成功获取后再打印日志            System.out.println(Thread.currentThread().getName() + &quot;抢到车位&quot;);            TimeUnit.SECONDS.sleep(2);        &#125; catch (InterruptedException e) &#123;            throw new RuntimeException(e);        &#125; finally &#123;            System.out.println(Thread.currentThread().getName() + &quot;离开车位&quot;);            semaphore.release();        &#125;    &#125;, String.valueOf(i)).start();&#125;//执行结果//1抢到车位//3抢到车位//2抢到车位//2离开车位//1离开车位//3离开车位//4抢到车位//5抢到车位//6抢到车位//4离开车位//5离开车位//6离开车位


什么是Java的Exchanger ？查看答案Exchanger 是 Java 并发包（java.util.concurrent）中的一个同步工具类，用于两个线程之间交换数据。它允许两个线程在某个同步点互相交换各自持有的数据，当一个线程到达 exchange() 方法时，会阻塞直到另一个线程也到达该方法，然后两者交换数据并继续执行。
import java.util.concurrent.Exchanger;public class ProducerConsumer &#123;    private static final Exchanger&lt;String&gt; EXCHANGER = new Exchanger&lt;&gt;();    public static void main(String[] args) &#123;        // 生产者线程        Thread producer = new Thread(() -&gt; &#123;            try &#123;                String data = &quot;生产的数据&quot;;                System.out.println(&quot;生产者：准备交换数据 &quot; + data);                String receivedData = EXCHANGER.exchange(data);                System.out.println(&quot;生产者：收到消费者的数据 &quot; + receivedData);            &#125; catch (InterruptedException e) &#123;                Thread.currentThread().interrupt();            &#125;        &#125;);        // 消费者线程        Thread consumer = new Thread(() -&gt; &#123;            try &#123;                String data = &quot;反馈信息&quot;;                System.out.println(&quot;消费者：准备交换数据 &quot; + data);                String receivedData = EXCHANGER.exchange(data);                System.out.println(&quot;消费者：收到生产者的数据 &quot; + receivedData);            &#125; catch (InterruptedException e) &#123;                Thread.currentThread().interrupt();            &#125;        &#125;);        producer.start();        consumer.start();    &#125;&#125;


线程池什么是线程池查看答案线程池是一种 线程复用机制，通过预先创建&#x2F;管理线程集合，避免频繁线程创建销毁带来的性能开销，实现任务的并发执行。


如何创建线程池查看答案
手动创建 ThreadPoolExecutor（推荐，更安全可控）
ThreadPoolExecutor threadPool = new ThreadPoolExecutor(              2,              5,              2,              TimeUnit.SECONDS,              new LinkedBlockingQueue&lt;&gt;(3),              Executors.defaultThreadFactory(),              new ThreadPoolExecutor.DiscardPolicy()      );        try &#123;          for (int i = 0; i &lt; 9; i++) &#123;              threadPool.execute(()-&gt;&#123;                  System.out.println(Thread.currentThread().getName()+&quot;=&gt;执行业务&quot;);              &#125;);          &#125;      &#125; catch (Exception e) &#123;          e.printStackTrace();      &#125; finally &#123;          threadPool.shutdown();      &#125;



通过 Executors 工厂类创建（简单快捷）
ExecutorService threadPool = Executors.newFixedThreadPool(5);//创建一个固定大小的线程池try &#123;    for (int i = 0; i &lt; 4; i++) &#123;        threadPool.execute(()-&gt;&#123;            System.out.println(Thread.currentThread().getName()+&quot;=&gt;执行业务&quot;);        &#125;);    &#125;&#125; catch (Exception e) &#123;    throw new RuntimeException(e);&#125; finally &#123;    threadPool.shutdown();&#125;



线程池的原理查看答案graph TD
  A[提交任务] --&gt; B(核心线程&lt;br&gt;是否空闲?):::decision
  B --&gt;|是| C[立即执行]:::process
  B --&gt;|否| D(任务队列&lt;br&gt;是否已满?):::decision
  D --&gt;|否| E[加入队列等待]:::process
  D --&gt;|是| F(线程数&lt;br&gt;&lt;最大线程数?):::decision
  F --&gt;|是| G[创建临时线程执行]:::process
  F --&gt;|否| H[触发拒绝策略]:::process
  
  classDef decision fill:#FFF6CC,stroke:#FFBC52,stroke-width:2px
  classDef process fill:#E5F6FF,stroke:#73A6FF,stroke-width:2px


线程池常见的参数有哪些？查看答案public ThreadPoolExecutor(int corePoolSize,                             int maximumPoolSize,                             long keepAliveTime,                             TimeUnit unit,                             BlockingQueue&lt;Runnable&gt; workQueue,                             ThreadFactory threadFactory,                             RejectedExecutionHandler handler) &#123;


corePoolSize（核心线程数）

作用：线程池长期保持的最小线程数（即使空闲也不会被销毁，除非开启 allowCoreThreadTimeOut）。
配置建议：
CPU 密集型任务（如计算）：设为 CPU 核心数 + 1（减少线程切换开销）。
IO 密集型任务（如网络 &#x2F; DB 操作）：设为 2 × CPU 核心数（利用等待时间并行处理）。
混合型任务：(线程等待时间/线程CPU时间 + 1) * CPU核数




maximumPoolSize（最大线程数）

作用：线程池允许创建的最大线程数量（包括核心线程和临时线程）
关键规则：
当 任务数 &gt; corePoolSize 且 工作队列已满 时，才会创建临时线程
临时线程数量 &#x3D; maximumPoolSize - corePoolSize


配置建议：通常设为 corePoolSize * 2，但需考虑系统资源上限


keepAliveTime（空闲线程存活时间）

作用：临时线程空闲时的存活时间，超时后会被回收，需配合 TimeUnit 参数使用
默认值：60 秒。


unit（时间单位）

作用：指定 keepAliveTime 的时间单位

常用值：
TimeUnit.SECONDS  // 秒TimeUnit.MILLISECONDS // 毫秒TimeUnit.MINUTES // 分钟


workQueue（任务队列）

作用：缓存待执行任务的队列，核心线程忙时任务进入队列等待。	

常见实现类：



队列类型
容量特性
适用场景
线程池默认使用



ArrayBlockingQueue
有界
任务量可控、需限制内存
手动配置（如自定义线程池）


LinkedBlockingQueue
无界（默认）
任务处理快、需避免任务被拒
FixedThreadPool、SingleThreadExecutor


SynchronousQueue
容量 0
任务处理极快、需动态线程数
CachedThreadPool


PriorityBlockingQueue
无界
任务需优先级排序
需手动配置（如自定义线程池）


DelayQueue
无界
定时任务、延迟执行
ScheduledThreadPool





threadFactory（线程工厂）

作用：自定义线程创建逻辑（如命名线程、设置优先级、守护线程等）。
默认值：Executors.defaultThreadFactory()（创建的线程名为 pool-1-thread-1 格式）。
场景：建议自定义工厂（如 new ThreadFactory() { ... }），便于日志追踪和问题排查。


handler（拒绝策略）

作用：当线程数&#x3D;maxPoolSize且队列已满时，对新任务的拒绝策略。

默认值：AbortPolicy（抛异常 RejectedExecutionException）。

常见策略：



策略类
行为



AbortPolicy（默认）
抛出 RejectedExecutionException 异常


CallerRunsPolicy
由提交任务的线程直接执行该任务（同步执行）


DiscardPolicy
静默丢弃新任务，不抛异常


DiscardOldestPolicy
丢弃队列中最旧的任务，然后重试提交








线程池的常用的阻塞队列有哪些？查看答案
**ArrayBlockingQueue**（有界阻塞队列）

底层由数组实现，容量一旦创建，就不能修改。
适用场景：需要严格控制队列长度，防止资源耗尽（如高并发限流）。
在线程池中： 当队列满时，提交新任务会触发线程池的拒绝策略。


**LinkedBlockingQueue**（默认无界，也可指定容量）

底层由链表实现，默认大小为  Integer.MAX_VALUE （无界易引发OOM），可指定为有界队列
适用场景：
有界： 需要控制任务数量，但任务量波动较大。
无界： 任务到达速度通常不会长时间远高于处理速度，且能容忍队列暂时增长（需警惕 OOM）。newFixedThreadPool 和 newSingleThreadExecutor 默认使用无界 LinkedBlockingQueue。


在线程池中：
有界： 队列满时触发拒绝策略。
无界： 理论上队列永远不会满（除非 OOM），因此提交任务通常不会触发拒绝策略（除非线程池关闭或饱和策略有其他限制）。




**SynchronousQueue**（同步队列）

没有容量的阻塞队列是一种没有容量的阻塞队列，生产者插入任务时必须等待消费者取出。它直接传递任务，避免任务排队，适合快速响应的场景，但对线程池的扩缩容更敏感。
任务处理速度快：适合需要快速响应的场景。
创建线程无限制：如**Executors.newCachedThreadPool()**默认使用此队列，配合 Integer.MAX_VALUE 最大线程数。
在线程池中：
如果没有空闲工作线程且当前线程数未达核心线程数，会创建新线程。
如果没有空闲工作线程且当前线程数已达到核心线程数（但小于最大线程数），会创建新线程。
如果没有空闲工作线程且当前线程数已达最大线程数，则提交任务会立即触发拒绝策略（因为队列无法存放任何任务）。这使得 SynchronousQueue 能非常快速地响应系统过载。




**DelayedWorkQueue**（延迟队列）

实现： 基于 PriorityQueue 实现的延时近似无界阻塞队列。

特性：

延时获取： 元素必须实现 Delayed 接口。只有在其指定的延迟时间到期后，元素才能被取出。

近似无界： 容量自动增长。


无界风险： OOM 风险。

适用场景： 需要延迟执行任务的场景，如定时任务调度、缓存过期失效等。



在线程池中： 

通常需要配合自定义的线程池使用（如 ScheduledThreadPoolExecutor 内部使用了类似 DelayQueue 的机制）。提交任务时，即使队列未满，任务也不会立即被执行，而是等到其延迟到期。队列满不是主要问题（近似无界），但需注意 OOM。


**PriorityBlockingQueue**（支持优先级排序）

实现： 支持优先级排序的近似无界阻塞队列。
特性：
优先级： 元素必须实现 Comparable 接口，或者在构造队列时提供 Comparator。队列按照优先级顺序出队（优先级最高的先出队）。
近似无界： 容量自动增长（受限于内存），所以 put 操作通常不会阻塞（除非资源耗尽）。
无界风险： 同样有 OOM 风险。
非 FIFO： 出队顺序由优先级决定。


适用场景： 需要根据任务优先级而非提交顺序来执行任务的场景。
在线程池中： 由于近似无界，提交任务通常不会因队列满而触发拒绝策略（优先级低的可能会长时间等待）。





线程池的拒绝策略有哪些？查看答案当线程池无法接受新的任务时，也就是线程数达到 maximumPoolSize，任务队列也满了的时候，就会触发拒绝策略。

AbortPolicy（默认）：直接抛出 RejectedExecutionException 异常，拒绝新任务。

CallerRunsPolicy：由提交任务的线程（如主线程）直接执行被拒任务。

DiscardPolicy：静默丢弃被拒任务，无异常、无日志。

DiscardOldestPolicy  ：移除队列中最旧的任务（队列头部），重试提交新任务。

自定义拒绝策略：默认策略不能满足需求，可以通过实现 RejectedExecutionHandler 接口来定义自己的淘汰策略。
public class MyRejectedExecution implements RejectedExecutionHandler &#123;    @Override    public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123;        System.out.println(&quot;Task &quot; + r.toString() + &quot; rejected. Queue size: &quot; + executor.getQueue().size());    &#125;&#125; public static void main(String[] args) &#123;        ThreadPoolExecutor threadPool = new ThreadPoolExecutor(                2,                5,                2,                TimeUnit.SECONDS,                new LinkedBlockingQueue&lt;&gt;(3),                Executors.defaultThreadFactory(),                new MyRejectedExecution()        );        try &#123;            for (int i = 0; i &lt; 9; i++) &#123;                threadPool.execute(()-&gt;&#123;                    System.out.println(Thread.currentThread().getName()+&quot;=&gt;办理业务&quot;);                &#125;);            &#125;        &#125; catch (Exception e) &#123;            e.printStackTrace();        &#125; finally &#123;            threadPool.shutdown();        &#125;    &#125;



如何选择拒绝策略查看答案需要结合队列来选择

有界队列：常用 AbortPolicy（抛异常）或 CallerRunsPolicy（让提交线程执行任务）。
无界队列：理论上不会触发拒绝策略（但需防OOM）。
SynchronousQueue：建议用 DiscardPolicy 或自定义策略避免阻塞提交线程。



有哪几种常见的线程池查看答案
FixedThreadPool（固定线程数线程池）
特点：核心线程数 &#x3D; 最大线程数（通过Executors.newFixedThreadPool(n)的n指定），线程池中的线程数量固定不变。使用无界阻塞队列LinkedBlockingQueue 存储等待任务。线程空闲时不会被回收（核心线程数 &#x3D; 最大线程数，且无超时机制）。
适用场景：适用于任务数量已知、任务执行时间较长且稳定的场景（如服务器接收固定数量的并发请求）。


CachedThreadPool（可缓存线程池）
特点：核心线程数 &#x3D; 0，最大线程数 &#x3D;Integer.MAX_VALUE（理论上无限）。使用**同步队列SynchronousQueue**（不存储任务，直接传递给线程）。线程空闲 60 秒后会被自动回收，因此空闲时几乎不占用资源。
适用场景：适用于任务数量多但执行时间短、突发且临时的任务（如临时批量处理短任务）。缺点：最大线程数过大，若任务执行时间过长，可能创建大量线程导致资源耗尽。


SingleThreadExecutor（单线程线程池）
特点：核心线程数 &#x3D; 1，最大线程数 &#x3D; 1，仅用一个线程执行所有任务。使用**无界阻塞队列LinkedBlockingQueue**，任务按提交顺序串行执行。若唯一线程因异常终止，会自动创建新线程替代。
适用场景：适用于需要任务串行执行（如日志写入、顺序处理数据）或避免并发冲突的场景。


ScheduledThreadPool（定时任务线程池）
特点：核心线程数固定（通过Executors.newScheduledThreadPool(n)的n指定），最大线程数 &#x3D; Integer.MAX_VALUE。使用**延迟队列DelayedWorkQueue**（支持定时 &#x2F; 周期性执行）。支持定时（schedule()）或周期性（scheduleAtFixedRate()）执行任务。
适用场景：适用于需要定时执行（如延迟 3 秒后执行）或周期性执行（如每隔 1 分钟执行一次）的任务（如定时备份、心跳检测）。





为什么不建议使用Executors去创建线程池查看答案【强制】线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同学更加明确线程池的运行规则，规避资源耗尽的风险。 
说明：Executors 返回的线程池对象的弊端如下： 

1）newFixedThreadPool(n) 和 newSingleThreadExecutor()：队列无界，可能导致 OOM
这两种线程池的核心线程数 &#x3D; 最大线程数（固定大小），工作队列使用 LinkedBlockingQueue，而该队列的默认容量是 Integer.MAX_VALUE（约 20 亿）。当任务提交速度远快于线程处理速度时，任务会在队列中无限堆积，占用大量内存，最终导致 OOM（内存溢出）。

2）newCachedThreadPool()：线程数无界，可能导致资源耗尽
该线程池的核心线程数为 0，最大线程数为 Integer.MAX_VALUE，线程空闲 60 秒后销毁，工作队列使用 SynchronousQueue（不存储任务，直接提交给线程）。
当任务提交量激增时，线程池会无限创建新线程（理论上可达 20 亿）。过多的线程会导致：

大量 CPU 时间用于线程上下文切换，系统吞吐量骤降；
线程占用的内存（如栈空间）急剧增加，最终触发 OOM。


3） newScheduledThreadPool(n)：存在线程数或队列的潜在问题
本质是支持定时任务的线程池，其核心线程数固定，但工作队列类似 DelayQueue，若任务调度不当（如大量长期未执行的定时任务），也可能导致队列堆积和资源耗尽。




线程池的生命周期查看答案
RUNNING（运行中）

初始状态：线程池创建后默认进入此状态。

行为：

能接受新任务（execute() 方法正常提交）。
能处理阻塞队列中已存在的任务。




SHUTDOWN（关闭中）

触发条件：调用 shutdown() 方法。

行为：

不接受新任务（新提交的任务会被拒绝策略处理）。
继续处理阻塞队列中已存在的任务，直到队列清空。


转换：当队列中所有任务处理完毕，且工作线程数量为 0 时，进入 TIDYING 状态。



STOP（停止中）

触发条件：调用 shutdownNow() 方法。

行为：

不接受新任务。
立即中断正在执行的任务（通过 Thread.interrupt()）。
清空阻塞队列（未执行的任务被移除并返回）。


转换：当所有工作线程都已中断（数量为 0）时，进入 TIDYING 状态。



TIDYING（整理中）

触发条件：

从 SHUTDOWN 转换：队列清空 + 工作线程数量为 0。
从 STOP 转换：工作线程数量为 0。


行为：

线程池进入 “整理” 状态，此时会执行 terminated() 钩子方法（默认空实现，可重写用于资源清理）。




TERMINATED（已终止）

触发条件：terminated() 方法执行完毕。
行为：线程池生命周期结束，无法再执行任何任务。






方法
作用
状态转换触发



shutdown()
平缓关闭：不接受新任务，处理完队列任务
RUNNING → SHUTDOWN


shutdownNow()
强制关闭：中断任务，清空队列
RUNNING → STOP


isShutdown()
判断是否处于 SHUTDOWN&#x2F;STOP 状态
-


isTerminated()
判断是否处于 TERMINATED 状态
-


awaitTermination()
阻塞等待线程池进入 TERMINATED 状态
-




线程池中shutdown ()，shutdownNow()有什么区别查看答案


方法
任务处理
线程状态
响应中断



shutdown()
已提交的任务会继续执行（包括队列中等待的任务）
不再接受新任务，线程池状态变为 SHUTDOWN
不中断正在执行的线程


shutdownNow()
尝试终止所有活跃线程，未执行的任务返回
立即终止，线程池状态变为 STOP
中断正在执行的线程（通过 Thread.interrupt()）




]]></content>
      <categories>
        <category>面试题</category>
        <category>Java 并发面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM面试题</title>
    <url>/2025/08/06/Interview/JVM%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[JVM 面试题Java 内存模型中堆(Heap)和栈(Stack)的区别?


对比维度
堆（Heap）
栈（Stack，通常指虚拟机栈）



存储内容
所有对象实例（new创建的对象）、数组
局部变量（方法内定义的变量）、方法调用信息（栈帧，包含操作数栈、局部变量表等）


线程共享性
所有线程共享，是线程不安全的（需同步机制保障）
线程私有，每个线程有独立的栈，线程间不共享


生命周期
与 JVM 进程一致（随 JVM 启动而创建，退出而销毁）
与线程 &#x2F; 方法调用绑定：线程启动时创建栈，方法调用时创建栈帧，方法结束时栈帧销毁


内存管理
由 JVM 自动管理，依赖垃圾回收器（GC）回收内存
无需 GC，随方法调用 &#x2F; 线程结束自动释放内存（栈帧出栈）


大小与调整
内存空间较大（通常几 GB），可通过-Xms（初始）、-Xmx（最大）参数调整
内存空间较小（通常几 MB），可通过-Xss参数调整单个线程的栈大小


异常类型
内存不足时触发OutOfMemoryError: Java heap space
栈深度超限触发StackOverflowError；栈扩展失败触发OutOfMemoryError: Stack overflow（部分 JVM）


什么情况下会触发OutOfMemoryError?OutOfMemoryError本质是 “内存区域无法分配新空间”，不同内存区域的 OOM 触发原因不同，具体如下：
1. 堆内存溢出（Java heap space）
触发原因：堆中创建的对象 &#x2F; 数组过多，且无法被垃圾回收（存在有效引用），导致堆空间耗尽。

典型场景：

内存泄漏：对象不再使用但仍被引用（如静态集合持有大量过期对象），例如：
static List&lt;Object&gt; list = new ArrayList&lt;&gt;();while (true) &#123;    list.add(new Object()); // 对象被静态集合引用，无法GC，最终堆溢出&#125;

对象创建速度超过 GC 回收速度：短时间内创建大量对象（如高并发下的大对象频繁实例化），堆空间无法及时释放。



解决思路：通过-Xmx调大堆内存；排查内存泄漏（用 MAT 等工具分析堆快照）；优化对象创建逻辑（如复用对象、使用池化技术）


2. 方法区 &#x2F; 元空间溢出（Metaspace OOM 或 PermGen space）
触发原因：方法区（JDK8 + 为元空间，JDK7 及之前为永久代）存储类信息、常量、静态变量等，当加载的类过多或常量池过大时，空间耗尽。

典型场景：

动态生成大量类：如使用 CGLib、JDK 动态代理等频繁生成子类（每个类的信息都存于方法区），例如：
while (true) &#123;    Enhancer enhancer = new Enhancer();    enhancer.setSuperclass(User.class);    enhancer.create(); // 每次创建都会生成新的代理类，类信息累积导致元空间溢出&#125;

常量池过大：字符串常量池（JDK7 后移至堆，但部分实现仍可能关联方法区）存储过多字符串，且无法被回收（如String.intern()滥用）。




3. 虚拟机栈 &#x2F; 本地方法栈溢出（StackOverflowError 与 Stack OOM）StackOverflowError（更常见）：线程栈深度超过最大限制（方法调用层级过深，如无限递归），例如：
public void recursive() &#123;    recursive(); // 无限递归，栈帧不断入栈，最终栈深度超限&#125;

OutOfMemoryError: Stack overflow（部分 JVM）：如果 JVM 允许栈动态扩展，当扩展时无法申请到足够内存（如创建大量线程，每个线程栈占用内存累积超过系统限制），例如：
while (true) &#123;    new Thread(() -&gt; &#123;        while (true) &#123;&#125; // 线程不退出，持续占用栈内存，最终总栈内存耗尽    &#125;).start();&#125;


解决思路：通过-Xss调大单个线程栈大小（但会减少最大线程数）；避免无限递归；控制线程创建数量（用线程池）。

4. 直接内存溢出（Direct buffer memory）
触发原因：直接内存（不受 JVM 堆管理，由操作系统直接分配）通常用于 NIO（DirectByteBuffer），当分配的直接内存超过限制（默认与堆最大值一致），会触发 OOM。

典型场景：
while (true) &#123;    ByteBuffer.allocateDirect(1024 * 1024); // 持续分配直接内存，超过限制后溢出&#125;

解决思路：通过-XX:MaxDirectMemorySize调大直接内存限制；及时释放不再使用的DirectByteBuffer（避免长期引用）。


]]></content>
      <categories>
        <category>面试题</category>
        <category>JVM 面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title>MyBrtis面试题</title>
    <url>/2025/08/05/Interview/MyBatis%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[MyBrtis面试题]]></content>
      <categories>
        <category>面试题</category>
        <category>MyBatis面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title>Java面试题</title>
    <url>/2025/07/03/Interview/Java%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[Java 面试题Java 语法基础练习题翻转整数给定一个 32 位有符号整数，将整数中的数字进行反转。如果反转后整数溢出那么就返回 0。
示例 1:
输入: 123输出: 321

示例 2:
输入: -123输出: -321

查看答案private static int reverse(int num) &#123;       int result = 0;       while (num != 0)&#123;           // 获取末尾数字           int pop = num % 10;//123 % 10 = 3; 12 % 10 = 2; 1 % 10 = 1; 0 % 10 = 0           // 获取数字           num /= 10;// 123 / 10 = 12; 12 / 10 = 1; 1 / 10 = 0;           // 判断是否越界           if (result &gt; Integer.MAX_VALUE / 10 || (result == Integer.MAX_VALUE / 10 &amp;&amp; pop &gt; 7))&#123;               return 0;           &#125;           if (result &lt; Integer.MIN_VALUE / 10 || (result == Integer.MIN_VALUE / 10 &amp;&amp; pop &lt; -8))&#123;               return 0;           &#125;           // 拼接数字           result = result * 10 + pop;// 0 * 10 + 3 = 3; 3 * 10 + 2 = 32; 32 * 10 + 1 = 321;       &#125;       return result;   &#125;


字符串转换整数请你来实现一个 myAtoi(string s) 函数，使其能将字符串转换成一个 32 位有符号整数。
函数 myAtoi(string s) 的算法如下：

空格：读入字符串并丢弃无用的前导空格（&quot; &quot;）
符号：检查下一个字符（假设还未到字符末尾）为 &#39;-&#39; 还是 &#39;+&#39;。如果两者都不存在，则假定结果为正。
转换：通过跳过前置零来读取该整数，直到遇到非数字字符或到达字符串的结尾。如果没有读取数字，则结果为0。
舍入：如果整数数超过 32 位有符号整数范围 [−231, 231 − 1] ，需要截断这个整数，使其保持在这个范围内。具体来说，小于 −231 的整数应该被舍入为 −231 ，大于 231 − 1 的整数应该被舍入为 231 − 1 。

返回整数作为最终结果。
示例 1：
输入：s &#x3D; “42”
输出：42
解释：加粗的字符串为已经读入的字符，插入符号是当前读取的字符。
带下划线线的字符是所读的内容，插入符号是当前读入位置。第 1 步：&quot;42&quot;（当前没有读入字符，因为没有前导空格）         ^第 2 步：&quot;42&quot;（当前没有读入字符，因为这里不存在 &#x27;-&#x27; 或者 &#x27;+&#x27;）         ^第 3 步：&quot;42&quot;（读入 &quot;42&quot;）           ^

示例 2：
输入：s &#x3D; “ -042”
输出：-42
解释：
第 1 步：&quot;   -042&quot;（读入前导空格，但忽视掉）            ^第 2 步：&quot;   -042&quot;（读入 &#x27;-&#x27; 字符，所以结果应该是负数）             ^第 3 步：&quot;   -042&quot;（读入 &quot;042&quot;，在结果中忽略前导零）               ^

示例 3：
输入：s &#x3D; “1337c0d3”
输出：1337
解释：
第 1 步：&quot;1337c0d3&quot;（当前没有读入字符，因为没有前导空格）         ^第 2 步：&quot;1337c0d3&quot;（当前没有读入字符，因为这里不存在 &#x27;-&#x27; 或者 &#x27;+&#x27;）         ^第 3 步：&quot;1337c0d3&quot;（读入 &quot;1337&quot;；由于下一个字符不是一个数字，所以读入停止）             ^

示例 4：
输入：s &#x3D; “0-1”
输出：0
解释：
第 1 步：&quot;0-1&quot; (当前没有读入字符，因为没有前导空格)         ^第 2 步：&quot;0-1&quot; (当前没有读入字符，因为这里不存在 &#x27;-&#x27; 或者 &#x27;+&#x27;)         ^第 3 步：&quot;0-1&quot; (读入 &quot;0&quot;；由于下一个字符不是一个数字，所以读入停止)          ^

示例 5：
输入：s &#x3D; “words and 987”
输出：0
解释：
读取在第一个非数字字符“w”处停止。
提示：

0 &lt;= s.length &lt;= 200
s 由英文字母（大写和小写）、数字（0-9）、&#39; &#39;、&#39;+&#39;、&#39;-&#39; 和 &#39;.&#39; 组成

查看答案private static int parseInt(String str) &#123;    // 去除空格    str = str.trim();    if(str.isEmpty())&#123;        return 0;    &#125;    // 检查符号位    int sign = 1;    int index = 0;    if (str.charAt(0) == &#x27;+&#x27; || str.charAt(0) == &#x27;-&#x27;) &#123;        sign = str.charAt(0) == &#x27;+&#x27; ? 1 : -1;        index++;    &#125;    // 转换数字并处理溢出    int result = 0;    while (index &lt; str.length()) &#123;        // 判断是否为数字        char c = str.charAt(index);        // 判断是否为数字        if (!Character.isDigit(c)) break;        // 将字符转换为数字        int digit = c - &#x27;0&#x27;;        // 检查溢出：result * 10 + digit &gt; Integer.MAX_VALUE        if (result &gt; (Integer.MAX_VALUE - digit) / 10) &#123;            return sign == 1 ? Integer.MAX_VALUE : Integer.MIN_VALUE;        &#125;        // 计算结果        result = result * 10 + digit;        // 移动到下一个字符        index++;    &#125;    return sign * result;&#125;

int digit = c - &#39;0&#39;; 这行代码的作用是将字符 c 转换为对应的数字值。
字符与 ASCII 码的关系
在计算机中，字符通常以 ASCII 码的形式存储。例如：

字符 &#39;0&#39; 的 ASCII 值是 48
字符 &#39;1&#39; 的 ASCII 值是 49
字符 &#39;2&#39; 的 ASCII 值是 50
…
字符 &#39;9&#39; 的 ASCII 值是 57

因此，字符 &#39;0&#39; 到 &#39;9&#39; 的 ASCII 值是连续递增的，差值恰好对应数字值。
代码解析
当你有一个字符变量 c（例如 &#39;3&#39;），执行 c - &#39;0&#39; 时：

c 被隐式转换为对应的 ASCII 值（例如 &#39;3&#39; 的值是 51）。
&#39;0&#39; 的 ASCII 值是 48。
计算差值：51 - 48 = 3，得到的结果就是字符 &#39;3&#39; 对应的数字 3。

示例：
char c = &#x27;3&#x27;;int digit = c - &#x27;0&#x27;;  // 等价于 51 - 48 = 3System.out.println(digit);  // 输出: 3


数组和字符串Java中String、StringBuffer和StringBuilder的区别是什么？查看答案
String：不可变字符，每次拼接会创建新的对象。
StringBuffer：可变字符，线程安全，多线程环境下性能高。
StringBuilder：可变字符，线程不安全，单线程的环境下性能高。



String str &#x3D; new String(“abc”) 创建了几个对象？查看答案
判断字符串常量池中是否存在字面量 &quot;abc&quot;。
若不存在：JVM 会在常量池中创建一个 String 对象，值为 &quot;abc&quot;。
若已存在：跳过此步骤，不创建新对象。


无论常量池中是否已有 &quot;abc&quot;，new String(&quot;abc&quot;) 都会在堆内存中创建一个新的 String 对象，该对象的值复制自常量池中的 &quot;abc&quot;。

String str1 = new String(&quot;abc&quot;);  // 最多创建 2 个对象（常量池 + 堆）String str2 = new String(&quot;abc&quot;);  // 最多创建 1 个对象（仅堆，常量池已存在 &quot;abc&quot;）System.out.println(str1 == str2); // false，堆中对象地址不同System.out.println(str1.equals(str2)); // true，内容相同


String str1 &#x3D; new String(“abc”) 和 String str2 &#x3D; “abc” 的区别？查看答案
new String(&quot;abc&quot;)：
无论如何都会在堆中创建新对象，且可能在常量池中创建对象（若字面量不存在）。
内存占用：至少 1 个对象（堆），最多 2 个对象（堆 + 常量池）。


String str2 = &quot;abc&quot;;：
仅在常量池中创建对象（若不存在），否则直接引用常量池中的对象。
内存占用：0 或 1 个对象（仅当常量池不存在 &quot;abc&quot; 时创建）。





intern方法有什么作用？查看答案intern() 是 String 类的一个 native 方法，用于手动将字符串对象添加到 字符串常量池 中，并返回常量池中的引用。其核心作用是 复用字符串对象，节省内存。以下是详细解析：
1. 基本原理
检查常量池：调用str.intern()时，JVM 会先检查字符串常量池中是否已存在与str内容相同（equals() 为 true）的字符串。

若存在：直接返回常量池中的引用，即使 str 本身在堆中。
若不存在：将 str 的内容添加到常量池（JDK 7+ 后直接复制引用，而非创建新对象），并返回该引用。

2. 关键区别（JDK 6 vs JDK 7+）

JDK 6 及以前：常量池存放在永久代（方法区），intern() 会在常量池 复制字符串对象（创建新对象）。
**JDK 7+**：常量池移至堆内存，intern() 会 直接引用堆中的对象，而非复制。



面向对象抽象类和接口有什么区别查看答案


抽象类
接口



定义与语法



使用 abstract class 声明
使用 interface 声明


可以包含普通方法和抽象方法
只能包含抽象方法（Java 8+ 允许默认方法和静态方法）


抽象方法使用 abstract 关键字声明
方法默认是 public abstract，无需显式声明


可以有构造器
不能有构造器


继承与实现



子类使用 extends 关键字继承
类使用 implements 关键字实现接口


一个类只能继承一个抽象类
一个类可以实现多个接口


子类必须实现所有抽象方法
实现类必须实现所有抽象方法（除非类是抽象类）


成员变量



可以有各种访问修饰符的成员变量
只能有 public static final 常量


示例：protected int age;
示例：int MAX_SPEED = 100;（隐式为 public static final）


设计目的



表示 “is-a” 关系，定义类的基本特征和行为
表示 “can-do” 关系，定义类的额外能力


用于代码复用和共享公共状态
用于实现多态和松耦合


适合作为相关类的基类
适合为不相关类提供通用功能


应用场景



当需要共享代码和状态时
当需要定义行为规范但不关心实现时


当类之间有共同的属性和行为时
当多个不相关的类需要实现同一功能时


例如：java.io.InputStream
例如：java.util.Comparator







使用抽象类：当需要定义类的基本行为，且有共享代码或状态时。
使用接口：当需要定义行为规范，且希望被多个不相关的类实现时。



Java中的参数传递是按值，还是按引用？查看答案在Java中，参数传递只有按值传递，无论是基本类型还是引用类型。


什么是反射？查看答案反射是 Java 在运行时动态获取类的信息（如方法、字段、构造器等），并可以动态调用对象的方法或操作字段的能力。核心类位于java.lang.reflect包中。

反射原理：
Java 程序的执行分为编译和运行两步，编译之后会生成字节码(.class)文件，JVM 进行类加载的时候，会加载字节码文件，将类型相关的所有信息加载进方法区，反射就是去获取这些信息，然后进行各种操作。

基本用法
// 获取Class对象的三种方式Class&lt;?&gt; clazz = MyClass.class;           // 方式1：类名.classClass&lt;?&gt; clazz = obj.getClass();          // 方式2：对象实例.getClass()Class&lt;?&gt; clazz = Class.forName(&quot;com.MyClass&quot;); // 方式3：全限定名// 通过反射创建对象Constructor&lt;?&gt; constructor = clazz.getConstructor();MyClass obj = (MyClass) constructor.newInstance();// 通过反射调用方法Method method = clazz.getMethod(&quot;methodName&quot;, paramTypes);method.invoke(obj, args);// 通过反射访问字段Field field = clazz.getDeclaredField(&quot;fieldName&quot;);field.setAccessible(true); // 打破私有访问限制field.set(obj, value);



反射在你平时写代码或者框架中的应用场景有哪些?查看答案


框架
反射应用场景
具体实现



Spring
依赖注入(IoC)
通过反射创建Bean实例并注入依赖



AOP动态代理
动态生成代理类并拦截方法调用



注解处理(@Autowired等)
扫描并解析类&#x2F;方法&#x2F;字段上的注解


Hibernate&#x2F;MyBatis
ORM映射
通过反射将数据库结果集映射到Java对象



懒加载机制
动态生成实体类的代理对象


JUnit
测试用例发现和执行
通过反射查找带@Test注解的方法并执行




什么是Java中的动态代理？查看答案动态代理是 Java 在运行时动态创建代理类和对象的机制，它允许在不修改原始类代码的情况下，通过代理对象控制对原始对象的访问。代理对象可以拦截对目标对象的方法调用，在方法执行前后插入自定义逻辑，增强功能（如日志、事务），实现 AOP（面向切面编程）。
核心机制

JDK 动态代理：基于接口实现，要求目标类必须实现至少一个接口。
CGLIB 动态代理：基于继承实现，通过生成目标类的子类拦截方法调用。
核心类
java.lang.reflect.Proxy：生成代理实例。
java.lang.reflect.InvocationHandler：处理方法调用的拦截逻辑。





JDK的动态代理和CGLIB的动态代理有什么区别？查看答案


特性
JDK 动态代理
CGLIB 动态代理



依赖接口
必须实现接口
无需接口，基于继承


代理方式
生成实现接口的代理类
生成继承目标类的子类


性能
创建快，调用慢（反射）
创建慢，调用快（字节码）


适用场景
接口导向的框架（如 Spring AOP）
无接口的类（如 Spring 的 @Service)



JDK 动态代理示例
// 1. 定义接口interface UserService &#123;    void saveUser(String username);&#125;// 2. 实现接口class UserServiceImpl implements UserService &#123;    @Override    public void saveUser(String username) &#123;        System.out.println(&quot;Saving user: &quot; + username);    &#125;&#125;// 3. 实现InvocationHandlerclass LoggingHandler implements InvocationHandler &#123;    private final Object target;  // 目标对象        public LoggingHandler(Object target) &#123;        this.target = target;    &#125;        @Override    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123;        // 前置增强        System.out.println(&quot;Before method: &quot; + method.getName());                // 调用目标方法        Object result = method.invoke(target, args);                // 后置增强        System.out.println(&quot;After method: &quot; + method.getName());                return result;    &#125;&#125;// 4. 创建代理对象并使用public class Main &#123;    public static void main(String[] args) &#123;        UserService target = new UserServiceImpl();                // 创建代理对象        UserService proxy = (UserService) Proxy.newProxyInstance(            UserService.class.getClassLoader(),            new Class&lt;?&gt;[]&#123;UserService.class&#125;,            new LoggingHandler(target)        );                // 调用代理方法        proxy.saveUser(&quot;Alice&quot;);    &#125;&#125;



CGLIB 动态代理示例


// 1. 定义目标类（无需实现接口）class UserService &#123;    public void saveUser(String username) &#123;        System.out.println(&quot;Saving user: &quot; + username);    &#125;&#125;// 2. 实现MethodInterceptorclass LoggingInterceptor implements MethodInterceptor &#123;    @Override    public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123;        System.out.println(&quot;Before method: &quot; + method.getName());        Object result = proxy.invokeSuper(obj, args);  // 调用父类（目标类）方法        System.out.println(&quot;After method: &quot; + method.getName());        return result;    &#125;&#125;// 3. 创建代理对象public class Main &#123;    public static void main(String[] args) &#123;        Enhancer enhancer = new Enhancer();        enhancer.setSuperclass(UserService.class);  // 设置父类（目标类）        enhancer.setCallback(new LoggingInterceptor());                UserService proxy = (UserService) enhancer.create();        proxy.saveUser(&quot;Bob&quot;);    &#125;&#125;


什么是Java 的SPI 机制？查看答案SPI（Service Provider Interface） 是 Java 提供的一种服务发现机制，允许第三方实现接口并通过配置文件动态加载，它通过在运行时动态加载接口实现类，实现模块解耦和可插拔架构。SPI 的核心思想是”面向接口编程 + 约定优于配置“。

工作流程
graph TD
    A[定义服务接口] --&gt; B[创建实现类]
    B --&gt; C[配置META-INF/services文件]
    C --&gt; D[ServiceLoader加载]
    D --&gt; E[获取实现实例]

示例代码：

定义服务接口
// 服务接口public interface DataSource &#123;    Connection getConnection();&#125;

实现服务接口
// MySQL实现public class MySQLDataSource implements DataSource &#123;    @Override    public Connection getConnection() &#123;        return new MySQLConnection();    &#125;&#125;// PostgreSQL实现public class PostgreSQLDataSource implements DataSource &#123;    @Override    public Connection getConnection() &#123;        return new PostgreSQLConnection();    &#125;&#125;

配置实现类
在META-INF/services/com.example.DataSource文件中写入：
com.example.MySQLDataSourcecom.example.PostgreSQLDataSource

ServiceLoader加载并使用
ServiceLoader&lt;DataSource&gt; loader = ServiceLoader.load(DataSource.class);// 遍历所有实现for (DataSource ds : loader) &#123;    Connection conn = ds.getConnection();    // 使用连接...&#125;// 获取指定实现（需自行判断）Optional&lt;DataSource&gt; mysqlDs = loader.stream()    .filter(p -&gt; p.type().getName().contains(&quot;MySQL&quot;))    .map(ServiceLoader.Provider::get)    .findFirst();





SPI 与 API 的区别查看答案


API
SPI



应用程序编程接口：框架或库提供的功能调用接口，用于被应用程序调用。
服务提供者接口：框架定义的标准接口，允许第三方提供实现，用于框架扩展。


调用方向：应用程序→API→框架
调用方向：框架→SPI→第三方实现


示例：Java 标准库的java.util.List接口
示例：JDBC 的java.sql.Driver接口



API：你调用别人提供的功能（如使用HashMap）
.bpegvbzchxul{zoom: 67%;}

SPI：别人调用你实现的扩展（如为JDBC提供新驱动）
.rkmllhghndms{zoom: 67%;}



单例模式有几种实现方式?查看答案
饿汉式（线程安全，非懒加载）
类加载时直接初始化实例，借助 JVM 类加载机制保证线程安全（类加载过程是单线程的）。
public class HungrySingleton &#123;    // 类加载时直接实例化    private static final HungrySingleton INSTANCE =  new HungrySingleton();    //私有构造器，防止外部实例化    private HungrySingleton()&#123;&#125;;    //全局访问点    private static HungrySingleton getInstance()&#123;        return INSTANCE;    &#125;&#125;

特点：

优点：实现简单，线程安全（类加载时初始化）。
缺点：非懒加载（类加载即实例化），若实例占用资源大且长期不使用，会浪费内存。


懒汉式（线程不安全，懒加载）


   延迟初始化实例，仅在第一次调用getInstance()时创建，但多线程环境下会产生多个实例（线程不安全）。
   public class LazySingletonUnsafe &#123;    private static LazySingletonUnsafe instance;    private LazySingletonUnsafe()&#123;&#125;    // 线程不安全：多线程同时进入if判断时，会创建多个实例    private static LazySingletonUnsafe getInstance() &#123;        if (instance == null)&#123;            instance = new LazySingletonUnsafe();        &#125;        return instance;    &#125;&#125;


优点：懒加载，节省资源。
缺点：线程不安全，多线程环境下失效，实际开发中禁止使用。


懒汉式（线程安全，同步方法）
在getInstance()方法上添加synchronized关键字，强制多线程串行执行，保证线程安全。
public class LazySingletonSafeSyncMethod &#123;    private static LazySingletonSafeSyncMethod instance;    private LazySingletonSafeSyncMethod()&#123;&#125;;    // 同步方法：多线程需排队执行，保证线程安全    private static synchronized LazySingletonSafeSyncMethod getInstance()&#123;        if (instance == null)&#123;            instance = new LazySingletonSafeSyncMethod();        &#125;        return instance;    &#125;&#125;


优点：线程安全，懒加载。
缺点：synchronized修饰整个方法，并发效率低（即使实例已创建，每次调用仍需排队）。


双重检查锁（DCL，线程安全，懒加载）
public class DCLSingleton &#123;    // volatile防止指令重排：避免&quot;半初始化&quot;实例被其他线程获取    private static volatile DCLSingleton instance;    private DCLSingleton ()&#123;&#125;    public static DCLSingleton getInstance() &#123;        // 第一次判空：避免已创建实例后仍进入同步块（提高效率）        if (instance == null)&#123;            synchronized (DCLSingleton.class)&#123;                // 第二次判空：防止多线程同时通过第一次判空后，重复创建实例                if (instance == null)&#123;                    instance = new DCLSingleton();                    // 注：new操作分3步：1.分配内存 2.初始化 3.赋值给instance                    // 若不加volatile，可能发生指令重排（1→3→2），导致其他线程获取&quot;半初始化&quot;实例                &#125;            &#125;        &#125;        return instance;    &#125;&#125;

特点：

优点：懒加载，线程安全，并发效率高（仅首次创建时同步）。
关键：volatile关键字不可省略，否则可能因指令重排导致线程安全问题。


静态内部类（线程安全，懒加载）
利用 JVM “静态内部类按需加载” 的特性实现懒加载，同时借助类加载机制保证线程安全。
public class StaticInnerClassSingleton &#123;    // 静态内部类：仅在调用getInstance()时才会加载    private static class InnerClass &#123;        private static final StaticInnerClassSingleton INSTANCE = new StaticInnerClassSingleton();    &#125;        private StaticInnerClassSingleton() &#123;&#125;        public static StaticInnerClassSingleton getInstance() &#123;        return InnerClass.INSTANCE;    &#125;&#125;

原理：

外部类加载时，静态内部类不会被加载，实现懒加载。
首次调用getInstance()时，静态内部类加载，其静态变量INSTANCE初始化（JVM 保证类加载过程线程安全），确保唯一实例。特点：实现简洁，线程安全，懒加载，效率高，是推荐的实现方式之一。


枚举单例（线程安全，天然防反射 &#x2F; 序列化）
利用枚举的特性（JVM 保证枚举实例唯一且不可变）实现单例，是《Effective Java》推荐的最佳方式。
public enum EnumSingleton &#123;    INSTANCE; // 唯一实例        // 枚举可定义方法    public void doSomething() &#123;        // 业务逻辑    &#125;&#125;

特点：

优点：线程安全（JVM 保证枚举实例仅被初始化一次），天然防止反射和序列化破坏单例，实现极简。
缺点：无法懒加载（枚举类加载时即初始化实例），若实例依赖参数初始化，灵活性较低。





如何避免反射和序列化破坏单例?查看答案
反射破坏单例及解决方案
反射破坏原理：通过Class.getDeclaredConstructor()获取私有构造器，调用setAccessible(true)取消访问检查后，可多次调用newInstance()创建实例。
示例（破坏 DCL 单例）：
public class TestReflect &#123;    public static void main(String[] args) throws Exception &#123;        // 获取单例实例        DCLSingleton instance1 = DCLSingleton.getInstance();                // 反射获取私有构造器        Constructor&lt;DCLSingleton&gt; constructor = DCLSingleton.class.getDeclaredConstructor();        constructor.setAccessible(true); // 绕过私有访问限制        DCLSingleton instance2 = constructor.newInstance(); // 创建新实例                System.out.println(instance1 == instance2); // false（单例被破坏）    &#125;&#125;

解决方案：在私有构造器中添加判断，若已有实例则抛出异常，阻止重复创建。
private DCLSingleton() &#123;    // 防止反射破坏：若已有实例，抛异常    if (instance != null) &#123;        throw new RuntimeException(&quot;禁止通过反射创建实例&quot;);    &#125;&#125;

序列化破坏单例及解决方案
序列化破坏原理：单例实例序列化后写入磁盘，反序列化时会通过反射创建新实例（即使构造器私有），导致单例失效。
示例（破坏静态内部类单例）：
public class TestSerialize &#123;    public static void main(String[] args) throws Exception &#123;        // 获取单例实例        StaticInnerClassSingleton instance1 = StaticInnerClassSingleton.getInstance();                // 序列化        ObjectOutputStream oos = new ObjectOutputStream(new FileOutputStream(&quot;singleton.obj&quot;));        oos.writeObject(instance1);                // 反序列化        ObjectInputStream ois = new ObjectInputStream(new FileInputStream(&quot;singleton.obj&quot;));        StaticInnerClassSingleton instance2 = (StaticInnerClassSingleton) ois.readObject();                System.out.println(instance1 == instance2); // false（单例被破坏）    &#125;&#125;

解决方案：在单例类中重写readResolve()方法，返回已有的单例实例，覆盖反序列化生成的新对象。
public class StaticInnerClassSingleton implements Serializable &#123;    // ... 其他代码同上 ...        // 反序列化时，JVM会调用此方法，返回已有实例    private Object readResolve() &#123;        return InnerClass.INSTANCE;    &#125;&#125;

枚举单例为何天然防破坏？

防反射：JVM 对枚举的构造器做了特殊保护，反射调用newInstance()时会直接抛出IllegalArgumentException，无法创建新实例。
防序列化：枚举的序列化机制与普通类不同，反序列化时不会创建新实例，而是直接返回枚举常量（通过Enum.valueOf()获取已有实例）。





泛型Java中泛型擦除是什么？查看答案泛型擦除是 Java 泛型的核心机制，指在编译后，泛型类型参数会被擦除，替换为其上限类型（通常是Object），从而使代码在运行时不再保留泛型类型信息。




Java集合框架ArrayList 和 LinkedList 有什么区别？查看答案


维度
ArrayList
LinkedList



数据结构
动态数组
双向链表


随机访问
支持高效随机访问（O(1)）
不支持高效随机访问（O(n)）


插入 &#x2F; 删除效率
尾部插入快（O(1)），中间插入慢（O(n)）
任意位置插入 &#x2F; 删除快（O(1)，需先定位）


内存占用
连续内存空间，可能有预分配冗余
非连续内存，每个节点包含前后引用


扩容机制
自动扩容（默认增长原来的 1.5 倍）
无需扩容，按需分配节点


适用场景
频繁随机访问，较少插入删除
频繁插入删除，较少随机访问




ArrayList线程安全吗？把ArrayList变成线程安全有哪些方法？查看答案不是线程安全的，ArrayList变成线程安全的方式有：

使用Collections类的synchronizedList方法将ArrayList包装成线程安全的List：
List&lt;String&gt; synchronizedList = Collections.synchronizedList(arrayList);

使用CopyOnWriteArrayList类代替ArrayList，它是一个线程安全的List实现：
CopyOnWriteArrayList&lt;String&gt; copyOnWriteArrayList = new CopyOnWriteArrayList&lt;&gt;(arrayList);

使用Vector类代替ArrayList，Vector是线程安全的List实现：
Vector&lt;String&gt; vector = new Vector&lt;&gt;(arrayList);



说一下CopyOnWriteArrayList查看答案CopyOnWriteArrayList是Java为读多写少场景设计的线程安全列表，它通过写时复制机制避免了读操作的锁开销，实现了读写分离。但由于每次写操作都要复制数组，会带来内存和性能开销，因此适用于读密集、写较少且允许弱一致性的场景。在实际项目中，我们需要根据读写比例和一致性要求选择合适的容器。

原理
写操作：在执行add()、remove()等修改操作时，会先复制原数组，在新数组上完成修改，最后用新数组替换原数组。
读操作：直接访问原数组，无需加锁，因此读操作无阻塞。


优点：读操作高效，线程安全，迭代器弱一致性避免并发修改异常。
缺点：写操作开销大（复制数组），占用更多内存，不适合写频繁的场景。



说一下 Collections.synchronizedList查看答案Collections.synchronizedList 是 Java 提供的一个工具方法，它位于 java.util.Collections 类中。用于将普通列表（如 ArrayList、LinkedList）转换为线程安全的列表。它会对每个访问方法（如 get, set, add, remove）进行同步（加 synchronized 锁），从而保证线程安全。


CopyOnWriteArrayList和Collections.synchronizedList的区别查看答案


特性
Collections.synchronizedList
CopyOnWriteArrayList



实现方式
同步包装器，使用 synchronized
写时复制（Copy-On-Write）


锁粒度
全局锁（所有操作串行化）
无锁读，写操作加锁


读性能
低（需获取锁）
高（无需锁）


写性能
中（仅需获取锁）
低（需复制数组）


迭代器安全性
不安全，需手动同步
安全（基于快照）


适用场景
读写频率相近，且需要弱一致性
读多写少，且允许弱一致性




ArrayList的扩容机制？查看答案当往 ArrayList 中添加元素时，会先检查是否需要扩容，如果当前容量+1 超过数组长度，就会进行扩容。
扩容后的新数组长度是原来的 1.5 倍，然后再把原数组的值拷贝到新数组中。


说一下HashMap的底层数据结构查看答案HashMap 的底层是数组 + 链表 + 红黑树的复合结构（JDK1.7之前是数组 + 链表 ）。

数组是主体，每个元素是一个桶；当发生哈希冲突时，冲突的元素会形成链表；
当链表长度超过 8 且数组长度 ≥64 时，链表会转换为红黑树以提升查询效率。
这种设计平衡了空间和时间复杂度，既避免了开放寻址法的扩容开销，又通过树化优化了链表过长的问题。
在 JDK 8 中，插入方式从头插法改为尾插法，避免了多线程环境下的链表成环问题，但仍不保证线程安全。



哈希冲突解决方法有哪些？查看答案
拉链法（链地址法）：每个哈希桶中维护一个链表（或其他数据结构），冲突的元素都存入该链表。
链表法：
原理：JDK 7 及以前的 HashMap 采用此方法。当冲突发生时，将元素插入链表头部（头插法）。
优点：实现简单，无需扩容整个哈希表，适用于冲突频繁的场景。
缺点：链表过长时查询效率为 O (n)。


链表 + 红黑树：
原理：JDK 8 后的 HashMap 优化：当链表长度超过阈值（8）且哈希表容量 ≥64 时，将链表转换为红黑树（查询效率 O (log n)）。
优点：高效处理大量冲突，避免链表过长导致的性能问题。




再哈希法：当发生冲突时，使用另一个哈希函数再次计算键的哈希值，直到找到一个空槽来存储键值对。
开放寻址法：当发生冲突时，直接在哈希表中寻找下一个空闲位置。常见的开放寻址方法包括线性探测、二次探测和双重散列。



HashMap和HashTable的区别查看答案
线程安全：HashMap 非线程安全，HashTable 线程安全（但性能差，推荐用 ConcurrentHashMap）。
空值支持：HashMap 允许 null 键和 null 值，HashTable 不允许。
历史设计：HashMap 继承自 AbstractMap，HashTable 继承自 Dictionary（已过时）。
容量与扩容：HashMap 初始容量 16 且必须为 2 的幂，HashTable 初始 11，扩容为 2n+1。
性能：HashMap 单线程性能更高，HashTable 因全局锁性能较差。


在实际开发中，优先使用 HashMap，仅在需要线程安全时考虑 ConcurrentHashMap，避免使用 HashTable。



ConcurrentHashMap和HashTable的区别查看答案
锁机制：ConcurrentHashMap 在 JDK 8 采用 CAS + synchronized 锁定桶节点，并发度更高；HashTable 使用全局锁。
性能：ConcurrentHashMap 读无锁，写仅锁冲突节点，性能远优于 HashTable。
数据结构：JDK 8 的 ConcurrentHashMap 采用数组+链表+红黑树；HashTable与 HashMap 一致，但所有操作同步。
空值支持：两者均不允许 null 键值。
迭代器：ConcurrentHashMap 弱一致性，不抛异常；HashTable 可能抛出 ConcurrentModificationException。


在实际开发中，强烈推荐使用 ConcurrentHashMap 替代 HashTable，尤其在高并发场景下，其性能优势显著。



HashSet和HashMap的区别查看答案
接口与功能：HashSet 实现 Set 接口，存储唯一元素；HashMap 实现 Map 接口，存储键值对。
底层实现：HashSet 依赖 HashMap，将元素作为 key 存储，value 固定为 PRESENT。
null 支持：两者均允许 1 个 null 键（HashSet 的 null 元素），但 HashMap 还允许多个 null 值。
应用场景：HashSet 用于去重和存在性检查，HashMap 用于键值映射。


在实际开发中，若只需存储不重复元素，选择 HashSet；若需键值关联，选择 HashMap。



HashMap的put流程查看答案
计算 key 的哈希值（高 16 位与低 16 位异或），减少哈希冲突。
static final int hash(Object key) &#123;    int h;    return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;//确定桶位置。index = (n - 1) &amp; hash // n 为数组长度，必须是 2 的幂次方

若数组未初始化，先进行扩容（初始容量 16）。

通过哈希值和数组长度取模确定桶位置。

处理桶内节点：

若桶为空，直接插入新节点。
若首节点 key 匹配，覆盖旧值。
若是树节点，调用树插入逻辑。
若是链表，遍历链表：
找到相同 key 则覆盖。
未找到则链尾插入，若链表长度 ≥8 且数组长度 ≥64，将链表转换为红黑树。




插入后检查元素数量是否超过阈值（容量 × 加载因子），超过则扩容。



JDK 8 对 put 方法进行了优化，采用尾插法避免多线程下的链表成环问题，并通过红黑树优化了链表过长时的性能。



HashMap的扩容机制查看答案
当元素数量超过阈值（capacity * loadFactor）即 容量（初始化16） * 负载因子（默认 0.75） 时，触发扩容。

创建一个新的数组，容量为原来的2倍，并重新计算阈值。
newCap = oldCap &lt;&lt; 1（例如，16 → 32）。

数据迁移

通过 hash &amp; oldCap 将节点分为两类：结果为 0 则留在原索引，否则移至原索引+oldCap。
JDK 8 优化：将链表拆分为低位链和高位链，避免链表反转，提高效率。


树化与反树化

若链表长度 ≥8 且容量 ≥64，转换为红黑树。
扩容后若树节点数 ≤6，红黑树退化为链表。





讲讲 LinkedHashMap查看答案LinkedHashMap 是 HashMap 的子类，它在哈希表的基础上增加了双向链表，用于维护元素的插入顺序或访问顺序。
LinkedHashMap 在 HashMap 的基础上维护了一个双向链表，通过 before 和 after 标识前置节点和后置节点。


讲讲TreeMap查看答案TreeMap 是基于红黑树实现的有序 Map，主要特点如下：1. **键有序**：   - 自然顺序：键必须实现 Comparable 接口。   - 自定义顺序：通过构造函数传入 Comparator。2. **核心数据结构**：   - 红黑树：自平衡二叉搜索树，确保操作的时间复杂度为 O(log n)。   - 每个节点包含颜色属性，通过旋转和变色维持平衡。3. **导航方法**：   - 提供 ceilingKey、floorKey 等方法，高效查找相邻键。   - 支持子Map操作，返回指定范围的视图。4. **适用场景**：   - 需要按键排序的场景（如时间范围查询、数值区间统计）。   - 需频繁查找相邻元素的场景。


讲讲ConcurrentHashMap查看答案ConcurrentHashMap 是 Java 提供的线程安全哈希表，主要特点如下：

JDK 8 优化：  
数据结构：数组 + 链表 + 红黑树，与 HashMap 一致。   
锁机制：抛弃JDK1.7之前使用的分段锁，采用 CAS + synchronized 锁定桶头节点，并发度更高。


核心优势：  
高效并发：读操作无锁，写操作仅锁冲突的桶，性能远优于 HashTable。
弱一致性：迭代器不抛出 ConcurrentModificationException，允许遍历期间修改。


原子操作：
提供 putIfAbsent、computeIfAbsent 等原子方法，避免复合操作的竞态条件。


适用场景：
高并发读写场景（如缓存、计数器）。
需线程安全但不希望使用全局锁的场景。




 相比 HashTable，ConcurrentHashMap 的锁粒度更小，读操作无锁，性能显著提升；相比 Collections.synchronizedMap，它提供了更丰富的原子方法和更高的并发度。



ConcurrentHashMap 为什么 key 和 value 不能为 null？查看答案
避免歧义：
在并发场景下，若允许 null，当 get(key) 返回 null 时，无法区分是 key 不存在还是 value 为 null，可能导致逻辑错误。


原子操作的语义：
原子方法（如 putIfAbsent）依赖返回值判断操作结果。若允许 null，返回 null 无法明确是插入成功还是 key 已存在，破坏原子性。


并发复杂性：
弱一致性迭代器难以处理 null 值的语义，增加实现复杂度。




相比之下，HashMap 允许 null 是为了单线程下的灵活性，但在并发环境中，这种灵活性会带来安全隐患。因此，ConcurrentHashMap 选择严格设计，强制用户处理 null 的情况，避免潜在问题。

































]]></content>
      <categories>
        <category>面试题</category>
        <category>Java 面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title>SpringBoot面试题</title>
    <url>/2025/07/02/Interview/SpringBoot%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[SpringBoot面试题什么是Spring Boot？有哪些优点？Spring Boot 是基于 Spring 框架的快速开发脚手架，它的核心目标是 “简化 Spring 应用的开发、配置和部署流程”。它并非替代 Spring，而是通过 “约定大于配置” 的设计理念，整合 Spring 生态的底层能力（如 IOC、AOP），解决传统 Spring 开发中 “配置繁琐、依赖冲突、部署复杂” 等痛点，让开发者能更专注于业务逻辑，快速搭建可直接运行的生产级应用。

自动配置，减少冗余配置
传统 Spring 开发需要手动写大量 XML 或注解配置（比如配置数据源、MVC 映射等），而 Spring Boot 会根据引入的依赖（如引入spring-boot-starter-web）自动推断并配置相关组件（如 Tomcat、DispatcherServlet），无需手动干预，大幅减少配置工作量。

起步依赖，解决依赖管理难题
传统开发中，需要手动引入多个相关依赖（如 Web 开发需手动加spring-web、tomcat等），还可能因版本不兼容导致冲突。Spring Boot 将常用依赖打包成 “starter”（如starter-web、starter-jpa），引入一个 starter 即可自动获取所有相关依赖及适配版本，避免版本冲突。

嵌入式服务器，简化部署流程
默认集成 Tomcat、Jetty 等嵌入式服务器，无需单独安装和配置外部服务器，应用可直接打包成 Jar 包，通过java -jar命令启动，部署流程从 “部署 war 包到服务器” 简化为 “一行命令启动”，极大降低部署成本。

开发效率高，支持快速迭代
内置热部署（如spring-boot-devtools），修改代码后无需重启应用即可生效；同时提供自动配置的监控（如 Actuator）、日志等基础能力，开发者无需从零搭建，能快速聚焦业务开发。

无缝兼容 Spring 生态，学习成本低
完全继承 Spring 的核心功能（IOC、AOP 等），熟悉 Spring 的开发者能快速上手；同时兼容 Spring Cloud 等微服务组件，适合微服务架构开发，无需额外学习新框架。

简化测试，支持开箱即用的测试工具
集成spring-boot-starter-test，内置 JUnit、Mockito 等测试工具，无需手动配置测试环境，可直接编写单元测试、集成测试，降低测试门槛。


说说Spring Boot的启动流程sequenceDiagram
    participant Main as main()
    participant SA as SpringApplication
    participant AC as ApplicationContext
    participant RS as Runner
    
    Main-&gt;&gt;SA: SpringApplication.run()
    SA-&gt;&gt;SA: 初始化阶段
    SA-&gt;&gt;AC: 创建应用上下文
    AC-&gt;&gt;AC: 准备阶段
    AC-&gt;&gt;AC: 刷新阶段（核心）
    AC-&gt;&gt;RS: 执行Runner
    AC--&gt;&gt;Main: 返回ApplicationContext


启动入口：SpringApplication.run()
一切从main方法调用SpringApplication.run()开始：
@SpringBootApplicationpublic class MyApp &#123;    public static void main(String[] args) &#123;        SpringApplication.run(MyApp.class, args);    &#125;&#125;

这个静态方法会：

创建SpringApplication实例
调用其run()方法开始启动流程


SpringApplication实例化（初始化准备）
SpringApplication.run()方法首先会创建SpringApplication实例，此过程主要完成基础配置初始化，具体包括：

判断应用类型：根据类路径（classpath）是否存在Servlet、Reactive相关类，确定应用类型（如SERVLET、REACTIVE），后续将创建对应类型的ApplicationContext。
加载初始化器（Initializer）：从META-INF/spring.factories中加载所有ApplicationContextInitializer（上下文初始化器），用于在上下文刷新前对其进行自定义配置（如设置环境变量、注册 Bean 等）。
加载监听器（Listener）：同样从META-INF/spring.factories中加载所有ApplicationListener（应用监听器），用于监听启动过程中的各种事件（如环境准备完成、上下文刷新完成等），实现扩展逻辑。
确定主应用类：通过main方法所在的类，定位主应用类（即标注@SpringBootApplication的类）。


run()方法执行（容器启动核心流程）
SpringApplication实例创建后，调用其run(args)方法，开始容器启动，核心步骤如下：

步骤 1：启动计时器与发布启动事件

启动计时器（StopWatch），用于记录启动耗时。
发布ApplicationStartingEvent事件（启动开始），所有监听器可响应此事件（如初始化日志系统）。


步骤 2：准备环境（Environment）

创建并配置 Environment（环境对象），包含：

整合命令行参数（args）、系统变量、环境变量、配置文件（application.yml/properties）等配置源。
激活指定的配置文件（如spring.profiles.active=dev）。


发布ApplicationEnvironmentPreparedEvent事件（环境准备完成），监听器可在此阶段修改环境配置（如动态添加配置）。



步骤 3：打印 Banner（可选）

读取banner.txt（默认在classpath下），打印启动图案（可通过spring.banner.location自定义，或关闭spring.main.banner-mode=off）。


步骤 4：创建 ApplicationContext（应用上下文）

根据之前判断的应用类型，创建对应的ApplicationContext（如 Servlet 应用对应AnnotationConfigServletWebServerApplicationContext）。
为上下文设置环境（Environment）、注册主应用类为配置类。


步骤 5：准备 ApplicationContext（上下文预处理）

应用初始化器（ApplicationContextInitializer）：调用所有初始化器的initialize(context)方法，对上下文进行预处理（如注册 BeanDefinition、设置上下文属性）。
发布ApplicationContextInitializedEvent事件（上下文初始化完成）。
注册特殊 Bean：如将命令行参数args封装为CommandLineArgs对象并注册到容器。


步骤 6：刷新 ApplicationContext（核心中的核心）
此步骤复用了 Spring Framework 的AbstractApplicationContext.refresh()逻辑，是容器初始化的核心，主要包括：

BeanFactory 初始化：创建DefaultListableBeanFactory作为 Bean 容器。
加载 Bean 定义：扫描主类所在包及子包（基于@ComponentScan），解析@Component、@Service等注解的类，将其注册为BeanDefinition（Bean 定义）。
执行自动配置：通过@EnableAutoConfiguration触发，从META-INF/spring.factories加载AutoConfiguration类，根据条件（@Conditional）注册符合条件的 Bean（如数据源、Web 服务器等）。
初始化非懒加载单例 Bean：实例化并初始化所有非懒加载的单例 Bean（依赖注入在此阶段完成）。
启动嵌入式服务器：对于 Web 应用，会触发ServletWebServerFactory（如TomcatServletWebServerFactory）的 Bean，创建并启动嵌入式服务器（Tomcat&#x2F;Netty 等）。
发布ContextRefreshedEvent事件（上下文刷新完成）。


步骤 7：刷新后处理

执行 ApplicationRunner 和 CommandLineRunner ：容器刷新完成后，自动调用所有实现这两个接口的 Bean 的run()方法，用于执行启动后的初始化逻辑（如数据加载、缓存预热）。

区别：ApplicationRunner接收ApplicationArguments（包装后的参数），CommandLineRunner接收原始String[] args。




步骤 8：启动完成

发布ApplicationStartedEvent（容器启动完成）和ApplicationReadyEvent（应用可接收请求）事件。
停止计时器，打印启动耗时。
返回创建好的ApplicationContext，应用正式启动完成。





讲述一下 SpringBoot 自动装配原理自动装配可以简单理解为：通过注解或者一些简单的配置就能在 Spring Boot 的帮助下实现某块功能。
SpringBoot 自动装配的核心是： 

基于 SPI 机制：通过spring.factories发现候选配置类。 
条件化加载：使用@Conditional系列注解动态决定配置类是否生效。 
可覆盖设计：默认配置可被用户自定义配置轻松替换。

一、核心设计思想传统 Spring 开发需要手动配置大量 Bean（如数据源、WebMvc 配置），而 SpringBoot 通过自动装配实现：

无配置启动：只需添加 starter 依赖（如spring-boot-starter-web），无需 XML 或 JavaConfig，应用即可自动配置并启动。
条件化装配：根据类路径（Classpath）中存在的类、配置属性等条件，动态决定是否加载某个配置。
可定制化：自动配置并非强制，用户可通过自定义 Bean 或配置文件覆盖默认配置。

二、实现机制：基于 SPI 的自动发现SpringBoot 的自动装配基于 Java 的服务发现机制（SPI, Service Provider Interface），核心流程如下：
1. 启动入口：@SpringBootApplication注解主类上的@SpringBootApplication是自动装配的起点，它是一个组合注解：
@SpringBootApplicationpublic class DemoApplication &#123; ... &#125;// 等价于以下三个注解@SpringBootConfiguration  // 等价于@Configuration@EnableAutoConfiguration  // 开启自动装配核心@ComponentScan            // 扫描@Component及其子注解（@Service、@Repository等）

2. 核心注解：@EnableAutoConfiguration这个注解导入了AutoConfigurationImportSelector类，负责加载自动配置类：
@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; ... &#125;

3. 自动配置类加载：spring.factoriesAutoConfigurationImportSelector会从META-INF/spring.factories（Spring Boot 2.7+ 以后从 META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports）文件中读取所有自动配置类：
# spring-boot-autoconfigure-*.jar/META-INF/spring.factoriesorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.web.servlet.WebMvcAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\...

每个自动配置类（如WebMvcAutoConfiguration）都是一个完整的 JavaConfig，包含多个 Bean 定义。
三、条件化装配：@Conditional注解自动配置类并非一定会生效，而是通过@Conditional及其衍生注解进行条件判断：



注解
作用场景



@ConditionalOnClass
当类路径中存在指定类时生效


@ConditionalOnMissingClass
当类路径中不存在指定类时生效


@ConditionalOnBean
当容器中存在指定 Bean 时生效


@ConditionalOnMissingBean
当容器中不存在指定 Bean 时生效


@ConditionalOnProperty
当配置文件中存在指定属性且值符合条件时生效


@ConditionalOnWebApplication
当应用是 Web 应用时生效


示例：DataSourceAutoConfiguration中的条件装配
@Configuration(proxyBeanMethods = false)@ConditionalOnClass(&#123; DataSource.class, EmbeddedDatabaseType.class &#125;)@ConditionalOnMissingBean(DataSource.class)@ConditionalOnProperty(prefix = &quot;spring.datasource&quot;, name = &quot;url&quot;, matchIfMissing = false)public class DataSourceAutoConfiguration &#123;    // 仅当类路径存在DataSource和EmbeddedDatabaseType    // 且容器中没有手动配置DataSource Bean    // 且配置文件中存在spring.datasource.url属性时，此配置才生效&#125;

四、自定义与覆盖机制自动配置提供默认实现，但用户可通过以下方式覆盖：
1. 自定义 Bean在@Configuration类中手动定义 Bean，会优先于自动配置中的 Bean：
@Configurationpublic class MyConfig &#123;    @Bean    public DataSource dataSource() &#123;        // 自定义数据源，覆盖自动配置的数据源        return new MyDataSource();    &#125;&#125;

2. 配置文件属性通过application.properties或application.yml修改默认配置：
spring:  datasource:    url: jdbc:mysql://localhost:3306/mydb  # 覆盖自动配置的数据库连接URL    username: root    password: secret

3. 排除特定自动配置类在@SpringBootApplication中排除不需要的自动配置：
@SpringBootApplication(exclude = &#123;DataSourceAutoConfiguration.class&#125;)public class DemoApplication &#123; ... &#125;

五、自动配置执行流程
启动入口：SpringApplication.run()触发自动装配流程。
加载自动配置类：AutoConfigurationImportSelector从spring.factories读取候选配置类。
筛选有效配置类：通过@Conditional注解过滤不符合条件的配置类。
加载有效配置类：将符合条件的配置类注册到 Spring 容器，完成 Bean 的自动装配。

如何自定义一个 SpringBoot Srarter?一、Starter 的核心组成一个完整的 Starter 通常包含 3 部分：

自动配置模块：包含@Configuration配置类，负责自动装配 Bean。
配置属性类：通过@ConfigurationProperties绑定用户配置（如application.properties中的属性）。
META-INF&#x2F;spring.factories：注册自动配置类，让 SpringBoot 启动时能扫描到。

二、自定义 Starter 的步骤（以 “demo-starter” 为例）步骤 1：创建 Starter 项目（Maven&#x2F;Gradle）推荐使用 Maven，项目结构如下：
demo-spring-boot-starter/├── src/│   ├── main/│   │   ├── java/│   │   │   └── com/│   │   │       └── demo/│   │   │           ├── config/          // 自动配置类│   │   │           └── properties/     // 配置属性类│   │   └── resources/│   │       └── META-INF/│   │           ├── spring.factories    // 注册自动配置│   │           └── spring-configuration-metadata.json  // 配置元数据（可选，用于IDE提示）│   └── test/└── pom.xml

步骤 2：配置 pom.xml 依赖核心依赖包括：

spring-boot-autoconfigure：提供自动配置基础能力。
spring-boot-configuration-processor：可选，用于生成配置元数据（IDE 会提示配置项）。

&lt;dependencies&gt;    &lt;!-- 自动配置核心依赖 --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;        &lt;version&gt;2.7.0&lt;/version&gt; &lt;!-- 与目标SpringBoot版本一致 --&gt;    &lt;/dependency&gt;    &lt;!-- 配置元数据生成器（可选，提升用户体验） --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;        &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt;        &lt;version&gt;2.7.0&lt;/version&gt;        &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 避免传递依赖 --&gt;    &lt;/dependency&gt;    &lt;!-- starter需要的核心功能依赖（例如，假设我们的starter提供一个简单的服务） --&gt;    &lt;dependency&gt;        &lt;groupId&gt;org.projectlombok&lt;/groupId&gt;        &lt;artifactId&gt;lombok&lt;/artifactId&gt;        &lt;version&gt;1.18.24&lt;/version&gt;        &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 若用户可能已引入，标记为可选 --&gt;    &lt;/dependency&gt;&lt;/dependencies&gt;

注意：

避免引入不必要的依赖，防止版本冲突（使用optional=true控制传递）。
Starter 命名规范：官方建议第三方 Starter 命名为xxx-spring-boot-starter（区分官方的spring-boot-starter-xxx）。

步骤 3：定义配置属性类（绑定用户配置）通过@ConfigurationProperties将用户在application.properties中的配置（如demo.prefix）绑定到 Java 类，供自动配置类使用。
// com.demo.properties.DemoProperties.java@Data@ConfigurationProperties(prefix = &quot;demo&quot;) // 配置前缀public class DemoProperties &#123;    // 默认值：若用户未配置，使用该值    private String prefix = &quot;defaultPrefix&quot;;    private boolean enabled = true; // 是否启用功能&#125;

用户使用时可在配置文件中自定义：
# application.propertiesdemo.prefix=myPrefixdemo.enabled=true

步骤 4：编写自动配置类（核心逻辑）自动配置类负责根据条件（如@Conditional）装配 Bean，依赖步骤 3 的配置属性。
// com.demo.config.DemoAutoConfiguration.java@Configuration@EnableConfigurationProperties(DemoProperties.class) // 启用配置属性类@ConditionalOnProperty(prefix = &quot;demo&quot;, name = &quot;enabled&quot;, havingValue = &quot;true&quot;, matchIfMissing = true)// 条件：当demo.enabled=true时生效（默认生效）public class DemoAutoConfiguration &#123;    private final DemoProperties properties;    // 注入配置属性    public DemoAutoConfiguration(DemoProperties properties) &#123;        this.properties = properties;    &#125;    // 自动装配核心Bean：仅当容器中没有该Bean时才自动配置（允许用户自定义覆盖）    @Bean    @ConditionalOnMissingBean    public DemoService demoService() &#123;        return new DemoService(properties.getPrefix());    &#125;&#125;// 核心功能类public class DemoService &#123;    private final String prefix;    public DemoService(String prefix) &#123;        this.prefix = prefix;    &#125;    public String doSomething(String input) &#123;        return prefix + &quot;:&quot; + input;    &#125;&#125;


关键注解说明：

@Configuration：标记为配置类。
@EnableConfigurationProperties：使DemoProperties生效，可被注入。
@ConditionalOnProperty：根据配置属性决定是否启用配置。
@ConditionalOnMissingBean：若用户手动定义了DemoService，则不使用自动配置的 Bean（允许覆盖）。


步骤 5：注册自动配置类（spring.factories）SpringBoot 启动时会通过 SPI 机制扫描META-INF/spring.factories，因此需要在此文件中注册自动配置类。
创建src/main/resources/META-INF/spring.factories：
# 格式：key为EnableAutoConfiguration的全路径，value为自动配置类的全路径（多个用逗号分隔）org.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.demo.config.DemoAutoConfiguration

步骤 6：生成配置元数据（提升用户体验）若引入了spring-boot-configuration-processor，编译时会自动生成META-INF/spring-configuration-metadata.json，IDE（如 IDEA）会根据该文件提示配置项（如demo.prefix的说明）。
如需自定义元数据（如描述），可创建src/main/resources/META-INF/additional-spring-configuration-metadata.json：
&#123;  &quot;properties&quot;: [    &#123;      &quot;name&quot;: &quot;demo.prefix&quot;,      &quot;type&quot;: &quot;java.lang.String&quot;,      &quot;description&quot;: &quot;功能前缀，用于拼接输出内容。&quot;,      &quot;defaultValue&quot;: &quot;defaultPrefix&quot;    &#125;,    &#123;      &quot;name&quot;: &quot;demo.enabled&quot;,      &quot;type&quot;: &quot;java.lang.Boolean&quot;,      &quot;description&quot;: &quot;是否启用demo功能。&quot;,      &quot;defaultValue&quot;: true    &#125;  ]&#125;

步骤 7：打包发布执行mvn clean install，将 Starter 安装到本地仓库（或发布到私服），供其他项目引入。
三、测试自定义 Starter创建一个测试项目， pom.xml 文件中引入自定义 Starter 依赖，验证自动配置是否生效。
1.  pom.xml 文件中引入依赖&lt;dependency&gt;    &lt;groupId&gt;com.demo&lt;/groupId&gt;    &lt;artifactId&gt;demo-spring-boot-starter&lt;/artifactId&gt;    &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt;

2. 编写测试代码在application.properties 配置文件中配置：
demo.prefix=myPrefixdemo.enabled=true

测试类中：
@SpringBootTestpublic class DemoStarterTest &#123;    @Autowired    private DemoService demoService; // 自动注入Starter中的Bean    @Test    public void testDoSomething() &#123;        String result = demoService.doSomething(&quot;test&quot;);        //用户在 中配置了demo.prefix=myPrefix，结果应为&quot;myPrefix:test&quot;        //未配置 则输出 &quot;defaultPrefix:test&quot;        System.out.println(result);     &#125;&#125;

3. 验证覆盖机制手动定义DemoService，验证是否覆盖自动配置：
@Configurationpublic class TestConfig &#123;     // 若用户手动定义了`DemoService`，则不使用自动配置的 Bean（允许覆盖）。    @Bean    public DemoService customDemoService() &#123;        return new DemoService(&quot;customPrefix&quot;); // 自定义Bean    &#125;&#125;

测试结果应为customPrefix:test，说明覆盖生效。
四、总结自定义 Starter 的核心流程是：

定义配置属性：通过@ConfigurationProperties绑定用户配置。
编写自动配置类：用@Conditional控制 Bean 的装配条件，支持用户覆盖。
注册配置类：通过spring.factories让 SpringBoot 扫描到。

]]></content>
      <categories>
        <category>面试题</category>
        <category>Spring Boot面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL面试题</title>
    <url>/2025/06/23/Interview/MySQL%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[MySQL面试题
此笔记为本人备考面试时整理，内容多源于网络搜集，仅作后续查阅之用，无盈利意图。若有侵权，请联系删除。
参考资料：
https://javaguide.cn/
https://www.xiaolincoding.com/
https://pdai.tech
https://javabetter.cn/

一、MySQL基础1、数据库三大范式查看答案
1NF 要求字段值必须是不可再分的原子值。
反例：用户信息表中地址字段存储 “北京市海淀区”，未拆分为省、市、区，违反 1NF；正例：拆分为province、city、district，每个字段独立存储。

2NF 1NF的基础上，要求非主属性完全依赖主键，避免部分依赖（如订单明细拆分）。
场景：订单明细表（（订单号+商品ID为主键）+ 金额 ），若字段订单金额仅依赖订单号，则存在部分依赖（非主属性订单金额不依赖商品ID），违反 2NF；优化：拆分为订单表（订单号、金额）和订单明细表（订单号、商品 ID、数量）。

3NF 2NF的基础上，非主键字段之间不能有依赖关系，消除传递依赖，如学生表与班级表分离。
反例：学生表（学生 ID，姓名，班级 ID，班级地址）中，班级地址依赖班级ID，形成 “学生 ID→班级 ID→班级地址” 的传递依赖，违反 3NF；优化：拆分为学生表（学生 ID，姓名，班级 ID）和班级表（班级 ID，班级地址）。




2、char 和 varchar 的区别是什么？查看答案


特性
CHAR
VARCHAR



存储方式
固定长度
可变长度


空间占用
始终占用定义长度（可能浪费）
仅占用实际数据长度 + 长度标识


存储开销
无额外开销
额外1~2字节存储长度


查询速度
更快（固定长度直接定位）
稍慢（需计算位置）


适用场景
长度固定的短字符串（如MD5）
长度变化大的字符串（如地址）


空格处理
存入时补足空格，查询时去除
原样存储和返回



CHAR 是定长分配，适合存储固定长度短字符串（如验证码），查询更快但可能浪费空间；
VARCHAR 是变长存储，适合长度不确定的数据（如用户名），空间利用率高但需额外长度标识。



3、varchar (100)和 varchar (10)的区别是什么？查看答案1. 存储机制
两者相同点：
都是可变长度字符串类型
实际存储空间 &#x3D; 字符数 + 长度标识字节（1-2字节）
存储”Hello”时都占用 5 字节 + 1 字节开销 &#x3D; 6 字节存储相同的字符串，所占用磁盘的存储空间其实是一样的


差异：
varchar (100) 最多存储100字符
varchar (10) 最多存储10字符



2. 性能影响
内存分配：
排序操作时，数据库可能按最大长度分配内存
VARCHAR(100) 的列可能比 VARCHAR(10) 多消耗 10 倍内存


索引效率：
索引大小：VARCHAR(100) 索引大约是 VARCHAR(10) 索引的 10 倍




适用场景：
varchar(10)：短文本（如验证码、商品编码前几位）；
varchar(100)：较长文本（如用户名、文章标题、地址片段）。





4、in和exists的区别？查看答案IN 运算符先执行子查询，将结果缓存到临时表，然后检查主查询的值是否在这个临时表中。
exists 运算符对于主查询的每一行，都会执行一次子查询检查是否存在匹配记录
区别


特性
IN
EXISTS



工作原理
检查值是否在结果集中
检查子查询是否返回任何行


执行顺序
先执行子查询，再执行主查询
主查询的每一行都执行子查询


性能特点
子查询结果集小时高效
主查询结果集小时高效


NULL 处理
NULL IN (结果集) 总是返回 UNKNOWN
不受子查询中 NULL 值影响


适用场景
静态值列表或小型结果集
关联子查询或大型结果集


可读性
更直观，易于理解
对初学者稍复杂




5、怎么存储 emoji?查看答案因为 emoji（😊）是 4 个字节的 UTF-8 字符，而 MySQL 的 utf8 字符集只支持最多 3 个字节的 UTF-8 字符，所以在 MySQL 中存储 emoji 时，需要使用 utf8mb4 字符集。
ALTER TABLE mytable CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci;

MySQL 8.0 已经默认支持 utf8mb4 字符集，可以通过 SHOW VARIABLES WHERE Variable_name LIKE &#39;character\_set\_%&#39; OR Variable_name LIKE &#39;collation%&#39;; 查看。


6、drop、delete 与 truncate 的区别？查看答案DELETE 支持行级删除，可以带 WHERE 条件，可以回滚。
DROP 是物理删除，用来删除整张表，包括表结构，且不能回滚。
TRUNCATE 用于清空表中的所有数据，但会保留表结构，不能回滚。


7、UNION 与 UNION ALL 的区别？查看答案UNION 会自动去除合并后结果集中的重复行。UNION ALL 不会去重，会将所有结果集合并起来。


8、count(1)、count(*) 与 count(列名) 的区别？查看答案
count(*)：


count(*)会统计结果集中所有行的数量，包括所有列，不忽略任何行，即使某些列包含NULL值。
它是一个标准的SQL函数，用于统计表中的总行数。


count(1)：


count(1)中的1是一个常量值，表示对每一行进行计数。
由于常量值永远不为NULL，因此count(1)实际上与count(*)一样计算所有行。
在MySQL中，优化器通常会将count(1)优化为与count(*)相同的执行计划。


count(列名)：


count(列名)会统计结果集中指定列非NULL值的数量。
如果列中的所有值都是非空的，那么count(列名)的结果与count(*)的结果相同。
但是，如果列中有空值（NULL），那么count(列名)的结果会小于count(*)的结果。



9、NULL 和 ‘ ‘ 的区别是什么？查看答案1. 本质含义
NULL：表示 “值不存在”或“未知”，相当于 “无值”。它不是空字符串，也不是数字 0，而是一个特殊的标记。
如果列允许 NULL 且未指定默认值，则插入时默认为 NULL。

&#39;&#39;（空字符串）：表示 “空值”，是一个长度为 0 的有效字符串，明确表示 “这里有一个空字符串”。
需要显式设置默认值为 &#39;&#39;（例如：ALTER TABLE tbl MODIFY col VARCHAR(10) DEFAULT &#39;&#39;;）。


2. 存储空间
NULL：通常需要额外 1 位（bit）来标记字段是否为 NULL（对于允许 NULL 的列）。

&#39;&#39;：
取决于存储引擎和字符集。例如：

在 UTF-8 中，&#39;&#39; 占用 0 字节；
在 varchar 中，可能需要 1~2 字节存储长度信息（即使长度为 0）。



3. 查询与比较
**NULL**：

不能用 = 直接比较，必须用 IS NULL 或 IS NOT NULL。
WHERE column IS NULL;  -- 正确WHERE column = NULL;   -- 错误！永远返回 false

在聚合函数（如 COUNT()、SUM()）中会被忽略（除非用 COUNT(*)）。



**&#39;&#39;**：

可以用 = 直接比较。
WHERE column = &#x27;&#x27;;  -- 正确

在聚合函数中会被视为有效值。




关键判断标准：如果某字段必须有值（即使是空），用 &#39;&#39;；如果可能无需赋值，用 NULL。


10、mysql 的深度分页如何优化查看答案深度分页是指当查询结果集很大时（如 LIMIT 1000000, 10），MySQL 需要扫描大量数据才能返回少量结果的性能问题场景。
方案1：游标分页
原理：记录上一页最后一条数据的 标识（如 ID），用 WHERE 代替 OFFSET。

-- 第1页：初始查询SELECT * FROM t ORDER BY id LIMIT 10; -- 记最后一条 ID 为 last_id  -- 第2页：基于游标SELECT * FROM t WHERE id &lt; last_id ORDER BY id DESC LIMIT 10; 


优点：

时间复杂度 O(1)
无性能衰减
支持高并发


限制：

只能顺序翻页，不能跳页，适合 APP 滚动加载。
需有序且唯一的列（如自增ID、时间戳）



方案2：覆盖索引 + 延迟关联
原理：利用索引先获取主键（减少扫描量），再回表取全字段。
SELECT * FROM ordersINNER JOIN (    SELECT id FROM orders    ORDER BY create_time DESC    LIMIT 1000000, 10  -- 索引覆盖扫描) AS tmp USING(id);-- USING(id) 等价于 ON table1.id = table2.id 

优化效果：

索引扫描代替全表扫描
减少回表数据量
性能提升 5-10 倍



方案3：范围分页
原理：通过 WHERE 条件缩小扫描范围
SELECT * FROM t WHERE create_time BETWEEN &#x27;2025-01-01&#x27; AND &#x27;2025-01-31&#x27; ORDER BY id LIMIT 10;

适用场景：

时间范围明确的数据
分区表的分区键查询





11、你知道哪些方法来优化 SQL？查看答案
针对性建索引：为 WHERE、JOIN、GROUP BY、ORDER BY 后的字段建索引（这些是查询的过滤、关联、排序核心）。
联合索引遵循 “最左前缀原则”：将区分度高的字段放在前面（如 INDEX (age, name) 可优化 age=30 AND name=&#39;张三&#39;，但不能优化 name=&#39;张三&#39;）。
避免索引失效：
索引列不参与函数 &#x2F; 计算（如 SUBSTR(name,1,1)=&#39;张&#39; 会失效，改用 name LIKE &#39;张%&#39;）；
避免 OR 连接非索引字段、字符串不加引号（如 phone=13800138000 若 phone 是字符串会隐式转换）；
控制索引数量（单表建议不超过 5-8 个，避免影响增删改性能）。


避免全表扫描：查询必须带有效过滤条件，分页用 LIMIT 并配合索引（如 LIMIT 10000,10 需 ORDER BY 字段有索引）。
**不用 SELECT ***：只查需要的字段，可能触发 “覆盖索引”（索引包含所有查询字段，无需回表）。
**子查询改 JOIN**：子查询（尤其相关子查询）可能重复执行，JOIN 更高效（如 IN (子查询) 改 JOIN 关联）。
优化 JOIN 逻辑：
小表驱动大表（减少外层循环次数）；
连接字段必须建索引（如 a.id = b.a_id 中 b.a_id 需索引）。


排序 &#x2F; 分组依赖索引：ORDER BY&#x2F;GROUP BY 的字段有索引时，可避免额外排序（如 Using filesort）。
合理选择数据类型：用更小的类型（如 INT 代替 BIGINT）、日期用 DATETIME 而非字符串，避免大字段（TEXT/BLOB 拆分到子表）。
分表分库：
水平分表：按时间 &#x2F; 哈希拆分大表（如 order_2023、order_2024）；
垂直分表：拆分不常用字段（如 user 拆分为 user_base 和 user_detail）。





二、数据库架构1、说说 MySQL 的基础架构？查看答案MySQL 采用分层架构，主要包括连接层、服务层、和存储引擎层。
下图是 MySQL 的一个简要架构图，从下图你可以很清晰的看到客户端的一条 SQL 语句在 MySQL 内部是如何执行的。

①、连接层主要负责客户端连接的管理，包括验证用户身份、权限校验、连接管理等。可以通过数据库连接池来提升连接的处理效率。
②、服务层是 MySQL 的核心，主要负责查询解析、优化、执行等操作。在这一层，SQL 语句会经过解析、优化器优化，然后转发到存储引擎执行，并返回结果。这一层包含查询解析器、优化器、执行计划生成器、日志模块等。
③、存储引擎层负责数据的实际存储和提取。MySQL 支持多种存储引擎，如 InnoDB、MyISAM、Memory 等。
binlog写入在哪一层？
binlog 在服务层，负责记录 SQL 语句的变化。它记录了所有对数据库进行更改的操作，用于数据恢复、主从复制等。


2、一条 SQL 查询语句在 MySQL 中的完整执行过程查看答案案例 SQLSELECT name, age FROM employees WHERE department = &#x27;Sales&#x27; AND salary &gt; 5000 ORDER BY hire_date DESC LIMIT 10;


执行过程详解1. 连接阶段 (Connector)
作用：建立客户端与服务器的连接
案例过程：
应用程序（如Java程序）通过JDBC驱动连接到MySQL
验证用户名&#x2F;密码（如：jdbc:mysql://localhost:3306/company）
检查权限（确认用户有employees表的SELECT权限）
建立连接线程（show processlist可查看）



2. 查询缓存 (Query Cache) [MySQL 8.0已移除]
MySQL 5.7中仍存在，但默认禁用


作用：缓存SELECT查询结果
案例过程：
生成查询缓存Key：department=&#39;Sales&#39;, salary&gt;5000, ...
检查缓存中是否有完全匹配的结果
若存在直接返回结果（本案例大概率不会命中，因包含动态条件）



3. 解析器 (Parser)
作用：语法解析，生成解析树
案例过程：
词法分析：拆分关键词SELECT → 查询命令name, age → 目标列FROM employees → 数据源WHERE → 条件开始department = &#x27;Sales&#x27; → 条件表达式...
语法分析：构建语法树 graph TD
A[SELECT] --&gt; B[ColumnList]
A --&gt; C[FROM]
A --&gt; D[WHERE]
A --&gt; E[ORDER BY]
A --&gt; F[LIMIT]
B --&gt; G[name]
B --&gt; H[age]
C --&gt; I[employees]
D --&gt; J[AND]
J --&gt; K[department=&#x27;Sales&#x27;]
J --&gt; L[salary&gt;5000]
E --&gt; M[hire_date DESC]
F --&gt; N[10]



4. 预处理器 (Preprocessor)
作用：语义检查，表&#x2F;列解析
案例过程：
检查employees表是否存在
验证name, age, department, salary, hire_date列是否存在
解析*符号（本案例未使用）
检查权限（再次确认SELECT权限）



5. 优化器 (Optimizer)
作用：生成最优执行计划

案例过程：

统计信息分析：

表行数（show table status like &#39;employees&#39;）
索引分布（department索引？salary索引？）


成本估算：

全表扫描 vs 使用索引
假设存在idx_dept_salary(department, salary)索引


执行计划生成：
EXPLAIN SELECT ...-- 结果示例：id: 1select_type: SIMPLEtable: employeestype: refkey: idx_dept_salaryrows: 100Extra: Using where; Using filesort
关键决策：

使用idx_dept_salary索引快速定位’Sales’部门
在索引结果中过滤salary &gt; 5000
对结果集进行文件排序（filesort）
应用LIMIT 10





6. 执行器 (Executor)
作用：调用存储引擎执行计划
案例过程：
打开employees表
调用存储引擎接口：// 伪代码index_read_first(idx_dept_salary, &#x27;Sales&#x27;)while (record = index_read_next()) &#123;    if (record.salary &gt; 5000) &#123;        result_set.add(record.name, record.age);        if (result_set.size() &gt;= 10) break;    &#125;&#125;
处理排序：
收集所有符合条件的行
在内存或磁盘进行快速排序（ORDER BY hire_date DESC）


应用LIMIT：取前10条结果



7. 存储引擎 (Storage Engine)
作用：实际数据存取（以InnoDB为例）
案例过程：
索引扫描：
使用B+树索引idx_dept_salary定位到第一个’Sales’部门记录
沿叶子节点链表扫描部门为’Sales’的记录


回表查询：
通过主键获取完整行数据（因SELECT包含非索引列name, age, hire_date）


过滤处理：
对每条记录检查salary &gt; 5000条件


数据返回：
将符合条件的name, age, hire_date返回给执行器


事务支持：
保证在READ COMMITTED隔离级别下看到一致的数据视图





8. 结果返回
作用：将最终结果发送给客户端

案例过程：

排序后的结果集放入网络缓冲区
通过TCP连接逐步发送给客户端
客户端（如MySQL命令行）显示结果：+----------+-----+| name     | age |+----------+-----+| John Doe | 32  || Jane Smith| 28 |...（共10行）
清理临时资源（排序内存、游标等）




关键流程总结sequenceDiagram
    participant Client
    participant Connector
    participant Parser
    participant Optimizer
    participant Executor
    participant InnoDB
    
    Client-&gt;&gt;Connector: 发送SQL查询
    Connector-&gt;&gt;Parser: 权限验证后传递
    Parser-&gt;&gt;Optimizer: 生成解析树
    Optimizer-&gt;&gt;Executor: 最优执行计划
    Executor-&gt;&gt;InnoDB: 调用索引扫描接口
    InnoDB-&gt;&gt;Executor: 返回数据页
    Executor-&gt;&gt;InnoDB: 请求回表查询
    InnoDB-&gt;&gt;Executor: 返回完整行数据
    Executor-&gt;&gt;Executor: 过滤/排序/LIMIT
    Executor-&gt;&gt;Client: 返回最终结果集

性能优化关键点
索引设计：创建复合索引(department, salary)可加速WHERE过滤
覆盖索引：若索引包含所有SELECT列（如(department, salary, name, age, hire_date)），可避免回表
排序优化：添加hire_date索引可消除filesort
LIMIT下推：在存储引擎层尽早应用行数限制
批量读取：顺序I&#x2F;O读取多个数据页减少磁盘寻道


💡 实际建议：通过EXPLAIN分析执行计划，关注type列（扫描方式）、Extra列（排序&#x2F;临时表）、rows列（扫描行数）等关键指标进行优化。



三、存储引擎查看答案1、讲一讲mysql的引擎吧，你有什么了解？
InnoDB：
InnoDB是MySQL的默认存储引擎。
具有ACID事务支持、行级锁、外键约束等特性。
它适用于高并发的读写操作，支持较好的数据完整性和并发控制。


MyISAM：
MyISAM是MySQL的另一种常见的存储引擎。
具有较低的存储空间和内存消耗，适用于大量读操作的场景。
MyISAM不支持事务、行级锁和外键约束，因此在并发写入和数据完整性方面有一定的限制。


Memory：
Memory引擎将数据存储在内存中，适用于对性能要求较高的读操作，但是在服务器重启或崩溃时数据会丢失。
不支持事务、行级锁和外键约束。





四、索引1、索引是什么？有什么好处？查看答案
索引类似于书籍的目录，可以减少扫描的数据量，提高查询效率。

如果查询的时候，没有用到索引就会全表扫描，这时候查询的时间复杂度是On

如果用到了索引，那么查询的时候，可以基于二分查找算法，通过索引快速定位到目标数据， mysql 索引的数据结构一般是 b+树，其搜索复杂度为O(logdN)，其中 d 表示节点允许的最大子节点个数为 d 个。




2、索引都分类查看答案
从功能上分
主键索引
唯一索引
普通索引
联合索引
全文索引
空间索引


从存储结构上分
聚簇索引
二级索引（非聚簇索引）





3、索引失效的几种情况查看答案
查询条件使用函数或者计算
不符合最左前缀原则
隐式类型转换（类型不匹配）
like通配符以“%” 开头
使用 or 时，两边有没有索引的字段
使用is null 或 is not null
使用not in
使用范围(&gt; ,&lt;)查询 
使用 !&#x3D; 或者 &lt;&gt;



4、创建索引有哪些注意点？查看答案
针对于数据量较大，且查询比较频繁的表建立索引。
针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引。
尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高。
如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。
尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间， 避免回表，提高查询效率。
要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增 删改的效率。
如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含 NULL值时，它可以更好地确定哪个索引最有效地用于查询。



5、如果Explain用到的索引不正确的话，有什么办法干预吗？可以使用 force index，强制走索引。
五、事务1、MySQL事务的四大特性查看答案
A（Atomicity） 原子性： 要求事务的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务中的操作不能只执行其中一部分。
C（Consistency） 一致性：执行事务前后，数据保持一致，例如转账业务中，无论事务是否成功，转账者和收款人的总额应该是不变的。
I（Isolation） 隔离性：并发执行的事务是彼此隔离的，多个事务之间不相互干扰。
D（Durability） 持久性：一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。



2、MySQL事务如何实现的查看答案graph TD
    A[事务ACID特性] --&gt; B[实现机制]
    B --&gt; B1[原子性 - Undo Log]
    B --&gt; B2[持久性 - Redo Log]
    B --&gt; B3[隔离性 - MVCC+锁]
    B --&gt; B4[一致性 - 前3者保证]
    
    B1 --&gt; C1[回滚操作]
    B2 --&gt; C2[崩溃恢复]
    B3 --&gt; C3[多版本并发控制]
    B3 --&gt; C4[行锁/间隙锁]


Undo Log（回滚日志）：
作用：实现事务的原子性
存储位置：共享表空间（ibdata1）或独立 Undo 表空间
工作原理：
更新数据前先记录修改前的值
事务回滚时恢复原始数据
支持 MVCC 的快照读




Redo Log（重做日志）：
作用：保证事务的持久性
存储形式：循环写的日志文件（ib_logfile0, ib_logfile1）
工作原理：
采用 WAL（Write-Ahead Logging）机制
先写日志后写数据页
崩溃恢复时重放日志




MVCC（多版本并发控制）
作用：实现隔离性（非锁定读）
核心元素：
DB_TRX_ID：6字节，最近修改的事务ID
DB_ROLL_PTR：7字节，回滚指针指向Undo Log
DB_ROW_ID：6字节，隐藏自增ID（无主键时）




锁机制
行级锁类型：

Record Lock：记录锁（锁定单行）
Gap Lock：间隙锁（锁定区间）
Next-Key Lock：记录锁+间隙锁（解决幻读）


锁兼容矩阵：



请求\持有
S（共享）
X（排他）



S（共享）
✓
✗


X（排他）
✗
✗








3、mysql可能出现什么和并发相关问题查看答案1. 脏读（Dirty Read）
定义：一个事务读取了另一个未提交事务修改的数据。

产生原因：事务隔离级别设置为 读未提交（READ UNCOMMITTED），允许读取未提交的数据。

影响：若未提交事务回滚，读取的数据是无效的，可能导致决策错误。

示例：
-- 事务 ABEGIN;UPDATE users SET balance = 200 WHERE id = 1;  -- 未提交-- 事务 BSELECT balance FROM users WHERE id = 1;  -- 读到 200（脏数据）-- 事务 A 回滚ROLLBACK;

解决方案：提高隔离级别至 读已提交（READ COMMITTED） 或更高。


2. 不可重复读（Non-Repeatable Read）
定义：同一事务中多次读取同一数据，结果不一致。

产生原因：事务隔离级别为 读已提交（READ COMMITTED），每次查询生成新的快照，允许读取其他事务已提交的修改。

影响：事务内的查询结果不一致，可能导致逻辑错误。

示例：
-- 事务 ABEGIN;SELECT balance FROM users WHERE id = 1;  -- 读到 100-- 事务 BBEGIN;UPDATE users SET balance = 200 WHERE id = 1;COMMIT;-- 事务 A 再次查询SELECT balance FROM users WHERE id = 1;  -- 读到 200（与第一次不同）

解决方案：使用 可重复读（REPEATABLE READ） 隔离级别（MySQL 默认），确保事务内快照一致。或使用锁定读SELECT balance FROM FROM users WHERE id = 1 FOR UPDATE;。


3. 幻读（Phantom Read）
定义：同一事务中，两次相同条件的查询返回不同行数。

产生原因：其他事务插入或删除数据，且提交后被当前事务读到。

影响：事务内的查询结果不一致，可能导致逻辑错误（如重复插入唯一键）。

示例：
-- 事务 ABEGIN;SELECT * FROM users WHERE age &gt; 30;  -- 返回 10 条记录-- 事务 BBEGIN;INSERT INTO users (name, age) VALUES (&#x27;Alice&#x27;, 35);COMMIT;-- 事务 A 再次查询SELECT * FROM users WHERE age &gt; 30;  -- 返回 11 条记录（幻读）

解决方案：

使用串行化（SERIALIZABLE）  隔离级别，但性能较低。
使用间隙锁（Next-Key Locking）SELECT * FROM users WHERE age &gt; 30 FOR UPDATE;。





4、不可重复读和幻读有什么区别？ 查看答案


不可重复读
幻读



同一事务内多次读取同一行数据，结果不一致。
同一事务内多次执行相同条件的查询，返回的 行数 不一致。


原因：其他事务对该行数据进行了 修改（Update&#x2F;Delete） 并提交。
原因：其他事务在查询范围内 插入（Insert） 或 删除（Delete） 了新数据并提交。


关注点：数据的 内容变化。
关注点：数据的 行数变化。




5、事务的隔离级别有哪些？ 查看答案


隔离级别
脏读可能性
不可重复读可能性
幻读可能性
加锁情况



读未提交（Read Uncommitted）
✅
✅
✅
无特殊锁


读已提交（Read Committed）
❌
✅
✅
行锁（仅在查询时加锁）


可重复读（Repeatable Read）
❌
❌
✅
行锁 + 间隙锁（MySQL 默认）


串行化（Serializable）
❌
❌
❌
表锁（强制事务串行执行）




六、MySQL 锁七、日志文件1、讲一下binlog查看答案二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但不包括数据查询（SELECT、SHOW）语句。
作用：
​	①. 灾难时的数据恢复。
​	②. MySQL的主从复制。
MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件，binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用。
binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志，用于备份恢复、主从复制；


2、RedoLog日志是什么？查看答案重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。
该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log file）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中,用于在刷新脏页到磁盘,发生错误时,进行数据恢复使用。


3、Write-ahead logging（WAL）是什么？查看答案Write-ahead logging（WAL）：因为在业务操作中，我们操作数据一般都是随机读写磁盘的，而不是顺序读写磁盘。 而redo log在往磁盘文件中写入数据时，由于是日志文件，所以都是顺序写的。顺序写的效率，要远大于随机写。 


4、binlog 和 redo log 有什么区别？查看答案binlog 由 MySQL 的 Server 层实现，与存储引擎无关；redo log 由 InnoDB 存储引擎实现。
binlog 会记录整个 SQL 或行变化；redo log 是为了恢复“已提交但未刷盘”的数据，undo log 是为了撤销未提交的事务。
binlog 是追加写入的，文件写满后会新建文件继续写入，不会覆盖历史日志，保存的是全量操作记录；redo log 是循环写入的，空间是固定的，写满后会覆盖旧的日志，仅保存未刷盘的脏页日志，已持久化的数据会被清除。


5、为什么要两阶段提交呢？查看答案事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。
在 MySQL 的 InnoDB 存储引擎中，开启 binlog 的情况下，MySQL 会同时维护 binlog 日志与 InnoDB 的 redo log，为了保证这两个日志的一致性，MySQL 使用了内部 XA 事务，内部 XA 事务由 binlog 作为协调者，存储引擎是参与者。


6、UndoLog日志的作用是什么？查看答案回滚日志，用于记录数据被修改前的信息 , 作用包含两个 : 提供回滚(保证事务的原子性) 和 MVCC(多版本并发控制) ；在事务没提交之前，MySQL 会先记录更新前的数据到 undo log 日志文件里面，当事务回滚时，可以利用 undo log 来进行回滚。


八、面试常问1、一个慢查询日志显示某SQL执行缓慢，你会如何分析和优化?一、先明确问题：收集关键信息首先会获取分析所需的基础信息，避免盲目优化：

获取完整 SQL：包括查询类型（SELECT&#x2F;UPDATE&#x2F;DELETE）、涉及的表、过滤条件（WHERE）、排序（ORDER BY）、分组（GROUP BY）、关联（JOIN）等细节。
了解表结构与索引：通过show create table查看表的字段类型、主键、索引；通过show index确认现有索引是否覆盖查询条件。
掌握数据规模与分布：表的总行数、过滤字段的分布（如某状态值占比）、是否有数据倾斜（如热点数据集中）。
确认执行环境：数据库版本（优化器行为可能不同）、当前负载（是否有锁竞争、其他慢查询）。

二、核心分析：通过执行计划定位瓶颈使用EXPLAIN（或EXPLAIN ANALYZE）查看 SQL 执行计划，重点关注 4 个关键指标，快速定位问题：

type 字段（访问类型）：
若为ALL（全表扫描）或index（全索引扫描），说明未有效利用索引，是主要瓶颈（尤其数据量大时）。
目标是优化到range（范围扫描）及以上（如ref、eq_ref）。


key 字段（实际使用的索引）：
若key=NULL，说明索引未被使用，需分析索引失效原因（如隐式转换、函数操作、反向模糊查询等）。
若key与预期不符，可能是优化器依赖的统计信息过时，需更新统计信息（analyze table）。


rows 字段（估算扫描行数）：
若rows远大于实际需要的行数，说明索引过滤性差（如用非唯一索引查询高频值），需优化索引粒度。


Extra 字段（额外执行信息）：
出现Using filesort（无法用索引排序，需磁盘排序）、Using temporary（创建临时表存储中间结果）时，性能会急剧下降，必须优化。
理想状态是Using index（覆盖索引，无需回表）。



三、针对性优化：分场景解决1. 索引问题（最常见）
缺少索引：为WHERE、JOIN ON、ORDER BY、GROUP BY涉及的字段添加合适索引（如联合索引需遵循 “最左前缀原则”）。例：SELECT * FROM user WHERE age &gt; 30 ORDER BY create_time，可添加(age, create_time)联合索引。
索引失效：修正导致索引失效的写法：
避免隐式类型转换（如WHERE phone = &#39;123&#39;改为WHERE phone = 123，假设 phone 是 int 类型）。
避免对索引字段用函数（如SUBSTR(name,1,1) = &#39;张&#39;改为name LIKE &#39;张%&#39;）。
替换反向模糊查询（LIKE &#39;%张&#39;）为全文索引或应用层处理。



2. SQL 逻辑不合理
**避免SELECT ***：只查询需要的字段，可能触发覆盖索引（Extra: Using index），减少 IO。
优化子查询：复杂子查询（如IN子查询）改为JOIN（优化器对JOIN支持更好）；联表查询最好要以小表驱动大表，并且被驱动表的字段要有索引，当然最好通过冗余字段的设计，避免联表查询。
优化大偏移量分页：LIMIT 100000, 10改为 “书签分页”（WHERE id &gt; 100000 LIMIT 10）或延迟关联（先查主键再关联表）。

3. 表结构与数据问题
数据量过大：单表超千万行时，用表分区（如按时间RANGE分区）或分库分表（Sharding-JDBC）拆分数据。
数据倾斜：对高频值字段（如status=0占 90%），添加更细粒度索引（如(status, create_time)），结合时间过滤减少扫描行数。

4. 环境与配置优化
调整数据库参数：增大innodb_buffer_pool_size（建议为内存的 50%-70%），减少磁盘 IO。
减少锁竞争：优化长事务（缩短事务时间），避免读写冲突（如show processlist排查锁等待）。
缓存热点数据：用 Redis 缓存高频查询结果，减少数据库访问。

2、
]]></content>
      <categories>
        <category>面试题</category>
        <category>MySql面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL运维</title>
    <url>/2025/06/27/MySQL/MySQL%E8%BF%90%E7%BB%B4/</url>
    <content><![CDATA[MySQL运维日志文件错误日志错误日志是 MySQL 中最重要的日志之一，它记录了当 mysqld 启动和停止时，以及服务器在运行过程中发生任何严重错误时的相关信息。当数据库出现任何故障导致无法正常使用时，建议首先查看此日志。
该日志是默认开启的，默认存放目录 &#x2F;var&#x2F;log&#x2F;，默认的日志文件名为 mysqld.log 。查看日志位置：
show variables like &#x27;%log_error%&#x27;;


二进制日志（BIN LOG）概述二进制日志（BINLOG）记录了所有的 DDL（数据定义语言）语句和 DML（数据操纵语言）语句，但不包括数据查询（SELECT、SHOW）语句。
作用：
​	①. 灾难时的数据恢复。
​	②. MySQL的主从复制。
在MySQL8版本中，默认二进制日志是开启着的，涉及到的参数如下：
show variables like &#x27;%log_bin%&#x27;;


参数说明： 

log_bin_basename：当前数据库服务器的binlog日志的基础名称(前缀)，具体的binlog文件名需要再该basename的基础上加上编号(编号从000001开始)。
log_bin_index：binlog的索引文件，里面记录了当前服务器关联的binlog文件有哪些。

格式MySQL服务器中提供了多种格式来记录二进制日志，具体格式及特点如下：



日志格式
含义



STATEMENT
基于SQL语句的日志记录，记录的是SQL语句，对数据进行修改的SQL都会记录在 日志文件中。


ROW
基于行的日志记录，记录的是每一行的数据变更。（默认）


MIXED
混合了STATEMENT和ROW两种格式，默认采用STATEMENT，在某些特殊情况下会 自动切换为ROW进行记录。


show variables like &#x27;%binlog_format%&#x27;;


如果我们需要配置二进制日志的格式，只需要在 &#x2F;etc&#x2F;my.cnf 中配置 binlog_format 参数即可。
查看由于日志是以二进制方式存储的，不能直接读取，需要通过二进制日志查询工具 mysqlbinlog 来查看，具体语法：
mysqlbinlog [ 参数选项 ] logfilename参数选项：-d 指定数据库名称，只列出指定的数据库相关操作。-o 忽略掉日志中的前n行命令。-v 将行事件(数据变更)重构为SQL语句-vv 将行事件(数据变更)重构为SQL语句，并输出注释信息

删除对于比较繁忙的业务系统，每天生成的binlog数据巨大，如果长时间不清除，将会占用大量磁盘空 间。可以通过以下几种方式清理日志：



指令
含义



reset master
删除全部 binlog 日志，删除之后，日志编号，将 从 binlog.000001重新开始


purge master logs to ‘binlog.*’
删除 * 编号之前的所有日志


purge master logs before ‘yyyy-mm-dd hh24:mi:ss’
删除日志为 “yyyy-mm-dd hh24:mi:ss” 之前 产生的所有日志


也可以在mysql的配置文件中配置二进制日志的过期时间，设置了之后，二进制日志过期会自动删除。
show variables like &#x27;%binlog_expire_logs_seconds%&#x27;;

慢查询日志慢查询日志记录了所有执行时间超过参数long_query_time设置值并且扫描记录数不小于 min_examined_row_limit 的所有的SQL语句的日志，默认未开启。long_query_time 默认为 10 秒，最小为 0， 精度可以到微秒。
 如果需要开启慢查询日志，需要在MySQL的配置文件 &#x2F;etc&#x2F;my.cnf 中配置如下参数：
#慢查询日志slow_query_log=1#执行时间参数long_query_time=2

默认情况下，不会记录管理语句，也不会记录不使用索引进行查找的查询。可以使用 log_slow_admin_statements和 更改此行为 log_queries_not_using_indexes，如下所述。
#记录执行较慢的管理语句log_slow_admin_statements =1#记录执行较慢的未使用索引的语句log_queries_not_using_indexes = 1


上述所有的参数配置完成之后，都需要重新启动MySQL服务器才可以生效。

主从复制概述主从复制是指将主数据库的 DDL 和 DML 操作通过二进制日志传到从库服务器中，然后在从库上对这些日志重新执行（也叫重做），从而使得从库和主库的数据保持同步。
MySQL支持一台主库同时向多台从库进行复制， 从库同时也可以作为其他从服务器的主库，实现链状复制。

MySQL 复制的优点主要包含以下三个方面：

主库出现问题，可以快速切换到从库提供服务。 
实现读写分离，降低主库的访问压力。 
可以在从库中执行备份，以避免备份期间影响主库服务。

原理MySQL主从复制的核心就是二进制日志，具体的过程如下：

复制分成三步： 

Master 主库在事务提交时，会把数据变更记录在二进制日志文件 Binlog 中。 
从库读取主库的二进制日志文件 Binlog ，写入到从库的中继日志 Relay Log 。 
slave重做中继日志中的事件，将改变反映它自己的数据。

分库分表概述问题分析

随着互联网及移动互联网的发展，应用系统的数据量也是成指数式增长，若采用单数据库进行数据存储，存在以下性能瓶颈：

IO瓶颈：热点数据太多、数据库缓存不足、产生大量磁盘IO、效率较低。 请求数据太多、带宽不够、网络IO瓶颈。
CPU瓶颈：排序、分组、连接查询、聚合统计等SQL会耗费大量的CPU资源，请求数太多，CPU出现瓶颈。

为了解决上述问题，我们需要对数据库进行分库分表处理。

分库分表的中心思想就是将数据分散存储，使得单一数据库&#x2F;表的数据量变小来缓解单一数据库的性能问题，从而达到提升数据库性能的目的。
拆分策略分库分表的形式，主要是两种：垂直拆分和水平拆分。而拆分的粒度，一般又分为分库和分表，所以组成的拆分策略最终如下：

垂直拆分
垂直分库：以表为依据，根据业务将不同表拆分到不同库中。

特点： 

每个库的表结构都不一样。 
每个库的数据也不一样。
所有库的并集是全量数据。


垂直分表：以字段为依据，根据字段属性将不同字段拆分到不同表中。

特点：

每个表的结构都不一样。 
每个表的数据也不一样，一般通过一列（主键&#x2F;外键）关联。 
所有表的并集是全量数据。



水平拆分
水平分库：以字段为依据，按照一定策略，将一个库的数据拆分到多个库中。

特点：

每个库的表结构都一样。 
每个库的数据都不一样。 
所有库的并集是全量数据。


水平分表：以字段为依据，按照一定策略，将一个表的数据拆分到多个表中。

特点： 

每个表的表结构都一样。
每个表的数据都不一样。 
所有表的并集是全量数据。




在业务系统中，为了缓解磁盘IO及CPU的性能瓶颈，到底是垂直拆分，还是水平拆分；具体是分 库，还是分表，都需要根据具体的业务需求具体分析。

实现技术
shardingJDBC：基于AOP原理，在应用程序中对本地执行的SQL进行拦截，解析、改写、路由处 理。需要自行编码配置实现，只支持java语言，性能较高。
MyCat：数据库分库分表中间件，不用调整代码即可实现分库分表，支持多种语言，性能不及前者。


本次课程，我们选择了是MyCat数据库中间件，通过MyCat中间件来完成分库分表操作。
MyCattodo :后面在学习，现在准备面试了解基本概念。
读写分离概述读写分离,简单地说是把对数据库的读和写操作分开,以对应不同的数据库服务器。主数据库提供写操作，从数据库提供读操作，这样能有效地减轻单台数据库的压力。
通过MyCat即可轻易实现上述功能，不仅可以支持MySQL，也可以支持Oracle和SQL Server。

一主一从原理：MySQL的主从复制，是基于二进制日志（binlog）实现的。
一主一从读写分离MyCat控制后台数据库的读写分离和负载均衡由schema.xml文件datahost标签的balance属性控制。
双主双从一个主机 Master1 用于处理所有写请求，它的从机 Slave1 和另一台主机 Master2 还有它的从 机 Slave2 负责所有读请求。当 Master1 主机宕机后，Master2 主机负责写请求，Master1 、 Master2 互为备机。架构图如下:

]]></content>
      <categories>
        <category>MySQL</category>
        <category>MySQL进阶</category>
      </categories>
      <tags>
        <tag>MySQL进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>windows同时安装两个不同版本的Mysql</title>
    <url>/2025/06/23/RandomNotes/windows%E5%90%8C%E6%97%B6%E5%AE%89%E8%A3%85%E4%B8%A4%E4%B8%AA%E4%B8%8D%E5%90%8C%E7%89%88%E6%9C%AC%E7%9A%84Mysql/</url>
    <content><![CDATA[windows同时安装两个不同版本的Mysql
本地已经安装了mysql-5.7.11 版本，现在需要再安装一个8版本的MySQL，由此记录一下。

查看本地mysql版本

1.下载MySQL   官网下载历史版本地址：MySQL :: Download MySQL Community Server (Archived Versions)
   
   选择版本后点击下载。
2.下载完成后，解压文件。（ps:注意将压缩包解压到和之前版本不同路径（路径请勿包含中文或空格））。   
3.创建 my.ini 配置文件（放在解压根目录，如 D:\mysql-8.0.28\my.ini）   [mysqld]# 端口（如 3307，与 5.7 不同）port=3307  # 安装目录basedir=&quot;D:/Application/mysql-8.0.28&quot;# 数据目录datadir=&quot;D:/Application/mysql-8.0.28/data&quot;# 服务端使用的字符集默认为UTF8character-set-server=utf8mb4  # 创建新表时将使用的默认存储引擎default-storage-engine=INNODB  # MySQL 8.0 认证插件（兼容旧客户端）default_authentication_plugin=mysql_native_password  [mysql]# 设置mysql客户端默认字符集default-character-set=utf8[client]port=3307  default-character-set=utf8mb4  

4.配置环境变量(如果之前配置了，有两个MySQL环境变量，可能会出问题，可以不用配置)   
5.初始化数据库   以 管理员身份 运行命令提示符（CMD）。
   
   cd D:\Application\mysql-8.0.28\binmysqld --initialize --console

   
   记下 root 临时密码
6.安装 Windows 服务   mysqld --install MySQL80 --defaults-file=&quot;D:\Application\mysql-8.0.28\my.ini&quot;

   
7.启动服务   net start MySQL80

   可能会启动失败
   
   解决：

Win键+R输入services.msc,打开服务面板。

发现可执行文件目录是5.7的地址。有可能是因为多个MySQL环境变量导致。

路径不对，如何修改？
Win键+R输入regedit打开注册表，在HKEY_LOCAL_MACHINE\SYSTEM\CurrentControlSet\Services\MySQL80 目录下修改ImagePath的路径（）。


重启启动服务



8.登录MySQL   密码是上面生成的临时密码
   
9.修改密码   ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;密码&#x27;;

10.登录出现错误在系统命令行下

解决方式

切换到安装目录


连接时添加 --ssl-mode=DISABLED 禁用 SSL 验证（因为MySQL8默认开启SSL加密）
mysql -uroot -p -P3307 --ssl-mode=DISABLED




]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>系统升级</title>
    <url>/2025/06/04/RandomNotes/%E7%B3%BB%E7%BB%9F%E5%8D%87%E7%BA%A7/</url>
    <content><![CDATA[SSH框架升级为SpringBoot前言和准备
公司系统使用框架为SSH（Spring + Spring MVC + Hibernate)，现在要求升级为SpringBoot。  
原项目：Spring 3.1.3 + Hibernate 4.2.21 使用jar包方式  
准备升级为：SpringBoot2.7.6 +  使用mavne管理jar包
Spring Boot 2.x需要Spring 5和Hibernate 5.2+，因此我们需要升级这些依赖。

步骤1. 创建Spring Boot项目   使用阿里云地址 https://start.aliyun.com/ 来创建一个新的Spring Boot 项目。选择 JDK8、Maven、Spring Boot 版本2.7.6。
   目录结构为：
   
2. jar包用maven替换将原项目src下的目录复制到新建的项目中。先运行一下@SpringBootApplication 类，根据报错去添加相关依赖。没有去网站[Maven Repository: Search/Browse/Explore (mvnrepository.com)](https://mvnrepository.com/)下载依赖。
1. 集成log4j
Spring Boot 已弃用 spring-boot-starter-log4j：  Spring Boot 从 1.2.x 版本开始，官方推荐使用 Logback 或 Log4j2，不再支持旧版的 Log4j 1.x。  因此，spring-boot-starter-log4j 在较新的 Spring Boot 版本中已被移除。

   因为之前系统使用log4j，为了不用改配置和代码，确定继续使用log4j。下载好依赖后导入 pom.xml 文件中。
   &lt;!--添加log4j依赖模块--&gt;&lt;dependency&gt;   &lt;groupId&gt;log4j&lt;/groupId&gt;   &lt;artifactId&gt;log4j&lt;/artifactId&gt;   &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt;

2. 集成Hibernate    原系统使用的 hibernate  版本 4.2.21。

导入依赖

   &lt;!-- 只需添加 JPA Starter Spring Boot 会自动引入兼容的 Hibernate 版本（无需手动指定）--&gt;&lt;dependency&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;   &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;

   spring-boot-starter-data-jpa 已集成 Hibernate 核心依赖，无需单独引入 hibernate-core 等包。  

配置文件

   以前需要在application-context.xml 文件中配置
   .chwmthociykd{zoom:80%;}

   现在只需要在application.yaml 文件中配置即可。
   
3. 前端代码移植
原系统使用JSP，需要将原项目WebContent 目录下的文件复制到，webapp 目录下。

原系统：



现在系统：



配置视图解析器


mvc:   view:     prefix: /WEB-INF/jsp/ #配置视图解析器     suffix: .jsp web:   resources:     static-locations: classpath:/static/,classpath:/WEB-INF/userData/,classpath:/WEB-INF/temp/ #设置静态资源路径


引入依赖
&lt;!--SpringBoot不推荐使用jsp  加入一个处理jsp的依赖。 负责编译jsp文件--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;    &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--jstl 依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;javax.servlet&lt;/groupId&gt;    &lt;artifactId&gt;jstl&lt;/artifactId&gt;&lt;/dependency&gt;

]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 1 - JVM介绍</title>
    <url>/2025/05/21/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%201%20-%20JVM%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[JVM什么是JVMJVM 全称是 Java Virtual Machine，中文译名 Java虚拟机，是 Java 生态的核心，它负责执行字节码，提供内存管理、垃圾回收、线程管理等功能，使 Java 程序能够实现 “一次编写，到处运行” 的跨平台特性。
JVM的三大核心功能是什么？JVM 包含内存管理、解释执行虚拟机指令、即时编译三大功能。
常见的JVM虚拟机有哪些？
JVM知识体系
学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>Spring面试题</title>
    <url>/2025/07/02/Interview/Spring%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
    <content><![CDATA[Spring面试题Ioc说一说什么是 IoC？IoC（Inversion of Control）控制反转，不是什么技术，而是一种设计思想。将你设计好的对象交给容器控制，而不是传统的在你的对象内部直接控制。

谁控制谁，控制什么？
传统Java SE程序设计，我们直接在对象内部通过new进行创建对象，是程序主动去创建依赖对象；而IoC是有专门一个容器来创建这些对象，即由Ioc容器来控制对象的创建；谁控制谁？当然是IoC 容器控制了对象；控制什么？那就是主要控制了外部资源获取（不只是对象包括比如文件等）。

为何是反转，哪些方面反转了？
有反转就有正转，传统应用程序是由我们自己在对象中主动控制去直接获取依赖对象，也就是正转；而反转则是由容器来帮忙创建及注入依赖对象；为何是反转？因为由容器帮我们查找及注入依赖对象，对象只是被动的接受依赖对象，所以是反转；哪些方面反转了？依赖对象的获取被反转了。


传统程序设计下，都是主动去创建相关对象然后再组合起来：

当有了IoC&#x2F;DI的容器后，在客户端类中不再主动去创建这些对象了，如图

说一说什么是DI？DI (Dependency Injection) 依赖注入,是实现 IOC 的具体方式，比如说利用注入机制（如构造器注入、Setter 注入或接口注入）将依赖传递给目标对象。

优点
在平时的 Java 开发中，如果我们要实现某一个功能，可能至少需要两个以上的对象来协助完成，在没有 Spring 之前，每个对象在需要它的合作对象时，需要自己 new 一个，比如说 A 要使用 B，A 就对 B 产生了依赖，也就是 A 和 B 之间存在了一种耦合关系。
有了 Spring 之后，就不一样了，创建 B 的工作交给了 Spring 来完成，Spring 创建好了 B 对象后就放到容器中，A 告诉 Spring 我需要 B，Spring 就从容器中取出 B 交给 A 来使用。
至于 B 是怎么来的，A 就不再关心了，Spring 容器想通过 new 创建 B 还是 new 创建 B，无所谓。
这就是 IoC 的好处，它降低了对象之间的耦合度，使得程序更加灵活，更加易于维护。



Spring的依赖注入有哪些实现方式？
构造函数注入：通过类的构造函数来注入依赖项。
Setter 注入：通过类的 Setter 方法来注入依赖项。
Field（字段） 注入：直接在类的字段上使用注解（如 @Autowired 或 @Resource）来注入依赖项。

@Autowired、@Resource 和 @Inject 的区别


特性
@Autowired (Spring)
@Resource (JSR-250)
@Inject (JSR-330)



来源规范
Spring 专属
Java EE 标准 (JSR-250)
Java DI 标准 (JSR-330)


包路径
org.springframework.beans.factory.annotation
javax.annotation
javax.inject


默认注入方式
按类型 (byType)
按名称 (byName)
按类型 (byType)


名称指定
需配合 @Qualifier
直接使用 name 属性
需配合 @Named


必需依赖
支持 required=false
总是必需
总是必需


构造器注入
✅ 支持
❌ 不支持
✅ 支持


方法&#x2F;字段
✅ 支持
✅ 支持
✅ 支持


参数注入
✅ 支持
❌ 不支持
✅ 支持


自定义限定符
✅ 支持
❌ 不支持
✅ 支持


什么是 Spring Bean？Bean 是指由 Spring 容器管理的对象，它的生命周期由容器控制，包括创建、初始化、使用和销毁。以通过三种方式声明：注解方式、XML 配置、Java 配置。
①、使用 @Component、@Service、@Repository、@Controller 等注解定义，主流。
②、基于 XML 配置，Spring Boot 项目已经不怎么用了。
③、使用 Java 配置类创建 Bean：
@Configurationpublic class AppConfig &#123;    @Bean    public UserService userService() &#123;        return new UserService();    &#125;&#125;

@Component 和 @Bean 的区别@Component 是 Spring 提供的一个类级别注解，由 Spring 自动扫描并注册到 Spring 容器中。
@Bean 是一个方法级别的注解，用于显式地声明一个 Bean，当我们需要第三方库或者无法使用 @Component 注解类时，可以使用 @Bean 来将其实例注册到容器中。
说一下 Bean 的生命周期实例化 → 属性注入 →（Aware 回调 → BeanPostProcessor 前置 → 初始化方法 → BeanPostProcessor 后置）→ 使用 →（销毁方法 → 资源释放）

实例化：Spring 首先使用构造方法或者工厂方法创建一个 Bean 的实例。在这个阶段，Bean 只是一个空的 Java 对象，还未设置任何属性。
属性注入：Spring 将配置文件中的属性值或依赖的 Bean 注入到该 Bean 中。这个过程称为依赖注入，确保 Bean 所需的所有依赖都被注入。
初始化：对注入属性后的 Bean 进行 “初始化”（如初始化连接、加载资源等），使其达到可用状态。
Aware 接口回调（可选）：若 Bean 实现了 Aware 系列接口（如 BeanNameAware、ApplicationContextAware），Spring 会回调接口方法，将容器相关信息传递给 Bean。
BeanNameAware：获取当前 Bean 在容器中的名称（setBeanName）；
BeanFactoryAware：获取当前 Bean 所属的容器（setBeanFactory）；
ApplicationContextAware：获取 Spring 应用上下文（setApplicationContext）。


BeanPostProcessor 前置处理（可选）：若容器中注册了 BeanPostProcessor（Bean 后置处理器），会调用其 postProcessBeforeInitialization 方法，对 Bean 进行初始化前的自定义处理（如修改属性、增强功能）。注：BeanPostProcessor 对容器中所有 Bean 生效，是 Spring 扩展的核心机制之一。
初始化方法执行（可选）：执行用户定义的初始化逻辑，按以下优先级执行：
@PostConstruct 注解的方法（JSR-250 标准，在依赖注入完成后执行）；
实现 InitializingBean 接口的 afterPropertiesSet 方法（Spring 内置接口，注入完成后回调）；
自定义 init-method（在 XML 中通过 init-method 指定，或 @Bean(initMethod = &quot;...&quot;)）。


BeanPostProcessor 后置处理（可选）：调用 BeanPostProcessor 的 postProcessAfterInitialization 方法，对初始化后的 Bean 进行最终处理（如 AOP 代理就是通过此步骤生成代理对象）。


使用中：Bean 进入可用状态，供应用程序调用。此时 Bean 已完成初始化，可通过容器的 getBean 方法获取，或被其他 Bean 依赖使用。
销毁：在容器关闭时，Spring 会调用 destroy 方法，释放 Bean 占用的资源（如关闭连接、释放缓存）。

Bean 的作用域有哪些?在 Spring 中，Bean 默认是单例的，即在整个 Spring 容器中，每个 Bean 只有一个实例。
可以通过在配置中指定 scope 属性，将 Bean 改为多例（Prototype）模式，这样每次获取的都是新的实例。
在Spring配置文件中，可以通过标签的scope属性来指定Bean的作用域。例如：
&lt;bean id=&quot;myBean&quot; class=&quot;com.example.MyBean&quot; scope=&quot;singleton&quot;/&gt;

基于Java的配置中，可以通过@Scope注解来指定Bean的作用域。例如：
@Bean@Scope(&quot;prototype&quot;)  // 每次获取都是新的实例public MyBean myBean() &#123;    return new MyBean();&#125;

Spring支持几种不同的作用域，以满足不同的应用场景需求。以下是一些主要的Bean作用域：

Singleton（单例）：在整个应用程序中只存在一个 Bean 实例。默认作用域，Spring 容器中只会创建一个 Bean 实例，并在容器的整个生命周期中共享该实例。
Prototype（原型）：每次请求时都会创建一个新的 Bean 实例。次从容器中获取该 Bean 时都会创建一个新实例，适用于状态非常瞬时的 Bean。
Request（请求）：每个 HTTP 请求都会创建一个新的 Bean 实例。仅在 Spring Web 应用程序中有效，每个 HTTP 请求都会创建一个新的 Bean 实例，适用于 Web 应用中需求局部性的 Bean。
Session（会话）：Session 范围内只会创建一个 Bean 实例。该 Bean 实例在用户会话范围内共享，仅在 Spring Web 应用程序中有效，适用于与用户会话相关的 Bean。
Application：当前 ServletContext 中只存在一个 Bean 实例。仅在 Spring Web 应用程序中有效，该 Bean 实例在整个 
ServletContext 范围内共享，适用于应用程序范围内共享的 Bean。
WebSocket（Web套接字）：在 WebSocket 范围内只存在一个 Bean 实例。仅在支持 WebSocket 的应用程序中有效，该 Bean 实例在 WebSocket 会话范围内共享，适用于 WebSocket 会话范围内共享的 Bean。Custom scopes（自定义作用域）：Spring 允许开发者定义自定义的作用域，通过实现 Scope 接口来创建新的 Bean 作用域。

Spring中的单例Bean会存在线程安全问题吗？在 Spring 中，单例 Bean 本身并不保证线程安全，其线程安全性取决于 Bean 的实现方式。单例 Bean 在容器中仅存在一个实例，当多个线程同时访问该实例时，若 Bean 包含可变状态（如成员变量），则可能出现线程安全问题；若 Bean 是无状态或不可变的，则线程安全。

单例 Bean 的线程安全问题：

可变状态的单例 Bean若 Bean 中包含可被多个线程修改的成员变量（如计数器、集合），则存在线程安全隐患。
@Componentpublic class CounterService &#123;    private int count = 0; // 可变状态，多线程访问可能冲突        public void increment() &#123;        count++; // 非原子操作，存在竞态条件    &#125;        public int getCount() &#123;        return count;    &#125;&#125;


问题：多个线程同时调用 increment() 时，由于 count++ 不是原子操作，可能导致计数错误。


有状态 Bean 的方法共享资源
若 Bean 的方法操作共享资源（如文件、数据库连接），且未进行同步控制，则可能出现线程安全问题。
@Componentpublic class FileService &#123;    private FileWriter writer; // 共享资源        @PostConstruct    public void init() throws IOException &#123;        writer = new FileWriter(&quot;data.txt&quot;);    &#125;        public void write(String data) throws IOException &#123;        writer.write(data); // 多线程写入可能导致数据错乱    &#125;&#125;


问题：多个线程同时调用 write() 可能导致文件内容混乱。




线程安全的单例 Bean 实现方式

无状态 Bean
Bean 不包含任何成员变量（仅提供方法逻辑），所有操作基于方法参数和局部变量。
@Componentpublic class CalculatorService &#123;    public int add(int a, int b) &#123;        return a + b; // 仅依赖方法参数，无共享状态    &#125;&#125;


线程安全原因：方法内的局部变量在每个线程的栈内存中独立存在，互不干扰。


不可变 BeanBean 的成员变量被声明为 final，且对象创建后状态不可变。
@Componentpublic class ConfigService &#123;    private final String apiKey;        @Autowired    public ConfigService(@Value(&quot;$&#123;api.key&#125;&quot;) String apiKey) &#123;        this.apiKey = apiKey; // 构造器注入后不可变    &#125;        public String getApiKey() &#123;        return apiKey;    &#125;&#125;


线程安全原因：不可变对象的状态无法被修改，多线程访问时不存在竞态条件。


同步机制在有状态 Bean 中使用 synchronized、Lock 或原子类（如 AtomicInteger）保证线程安全。
@Componentpublic class SafeCounterService &#123;    private final AtomicInteger count = new AtomicInteger(0); // 原子类保证线程安全        public void increment() &#123;        count.incrementAndGet(); // 原子操作    &#125;        public int getCount() &#123;        return count.get();    &#125;&#125;


线程安全原因：AtomicInteger 使用 CAS（Compare-and-Swap）保证原子性，避免锁竞争。

@Componentpublic class CounterService &#123;    private int count = 0; // 可变状态，多线程访问可能冲突        //使用 synchronized 确保线程安全    public synchronized void increment() &#123;        count++; // 非原子操作，存在竞态条件    &#125;        public int getCount() &#123;        return count;    &#125;&#125;


使用 synchronized 确保线程安全


ThreadLocal 隔离线程状态使用 ThreadLocal 为每个线程提供独立的变量副本。
@Componentpublic class RequestContextHolder &#123;    private final ThreadLocal&lt;String&gt; requestId = new ThreadLocal&lt;&gt;();        public void setRequestId(String id) &#123;        requestId.set(id);    &#125;        public String getRequestId() &#123;        return requestId.get();    &#125;        public void clear() &#123;        requestId.remove(); // 避免内存泄漏    &#125;&#125;


线程安全原因：每个线程独立维护自己的 ThreadLocal 副本，互不干扰。


改为 prototype 作用域
如果 Bean 确实需要维护状态，可以考虑将其改为 prototype 作用域，这样每次注入都会创建一个新的实例，避免了多线程共享同一个实例的问题。
@Service@Scope(&quot;prototype&quot;) // 每次注入都创建新实例public class StatefulService &#123;    private String state; // 现在每个实例都有独立状态        public void setState(String state) &#123;        this.state = state;    &#125;&#125;



FactoryBean 与 BeanFactory 的区别
FactoryBean：它是一个工厂 Bean，实现了FactoryBean接口，主要用于创建特定类型的 Bean 实例。
BeanFactory：它是 Spring 容器的核心接口，负责管理和获取 Bean 实例，是容器的基础。

什么是循环依赖?A 依赖 B，B 依赖 A，或者 C 依赖 C，就成了循环依赖。
class ServiceA &#123;    @Autowired    private ServiceB serviceB;  // A依赖B&#125;class ServiceB &#123;    @Autowired    private ServiceA serviceA;  // B依赖A&#125;

原因很简单，AB 循环依赖，A 实例化的时候，发现依赖 B，创建 B 实例，创建 B 的时候发现需要 A，创建 A1 实例……无限套娃。。。。
Spring中的循环依赖如何处理？Spring的解决方案：核心是三级缓存机制，通过提前暴露刚实例化（但未初始化）的 Bean 的早期引用（可能被包装成代理），并利用属性注入（Setter&#x2F;Field） 来打破 Singleton Bean 的循环依赖。
graph TD
    subgraph Spring容器
        A[一级缓存] --&gt;|完全初始化的Bean| singletonObjects
        B[二级缓存] --&gt;|早期暴露的Bean| earlySingletonObjects
        C[三级缓存] --&gt;|Bean工厂| singletonFactories
    end


singletonObjects (一级缓存)：
存放内容： 完全初始化好的、可用的成品单例 Bean。
访问时机： 当需要获取一个 Bean 时，首先检查这里。
状态： Bean 已实例化、属性已填充、初始化方法（如 @PostConstruct、InitializingBean、init-method）已执行。


earlySingletonObjects (二级缓存)：
存放内容： 提前暴露的、早期的单例 Bean 引用。这些 Bean 已经实例化，但属性尚未填充（可能依赖其他 Bean），初始化方法也未执行。
作用： 解决循环依赖的关键。当一个 Bean 还在创建过程中（刚实例化完，还没填充属性），就提前把它放入这个缓存，供其他依赖它的 Bean 引用，从而打破循环。
状态： Bean 已实例化（调用了构造方法），但属性未填充，未初始化。


singletonFactories (三级缓存)：
存放内容： 单例对象工厂（ObjectFactory）。每个单例 Bean 在实例化后（调用构造方法后），都会生成一个对应的 ObjectFactory 并放入此缓存。
ObjectFactory 的作用： 当需要获取该 Bean 的早期引用时（比如在解决循环依赖时），会调用这个工厂的 getObject() 方法。这个方法最终会调用 getEarlyBeanReference()。
getEarlyBeanReference() 的重要性：
如果 Bean 不需要被 AOP 代理（如没有切面匹配它），这个方法直接返回原始的 Bean 实例。
如果 Bean 需要被 AOP 代理，这个方法会提前生成并返回代理对象。这是保证注入到其他 Bean 中的是代理对象（而不是原始对象）的关键，避免了后续注入不一致的问题。





🔄 解决循环依赖的流程（以 ServiceA 和 ServiceB 为例）

开始创建 ServiceA：
容器发现需要创建 ServiceA。
调用 ServiceA 的构造方法，实例化 ServiceA 对象（此时 serviceB 属性还是 null）。
将创建 ServiceA 的 ObjectFactory 放入 **三级缓存 (singletonFactories)**。


填充 ServiceA 的属性：
容器准备为 serviceB 属性赋值。
发现需要注入 ServiceB，于是去获取 ServiceB。


开始创建 ServiceB：
容器发现需要创建 ServiceB。
调用 ServiceB 的构造方法，实例化 ServiceB 对象（此时 serviceA 属性还是 null）。
将创建 ServiceB 的 ObjectFactory 放入 **三级缓存 (singletonFactories)**。


填充 ServiceB 的属性：
容器准备为 serviceA 属性赋值。
发现需要注入 ServiceA，于是去获取 ServiceA。


获取 ServiceA（关键步骤）：
在 singletonObjects (一级缓存) 中未找到完全初始化的 ServiceA。
在 earlySingletonObjects (二级缓存) 中未找到 ServiceA 的早期引用。
在 singletonFactories (三级缓存) 中找到了 ServiceA 的 ObjectFactory。
调用 ObjectFactory.getObject() -&gt; 实际调用 getEarlyBeanReference()。
如果 ServiceA 需要 AOP 代理，则在此刻生成代理对象并返回。
如果不需要，则返回原始 ServiceA 对象。


将这个（可能是代理的）早期对象放入 **二级缓存 (earlySingletonObjects)**，并从三级缓存中移除对应的 ObjectFactory。
将这个早期对象注入到 ServiceB 的 serviceA 属性中。至此，ServiceB 的属性填充完成。


完成 ServiceB 的初始化：
执行 ServiceB 的初始化方法（@PostConstruct 等）。
将完全初始化好的 ServiceB 放入 **一级缓存 (singletonObjects)**，并从二级和三级缓存中移除。


回到填充 ServiceA 的属性：
容器现在获取到了完全初始化好的 ServiceB（它已经在步骤 6 中被放入一级缓存）。
将 ServiceB 注入到 ServiceA 的 serviceB 属性中。至此，ServiceA 的属性填充完成。


完成 ServiceA 的初始化：
执行 ServiceA 的初始化方法（@PostConstruct 等）。
将完全初始化好的 ServiceA 放入 **一级缓存 (singletonObjects)**，并从二级缓存中移除（它之前在步骤 5 被放入了二级缓存）。



✅ 至此，循环依赖成功解决！ ServiceA 持有完整的 ServiceB，ServiceB 持有完整的 ServiceA（或 ServiceA 的代理对象）。
解决条件与限制
Spring只能解决特定条件下的循环依赖：

必须是单例Bean：原型(prototype)作用域的Bean无法解决
不能是构造器注入：仅支持属性注入或setter注入
需要Spring管理：不能是new创建的对象

当遇到构造器注入的循环依赖时，Spring会直接抛出BeanCurrentlyInCreationException异常。
为什么要二级缓存, 一级缓存能实现吗?理论上可以的, 只要在设计一级缓存的过程中能准确的标识当前 bean 是处于完成状态还是半成品状态即可; 但是如果通过二级缓存, 可以简化代码开发, 并且能提高每次的判断执行效率, 所以引入二级缓存
为什么用三级缓存解决循环依赖问题？用二级缓存不行吗？如果不引入三级缓存的话会造成一下问题, 如果 B 通过二级缓存将 A 的值进行填充了，那么 B 中 A 的对象就是 A 的原始 bean 对象; 因为 bean 的生命周期中 bean 的字段填充是发生在初始化之前的, 所以当 A 进行后续操作中被代理了功能得到增强了, 那么 B 中的 A 字段是无法被更新和感知的; 所以引入三级缓存的概念, 如果 A 被代理了, 那么在 B 在进行赋值的时候就可以将代理提前。
举个栗子

假设只有两级缓存（仅保留一级和二级缓存）

实例化 BeanA → 直接放入二级缓存（earlySingletonObjects）
填充 BeanA 属性时发现需要 BeanB
实例化 BeanB → 直接放入二级缓存
填充 BeanB 属性时发现需要 BeanA → 从二级缓存取出 BeanA 的原始对象
将 BeanA 注入 BeanB
完成 BeanB 初始化 → 移入一级缓存
继续填充 BeanA → 注入已完成的 BeanB
完成 BeanA 初始化 → 移入一级缓存

表面看似乎可行？但遇到 AOP 代理时会暴露致命缺陷！
如果BeanA需要被动态代理（比如加了 @Transactional），如果没有三级缓存，当填充BeanB的属性BeanA时，拿到的是 A 的原始对象。Spring 需要在初始化阶段之后生成代理对象A ；会导致：
sequenceDiagram
    participant C as Spring容器
    participant A as BeanA原始对象
    participant P as BeanA代理对象

    C-&gt;&gt;A: 1. 实例化BeanA（原始对象）
    C-&gt;&gt;C: 2. 将原始BeanA存入二级缓存
    C-&gt;&gt;A: 3. 填充属性（需要BeanB）...
    ## 创建BeanB并注入原始BeanA ...

    C-&gt;&gt;A: 4. 执行BeanA初始化
    C-&gt;&gt;P: 5. 【问题点】此时才生成代理对象
    C-&gt;&gt;C: 6. 将代理对象放入一级缓存

代理对象失效：循环依赖时，其他 BeanB 注入的是原始 BeanA 实例，而非代理对象，AOP 增强逻辑无法生效。

代理时机错误：代理对象应在 BeanA初始化完成后生成，若提前存入二级缓存，会破坏初始化流程。



三级缓存的解决方案：
三级缓存存储 ObjectFactory，其 getObject() 方法可延迟生成代理对象（调用 getEarlyBeanReference() 方法）。当发生循环依赖时，通过工厂生成代理对象并放入二级缓存，确保其他 Bean 注入的是代理后的实例。


@Lazy 能解决循环依赖吗？
@Lazy的作用原理@Lazy注解的核心作用是延迟加载 Bean 的实例化过程，即当真正需要用到该Bean的时候才去初始化。当应用于循环依赖场景时：

延迟依赖注入：将依赖对象包装为Proxy（代理对象），在实际使用时才创建真实实例。
打破初始化死锁：避免两个 Bean 在初始化阶段互相等待对方实例化完成。


@Lazy能解决的场景
构造器注入的循环依赖（Spring 默认无法解决）
@Servicepublic class A &#123;    private final B b;    @Autowired    public A(@Lazy B b) &#123; // 使用@Lazy延迟加载B        this.b = b;    &#125;&#125;@Servicepublic class B &#123;    private final A a;    @Autowired    public B(@Lazy A a) &#123; // 使用@Lazy延迟加载A        this.a = a;    &#125;&#125;


原理：注入时实际保存的是B的代理对象（而非真实实例），A可以顺利完成初始化。当A首次使用B时，才会触发B的真实实例化。


单例与原型 Bean 的循环依赖
@Service@Scope(&quot;prototype&quot;)public class A &#123;    @Autowired    private B b;&#125;@Servicepublic class B &#123;    @Autowired    private A a;&#125;


问题：原型 Bean 不支持三级缓存，默认无法解决循环依赖。

解决方法
@Service@Scope(&quot;prototype&quot;)public class A &#123;    @Autowired    private B b;&#125;@Servicepublic class B &#123;    @Autowired    @Lazy    private A a;&#125;


能解决：通过延迟加载和代理对象，@Lazy 可以解决构造器注入的循环依赖，以及非单例 Bean 的循环依赖。

不能解决：如果循环依赖的 Bean 在初始化阶段就需要真实依赖对象（而非代理），@Lazy 无法解决问题，此时必须重构代码。


AOP说说什么是 AOP？AOP为Aspect Oriented Programming的缩写，意为：面向切面编程，AOP 就是把一些业务逻辑中的相同代码抽取到一个独立的模块中，让业务逻辑更加清爽。简单的把 AOP 理解为贯穿于方法之中，在方法执行前、执行时、执行后、返回值后、异常后要执行的操作。
它的核心是 “将程序中跨多个模块的通用功能（比如日志记录、事务管理、权限校验等）从业务逻辑中抽离出来，单独维护”，实现 “业务逻辑与通用功能的解耦”。
核心概念

切面（Aspect）

被抽离出来的通用功能模块，包含 “要增强的逻辑” 和 “在哪里增强”。可以认为是切入点(Pointcut)+通知(Advice)。

示例：日志记录、权限校验、事务管理等。

@Aspect
public class LoggingAspect &#123;
  @Before(&quot;execution(* com.example.service.*.*(..))&quot;)
  public void logBefore() &#123;
      System.out.println(&quot;Logging before method execution&quot;);
  &#125;
&#125;
- **连接点（Join Point）**  - 程序执行过程中**可插入切面的点**，例如方法调用、异常处理等，AOP允许在这些点上插入切面逻辑。在 Spring AOP 中，仅支持方法级别的连接点。  - **示例**：某个 Service 方法被调用时、Controller 返回响应前。- **切入点（Pointcut）**  - 定义 “**哪些连接点需要被增强**”，筛选出真正需要应用切面的位置。通常使用 @Pointcut 注解来定义切点表达式。  - 举个栗子：    ```java    // 匹配所有UserService类的方法    @Pointcut(&quot;execution(* com.example.service.UserService.*(..))&quot;)    // 匹配所有带@Log注解的方法    @Pointcut(&quot;@annotation(com.example.annotation.Log)&quot;)




通知（Advice）
指拦截到目标对象的连接点之后要做的事情，也可以称作切面中具体的增强逻辑。

前置通知（Before）：目标方法执行前。
后置通知（After）：目标方法执行后（无论是否异常）。
返回通知（AfterReturning）：目标方法正常返回后。
异常通知（AfterThrowing）：目标方法抛出异常时。
环绕通知（Around）：包裹目标方法，可自定义执行时机。


目标对象（Target）
就是被代理的对象，或者叫被切面增强的对象（即包含核心业务逻辑的类）。

代理（Proxy）
AOP 通过动态代理技术生成 “增强后的对象”。

两种代理方式：
JDK 动态代理：基于接口，代理对象实现目标接口。
CGLIB 代理：基于继承，代理对象继承目标类。




织入（Weaving）


  将切面逻辑插入目标对象，生成代理对象的过程。

发生时机：
编译时：如 AspectJ 编译时织入。
类加载时：如使用 LoadTimeWeaver。
运行时：如 Spring AOP 的动态代理。



AOP的使用场景有哪些？AOP 的使用场景有很多，比如说日志记录、事务管理、权限控制、性能监控等。

日志记录

添加 Maven 依赖
&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt;&lt;/dependency&gt;

定义日志注解（用于标记需要记录的方法）
import java.lang.annotation.*;@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Loggable &#123;    String value() default &quot;&quot;;  // 自定义操作描述    boolean recordParams() default true; // 是否记录参数    boolean recordResult() default true; // 是否记录返回值&#125;

实现日志切面
import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.*;import org.aspectj.lang.reflect.MethodSignature;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.stereotype.Component;import java.util.Arrays;@Aspect@Componentpublic class LoggingAspect &#123;    private static final Logger logger = LoggerFactory.getLogger(LoggingAspect.class);    // 切入点：所有带有自定义@Loggable注解的方法为切点    @Pointcut(&quot;@annotation(com.example.demo.Loggable)&quot;)    public void loggableMethods() &#123;&#125;    // 环绕通知（最灵活，可控制方法执行）    @Around(&quot;loggableMethods()&quot;)    public Object logAround(ProceedingJoinPoint joinPoint) throws Throwable &#123;        MethodSignature signature = (MethodSignature) joinPoint.getSignature();        Loggable loggable = signature.getMethod().getAnnotation(Loggable.class);                // 方法开始日志        long startTime = System.currentTimeMillis();        logMethodStart(joinPoint, loggable);                try &#123;            // 执行目标方法            Object result = joinPoint.proceed();                        // 方法结束日志            long executionTime = System.currentTimeMillis() - startTime;            logMethodEnd(joinPoint, loggable, result, executionTime);                        return result;        &#125; catch (Exception e) &#123;            // 异常日志            long executionTime = System.currentTimeMillis() - startTime;            logException(joinPoint, loggable, e, executionTime);            throw e;        &#125;    &#125;    private void logMethodStart(JoinPoint joinPoint, Loggable loggable) &#123;        String methodName = joinPoint.getSignature().toShortString();        String description = loggable.value().isEmpty() ? methodName : loggable.value();                StringBuilder logMessage = new StringBuilder();        logMessage.append(&quot;▶️ 开始执行: &quot;).append(description);                if (loggable.recordParams()) &#123;            Object[] args = joinPoint.getArgs();            logMessage.append(&quot; | 参数: &quot;).append(Arrays.toString(args));        &#125;                logger.info(logMessage.toString());    &#125;    private void logMethodEnd(JoinPoint joinPoint, Loggable loggable, Object result, long executionTime) &#123;        String methodName = joinPoint.getSignature().toShortString();        String description = loggable.value().isEmpty() ? methodName : loggable.value();                StringBuilder logMessage = new StringBuilder();        logMessage.append(&quot;✅ 执行完成: &quot;).append(description)                  .append(&quot; | 耗时: &quot;).append(executionTime).append(&quot;ms&quot;);                if (loggable.recordResult() &amp;&amp; result != null) &#123;            logMessage.append(&quot; | 结果: &quot;).append(result.toString());        &#125;                logger.info(logMessage.toString());    &#125;    private void logException(JoinPoint joinPoint, Loggable loggable, Exception e, long executionTime) &#123;        String methodName = joinPoint.getSignature().toShortString();        String description = loggable.value().isEmpty() ? methodName : loggable.value();                String errorMsg = String.format(&quot;❌ 执行异常: %s | 耗时: %dms | 异常: %s - %s&quot;,                description, executionTime, e.getClass().getSimpleName(), e.getMessage());                logger.error(errorMsg, e);    &#125;&#125;

在使用的地方加上自定义注解
@Servicepublic class UserService &#123;    @Loggable(value = &quot;创建用户&quot;, recordParams = true, recordResult = true)    public User createUser(String name, String email) &#123;        // 业务逻辑        return new User(name, email);    &#125;    @Loggable(&quot;获取用户列表&quot;)    public List&lt;User&gt; getUsers() &#123;        // 业务逻辑        return Arrays.asList(new User(&quot;Alice&quot;, &quot;alice@example.com&quot;));    &#125;    @Loggable(value = &quot;删除用户&quot;, recordResult = false)    public void deleteUser(Long id) &#123;        // 业务逻辑        if (id &lt;= 0) throw new IllegalArgumentException(&quot;无效的用户ID&quot;);    &#125;&#125;

日志输出示例

正常执行日志
▶️ 开始执行: 创建用户 | 参数: [John Doe, john@example.com]✅ 执行完成: 创建用户 | 耗时: 42ms | 结果: User&#123;name=&#x27;John Doe&#x27;, email=&#x27;john@example.com&#x27;&#125;

异常执行日志
▶️ 开始执行: 删除用户 | 参数: [-1]❌ 执行异常: 删除用户 | 耗时: 5ms | 异常: IllegalArgumentException - 无效的用户ID




事务管理
package com.example.aop.transaction;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.annotation.AfterThrowing;import org.aspectj.lang.annotation.Around;import org.aspectj.lang.annotation.Aspect;import org.aspectj.lang.annotation.Pointcut;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;/** * 事务切面，使用AOP控制事务边界 */@Aspect@Componentpublic class TransactionAspect &#123;        @Autowired    //负责事务的底层操作，包括获取连接、开启事务、提交 / 回滚事务等。    private TransactionManager transactionManager;        // 定义切入点：匹配所有Service包下的方法    @Pointcut(&quot;execution(* com.example.service.*.*(..))&quot;)    public void serviceMethods() &#123;&#125;        // 环绕通知：控制事务的开启、提交和回滚    @Around(&quot;serviceMethods()&quot;)    public Object around(JoinPoint joinPoint) throws Throwable &#123;        try &#123;            // 开启事务            transactionManager.beginTransaction();                        // 执行目标方法            Object result = joinPoint.proceed();                        // 提交事务            transactionManager.commit();                        return result;        &#125; catch (Exception e) &#123;            // 回滚事务            transactionManager.rollback();            throw e;        &#125;    &#125;        // 异常通知：当方法抛出异常时回滚事务    @AfterThrowing(pointcut = &quot;serviceMethods()&quot;, throwing = &quot;ex&quot;)    public void afterThrowing(JoinPoint joinPoint, Exception ex) &#123;        transactionManager.rollback();    &#125;&#125;    

说说 JDK 动态代理和 CGLIB 代理？AOP 是通过动态代理实现的，代理方式有两种：JDK 动态代理和 CGLIB 代理。
Spring AOP 默认优先使用 JDK 动态代理，当目标类 没有实现接口 时，会自动切换为 CGLIB 代理。如果希望强制使用 CGLIB 代理（即使目标类有接口），可以通过配置开启（如 @EnableAspectJAutoProxy(proxyTargetClass = true)）。



特性
JDK 动态代理
CGLIB 动态代理



依赖接口
必须实现接口
无需接口，基于继承


代理方式
生成实现接口的代理类
生成继承目标类的子类


性能
创建快，调用慢（反射）
创建慢，调用快（字节码）


适用场景
接口导向的框架（如 Spring AOP）
无接口的类（如 Spring 的 @Service)


说说 Spring AOP 和 AspectJ 的 区别?
定位不同
Spring AOP：Spring 框架的轻量级 AOP 实现，依赖 Spring IoC 容器，仅支持方法级别的增强。
AspectJ：独立的、功能完整的 AOP 框架，支持 方法调用、字段访问、构造函数、静态初始化 等各种连接点（Join Point），提供更强大的切面能力。


实现原理不同
Spring AOP：运行时基于代理（Proxy），通过 JDK 动态代理（接口代理）或 CGLIB（类代理）生成代理对象，在方法调用时插入切面逻辑。
AspectJ：编译期或类加载期织入字节码，直接修改目标类的字节码，将切面逻辑嵌入到目标方法中，无需代理对象。


功能范围不同
Spring AOP：仅支持 5 种通知类型（Before、After、AfterReturning、AfterThrowing、Around）和简单的切入点表达式（如 execution、@annotation）。
AspectJ：支持完整的 AspectJ 语法，包括 引介增强（@DeclareParents）、各种切入点类型（如 call、get、set）及更灵活的切面实例化模型（如 perthis、pertarget）。


性能不同
Spring AOP：运行时代理生成有一定开销，但多次调用后趋于稳定，适合大多数业务场景。
AspectJ：编译期织入无运行时开销，性能更优，适合对性能敏感的高频调用场景。


应用场景不同
Spring AOP：适用于 Spring 项目中的简单切面需求（如日志、事务、权限校验），与 Spring 生态无缝集成。
AspectJ：适用于 复杂切面需求（如拦截字段访问、静态方法）或 非 Spring 项目（如独立 Java 应用、Android 开发）。



Spring MVC什么是Spring MVC?Spring MVC 是 Spring 框架的一个模块，用于构建基于 Java 的 Web 应用程序。它遵循 MVC（Model-View-Controller）设计模式，将 Web 应用划分为三个核心组件：模型（Model）、视图（View） 和 控制器（Controller），以实现关注点分离，提高代码可维护性和可测试性。
Spring MVC的核心组件
DispatcherServlet（前端控制器）：作为请求的统一入口，接收所有 HTTP 请求并分发给相应的处理组件进行处理，并根据处理结果将响应返回给客户端。

HandlerMapping（处理器映射器）：确定哪个 Controller (或 Handler) 应该处理传入的请求。
它维护了一个请求 URL（或请求方法、参数等条件）到具体 Controller 方法的映射关系。DispatcherServlet 查询 HandlerMapping 来找到匹配当前请求的 Handler（通常是一个 Controller 的方法）和可选的拦截器链。常见的实现如 RequestMappingHandlerMapping (基于 @RequestMapping 注解)。

HandlerAdapter（处理器适配器）：负责实际调用找到的 Handler (通常是 Controller 方法) 来处理请求，并且适配不同类型的处理器。。 
因为 Handler 的实现方式可以多种多样（如基于 @Controller 注解的类、实现了 Controller 接口的旧式类、HttpRequestHandler 等），DispatcherServlet 需要一种统一的方式来调用它们。HandlerAdapter 屏蔽了不同 Handler 实现细节的差异，提供了统一的调用接口。常见的实现如 RequestMappingHandlerAdapter (用于调用 @RequestMapping 注解的方法)。

**Controller &#x2F; Handler (处理器&#x2F;控制器)**：处理具体的请求。它接收 DispatcherServlet 通过 HandlerAdapter 转发的请求，处理用户输入（解析参数、表单、请求体等），调用服务层进行业务处理，并返回一个包含模型数据和逻辑视图名的 ModelAndView 对象（或其它类型的返回值，如 ResponseEntity, String 视图名等）。通常使用 @Controller 或 @RestController 注解标记。

ModelAndView（模型与视图）：封装处理结果，包含模型数据（Model）和视图名称（View）。
装载了模型数据和视图信息，作为 Handler 的处理结果，返回给 DispatcherServlet。

ViewResolver（视图解析器）： 将 Controller 返回的逻辑视图名解析为实际的 View 对象。
Controller 通常返回一个字符串（如 &quot;userList&quot; 或 &quot;redirect:/success&quot;），这只是一个逻辑标识。ViewResolver 根据配置的规则（如视图前缀、后缀）将这个逻辑名映射到具体的视图技术实现（如 JSP 文件 /WEB-INF/views/userList.jsp, Thymeleaf 模板, FreeMarker 模板等）。常见的实现如 InternalResourceViewResolver (用于 JSP&#x2F;JSTL)。

View（视图）：负责渲染最终的响应内容（通常是 HTML）。
它使用 Model 中的数据，结合特定的视图技术（JSP, Thymeleaf, FreeMarker, PDF, JSON 等）来生成具体的输出（HTML, JSON, XML, PDF 等），并将其写入 HTTP 响应流。DispatcherServlet 将渲染任务委托给 View 对象。

HandlerInterceptor（拦截器）：在请求处理前后执行自定义逻辑（如日志记录、权限验证）。

ExceptionHandler（异常处理器）：统一处理控制器抛出的异常。

MultipartResolver（文件上传解析器）：处理文件上传请求。


Spring MVC 的工作原理.bzkxgkgelboo{zoom: 67%;}


请求到达：用户发送 HTTP 请求到 Web 服务器。
DispatcherServlet 接管：请求被配置好的 DispatcherServlet 捕获。
查找 Handler：DispatcherServlet 查询 HandlerMapping，根据请求 URL 等信息找到对应的 Handler (Controller 方法) 和拦截器链。
执行拦截器前置处理：如果配置了拦截器 (HandlerInterceptor)，执行其 preHandle 方法。
适配并执行 Handler：DispatcherServlet 通过合适的 HandlerAdapter 调用找到的 Handler (Controller 方法)。
Controller 处理： Controller 执行业务逻辑：
处理请求参数、表单数据、请求体等。
调用 Service 层。
将结果数据放入 Model。
返回一个结果（逻辑视图名 String, ModelAndView, ResponseEntity 等）。


执行拦截器后置处理：如果配置了拦截器，执行其 postHandle 方法（此时 Model 已填充）。
解析视图：DispatcherServlet 将 Controller 返回的逻辑视图名交给 ViewResolver 解析，得到具体的 View 对象。
渲染视图：DispatcherServlet 调用 View 对象的 render() 方法，传入 Model 数据。View 使用模型数据和特定技术生成响应内容（如 HTML）。
执行拦截器最终处理：如果配置了拦截器，执行其 afterCompletion 方法（无论成功或异常）。
返回响应： 生成的响应内容通过 DispatcherServlet 返回给 Web 服务器，最终发送给客户端。

事务Spring 事务的本质其实就是数据库对事务的支持，没有数据库的事务支持，Spring 是无法提供事务功能的。Spring 只提供统一事务管理接口，具体实现都是由各数据库自己实现，数据库事务的提交和回滚是通过数据库自己的事务机制实现。
Spring 管理事务的方式有几种？Spring 管理事务的方式主要分为两大类：声明式事务和编程式事务。声明式事务是首选和主流的方式，因为它更简洁、非侵入性且符合 Spring 的 AOP 理念。编程式事务则提供了更细粒度的控制，但代码侵入性强。

声明式事务（Declarative Transaction Management）
通过 AOP 实现事务管理，将事务逻辑与业务代码分离，降低耦合度。其本质是通过 AOP 功能，对方法前后进行拦截，将事务处理的功能编织到拦截的方法中，也就是在目标方法开始之前启动一个事务，在目标方法执行完之后根据执行情况提交或者回滚事务。
实现方式

基于 @Transactional 注解（最常用）

原理：利用 Spring AOP 动态代理在方法执行前后添加事务逻辑。
@Configuration@EnableTransactionManagement // 启用事务注解支持public class AppConfig &#123;    @Bean    public PlatformTransactionManager transactionManager(DataSource dataSource) &#123;        return new DataSourceTransactionManager(dataSource); // 配置事务管理器    &#125;&#125;@Servicepublic class UserService &#123;    @Transactional(        propagation = Propagation.REQUIRED, // 事务传播行为        isolation = Isolation.DEFAULT,      // 隔离级别        rollbackFor = Exception.class,      // 触发回滚的异常        timeout = 5                        // 超时时间（秒）    )    public void updateUser(User user) &#123;        // 业务逻辑（自动被事务包裹）    &#125;&#125;


基于 XML 配置（旧项目常用）

在 XML 中定义事务规则，无需修改源码：

&lt;!-- 配置事务管理器 --&gt;
&lt;bean id=&quot;txManager&quot; class=&quot;org.springframework.jdbc.datasource.DataSourceTransactionManager&quot;&gt;
    &lt;property name=&quot;dataSource&quot; ref=&quot;dataSource&quot;/&gt;
&lt;/bean&gt;

&lt;!-- 定义事务规则 --&gt;
&lt;tx:advice id=&quot;txAdvice&quot; transaction-manager=&quot;txManager&quot;&gt;
    &lt;tx:attributes&gt;
        &lt;tx:method name=&quot;update*&quot; propagation=&quot;REQUIRED&quot; rollback-for=&quot;Exception&quot;/&gt;
        &lt;tx:method name=&quot;get*&quot; read-only=&quot;true&quot;/&gt;
    &lt;/tx:attributes&gt;
&lt;/tx:advice&gt;

&lt;!-- 通过 AOP 应用事务 --&gt;
&lt;aop:config&gt;
    &lt;aop:advisor advice-ref=&quot;txAdvice&quot; 
        pointcut=&quot;execution(* com.example.service.*.*(..))&quot;/&gt;
&lt;/aop:config&gt;
       2. 编程式事务（Programmatic Transaction Management）   通过编写代码直接管理事务的生命周期，灵活性高但代码侵入性强。编程式事务可以使用 TransactionTemplate 和 PlatformTransactionManager 来实现，需要显式执行事务。允许我们在代码中直接控制事务的边界，通过编程方式明确指定事务的开始、提交和回滚。   实现方式   - **使用 `TransactionTemplate`（推荐编程式方案）**     ```java     @Service     public class OrderService &#123;         @Autowired         private TransactionTemplate transactionTemplate;              public void createOrder(Order order) &#123;             transactionTemplate.execute(status -&gt; &#123;                 try &#123;                     orderDao.save(order);                     inventoryService.deductStock(order.getProductId());                     return null; // 返回结果（可自定义）                 &#125; catch (Exception e) &#123;                     status.setRollbackOnly(); // 标记回滚                     throw e;                 &#125;             &#125;);         &#125;     &#125;




直接使用 PlatformTransactionManager（底层 API）
@Servicepublic class PaymentService &#123;    @Autowired    private PlatformTransactionManager txManager;    public void processPayment() &#123;        TransactionDefinition def = new DefaultTransactionDefinition();        TransactionStatus status = txManager.getTransaction(def);        try &#123;            paymentDao.executePayment();            txManager.commit(status); // 提交事务        &#125; catch (Exception e) &#123;            txManager.rollback(status); // 回滚事务            throw e;        &#125;    &#125;&#125;



Spring 事务的隔离级别Spring 事务的隔离级别（Isolation Level）是数据库事务处理中的核心概念，用于控制多个并发事务对同一数据的访问规则，解决脏读、不可重复读、幻读等问题。Spring 通过 @Transactional 注解的 isolation 属性支持标准的事务隔离级别，其底层依赖于数据库的实现。
@Transactional(isolation = Isolation.READ_COMMITTED)




隔离级别
脏读 (Dirty Read)
不可重复读 (Non-Repeatable Read)
幻读 (Phantom Read)
适用场景
性能影响



READ_UNCOMMITTED (读未提交)
❌ 可能发生
❌ 可能发生
❌ 可能发生
极低并发场景（几乎不用）
最高


READ_COMMITTED (读已提交)
✅ 禁止
❌ 可能发生
❌ 可能发生
多数数据库默认级别（如 Oracle）
较高


REPEATABLE_READ (可重复读)
✅ 禁止
✅ 禁止
❌ 可能发生
MySQL InnoDB 的默认级别
中等


SERIALIZABLE (串行化)
✅ 禁止
✅ 禁止
✅ 禁止
高一致性要求场景（如金融交易）
最低


DEFAULT (默认)
-
-
-
使用数据库的默认隔离级别（推荐）
依赖数据库



READ_UNCOMMITTED (读未提交)

问题：事务能读取其他事务未提交的数据（脏读）。

场景：
-- 事务AUPDATE account SET balance = 1000 WHERE id = 1; -- 未提交-- 事务B（READ_UNCOMMITTED）SELECT balance FROM account WHERE id = 1; -- 读到1000（脏数据）

风险：事务A若回滚，事务B读到的数据就是无效的。



READ_COMMITTED (读已提交)

解决：禁止脏读（只读已提交数据）。

遗留问题：不可重复读（同一事务内多次读同一数据结果不同）。

场景：
-- 事务B（第一次查询）SELECT balance FROM account WHERE id = 1; -- 返回1000-- 事务A提交更新UPDATE account SET balance = 900 WHERE id = 1;COMMIT;-- 事务B（第二次查询）SELECT balance FROM account WHERE id = 1; -- 返回900（两次读取结果不一致！）


REPEATABLE_READ (可重复读)

解决：禁止脏读、不可重复读。

遗留问题：幻读（同一查询条件返回的行数变化）。

场景（MySQL InnoDB 通过 MVCC 解决了幻读）：
-- 事务B（第一次查询）SELECT COUNT(*) FROM orders WHERE user_id = 1; -- 返回5条-- 事务A插入新订单并提交INSERT INTO orders(user_id) VALUES (1);COMMIT;-- 事务B（第二次查询）SELECT COUNT(*) FROM orders WHERE user_id = 1; -- 仍返回5条（避免幻读）


SERIALIZABLE (串行化)

解决：所有并发问题（通过强制事务串行执行）。

代价：性能严重下降（类似表级锁）。

场景：
-- 事务B执行查询（自动加共享锁）SELECT * FROM account WHERE id = 1;-- 事务A尝试更新（被阻塞，直到事务B结束）UPDATE account SET balance = 800 WHERE id = 1;



Spring 事务的传播机制Spring 事务的传播机制定义了 当一个事务方法被另一个事务方法调用时，如何管理事务的创建、嵌套和合并。这是 Spring 事务管理中最复杂且强大的特性之一，通过 @Transactional(propagation = Propagation.XXX) 枚举类提供 7 种传播行为。



传播行为
是否创建新事务
当前无事务时
异常影响范围
应用场景



REQUIRED
否（加入现有）
创建新事务
整个事务回滚
常规业务逻辑


SUPPORTS
否
非事务执行
无事务，异常不触发回滚
查询操作


MANDATORY
否
抛出异常
整个事务回滚
强制要求事务的敏感操作


REQUIRES_NEW
是
创建新事务
仅影响当前事务
日志记录、独立子操作


NOT_SUPPORTED
否
非事务执行
无事务，异常不触发回滚
非事务的性能敏感操作


NEVER
否
非事务执行
存在事务时抛出异常
禁止事务的操作


NESTED
否（嵌套事务）
创建新事务（同 REQUIRED）
嵌套事务回滚不影响外层，外层回滚嵌套也回滚
子操作可独立回滚的场景



REQUIRED（默认）

规则：

若当前存在事务，则加入该事务；
若不存在事务，则新建一个事务。


场景：
@Transactional(propagation = Propagation.REQUIRED)public void methodA() &#123;    methodB(); // 加入 methodA 的事务&#125;@Transactional(propagation = Propagation.REQUIRED)public void methodB() &#123; ... &#125;

用途：最常用的传播行为（如订单创建+库存扣减需在同一事务）。



SUPPORTS
规则：

若当前存在事务，则加入；
若不存在事务，则以非事务方式执行。


场景：查询方法（支持事务但不强制）。
@Transactional(propagation = Propagation.SUPPORTS)public User getUserById(Long id) &#123; ... &#125;

应用场景：查询方法（无需事务，但可参与外层事务）。



MANDATORY
规则：

若当前存在事务，则加入；
若不存在事务，则抛出异常（IllegalTransactionStateException）。


场景：强制要求调用方必须开启事务（如资金操作）。
@Transactionalpublic void methodA() &#123;    methodB(); // 正确：B 加入 A 的事务&#125;public void methodC() &#123;    methodB(); // 错误：抛出异常，因为 C 无事务&#125;@Transactional(propagation = Propagation.MANDATORY)public void methodB() &#123;    // 必须在事务中执行&#125;


REQUIRES_NEW
规则：

无论当前是否存在事务，都新建一个独立事务；
原事务（若有）被挂起，新事务执行完毕后再恢复。


场景：日志记录（即使主事务失败，日志仍需提交）。
@Transactionalpublic void methodA() &#123;    try &#123;        methodB(); // B 创建新事务，A 的事务挂起    &#125; catch (Exception e) &#123;        // B 的异常不影响 A 的事务    &#125;&#125;@Transactional(propagation = Propagation.REQUIRES_NEW)public void methodB() &#123;    // 独立事务&#125;


NOT_SUPPORTED
规则：

以非事务方式执行；
若当前存在事务，则挂起该事务。


场景：执行耗时操作（如文件处理），避免长事务阻塞。
@Transactionalpublic void methodA() &#123;    methodB(); // A 的事务挂起，B 以非事务方式执行&#125;@Transactional(propagation = Propagation.NOT_SUPPORTED)public void methodB() &#123;    // 非事务执行&#125;


NEVER
规则：

强制要求不在事务中执行；
若当前存在事务，则抛出异常。


场景：与事务不兼容的操作（如某些外部 API 调用）。
public void methodA() &#123;    methodB(); // 正确：A 无事务&#125;@Transactionalpublic void methodC() &#123;    methodB(); // 错误：抛出异常，因为 C 有事务&#125;@Transactional(propagation = Propagation.NEVER)public void methodB() &#123;    // 禁止在事务中执行&#125;


NESTED
规则：

若当前存在事务，则在嵌套事务中执行（使用保存点 Savepoint）；
若不存在事务，则同 REQUIRED（新建事务）。


特点：

嵌套事务回滚不影响主事务（除非主事务提交）；
主事务回滚会导致嵌套事务一起回滚。


场景：复杂业务中的子操作（如订单拆分子订单，子订单失败不影响主订单）。
@Transactionalpublic void methodA() &#123;    try &#123;        methodB(); // 嵌套事务    &#125; catch (Exception e) &#123;        // B 回滚，但 A 可以继续执行或提交    &#125;&#125;@Transactional(propagation = Propagation.NESTED)public void methodB() &#123;    // 嵌套事务，使用保存点&#125;



spring 声明式事务在哪些情况下会失效？
方法的访问权限问题
若事务方法的访问权限是 private、protected 或者默认的（包级私有），或者 final&#x2F;static方法，事务就会失效。因为Spring 默认使用基于 JDK 的动态代理（当接口存在时）或基于 CGLIB 的代理（当只有类时）来实现事务。

同类内部方法调用
@Servicepublic class UserService &#123;        public void saveUser(User user) &#123;        // 非事务方法调用事务方法        this.updateUser(user);     &#125;        @Transactional    public void updateUser(User user) &#123;        // 数据库操作    &#125;&#125;


原因：Spring 事务基于 AOP 代理，内部调用不走代理。

解决办法：

借助 ApplicationContext 来获取代理对象：
@Servicepublic class UserService &#123;        @Autowired    private ApplicationContext context;        public void saveUser(User user) &#123;        UserService proxy = context.getBean(UserService.class);        proxy.updateUser(user);    &#125;        @Transactional    public void updateUser(User user) &#123;        // 数据库操作    &#125;&#125;

通过构造函数注入自身代理：
@Servicepublic class UserService &#123;        private final UserService self;        @Autowired    public UserService(UserService self) &#123;        this.self = self;    &#125;        public void saveUser(User user) &#123;        self.updateUser(user);    &#125;        @Transactional    public void updateUser(User user) &#123;        // 数据库操作    &#125;&#125;




未被 Spring 容器管理
// ❌ 未加 @Service 注解public class ExternalService &#123;    @Transactional    public void process() &#123; ... &#125;&#125;

原因：非 Spring Bean 无法被代理。解决：确保类被注解标记（@Component, @Service 等）。

注解未被正确扫描
若 @Transactional 注解所在的类没有被 Spring 组件扫描到，或者没有启用事务支持，事务就会失效。
解决办法：确保配置了 @EnableTransactionManagement 注解：
@Configuration@EnableTransactionManagement@ComponentScan(&quot;com.example.service&quot;)public class AppConfig &#123;    // 配置类&#125;

异常类型不匹配
@Transactionalpublic void update() throws IOException &#123;    jdbcTemplate.update(...); // 抛 SQLException（RuntimeException 子类）    throw new IOException();  // 非 RuntimeException&#125;

原因：若事务方法抛出的异常不在 @Transactional 注解的 rollbackFor（ 用来指定能够触发事务回滚的异常类型 ） 范围内，事务将不会回滚。Spring 默认抛出未检查 unchecked 异常（继承自 RuntimeException 的异常）或者 Error 才回滚事务，其他异常不会触发回滚事务。
解决：显式指定回滚异常
@Transactional(rollbackFor = Exception.class)

异常被捕获未抛出
@Transactionalpublic void update() &#123;    try &#123;        jdbcTemplate.update(...); // 抛异常    &#125; catch (DataAccessException e) &#123;        // 吞掉异常 → 事务不会回滚！    &#125;&#125;

解决：在 catch 中抛出 RuntimeException 或手动回滚：
catch (Exception e) &#123;    TransactionAspectSupport.currentTransactionStatus().setRollbackOnly();    throw new BusinessException(e);&#125;

事务传播行为配置有误
要是事务传播行为配置成 PROPAGATION_SUPPORTS、PROPAGATION_NOT_SUPPORTED 或者 PROPAGATION_NEVER，在特定条件下事务会失效。
@Transactional(propagation = Propagation.NOT_SUPPORTED)public void doSomething() &#123;    // 此方法不会在事务中执行&#125;

解决办法：依据业务需求，合理选择传播行为，像 PROPAGATION_REQUIRED 就是常用的选择。
@Transactional(propagation = Propagation.REQUIRED)public void doSomething() &#123;    // 会加入当前事务或者创建新事务&#125;

多线程环境问题
在多线程环境中，由于每个线程拥有独立的事务上下文，子线程的事务不会影响主线程。
@Transactionalpublic void parentMethod() &#123;    new Thread(() -&gt; &#123;        // 子线程中的事务与主线程无关        childMethod();    &#125;).start();&#125;@Transactionalpublic void childMethod() &#123;    // 数据库操作&#125;

解决办法： 尽量避免在多线程中使用事务，或者采用其他方式来保证数据一致性。



]]></content>
      <categories>
        <category>面试题</category>
        <category>Spring面试题</category>
      </categories>
      <tags>
        <tag>面试题</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 2 - Java 类字节码</title>
    <url>/2025/05/22/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%202%20-%20Java%20%E7%B1%BB%E5%AD%97%E8%8A%82%E7%A0%81/</url>
    <content><![CDATA[Java虚拟机的组成Java虚拟机主要分为以下几个组成部分：


ClassLoader：类加载子系统，核心组件类加载器，负责将字节码文件中的内容加载到内存中。
JVM内存结构：运行时数据区，JVM管理的内存，创建出来的对象、类的信息等等内容都会放在这块区域中。
执行引擎：包含了即时编译器、解释器、垃圾回收器，执行引擎使用解释器将字节码指令解释成机器码，使用即时编译器优化性能，使用垃圾回收器回收不再使用的对象。
本地接口：调用本地使用C&#x2F;C++编译好的方法，本地方法在Java中声明时，都会带上native关键字，如下图所示。

字节码文件的组成
字节码文件比较难读，更加详细的请去官网https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html#jvms-6.5阅读。

字节码文件总共可以分为以下几个部分：

基础信息：魔数、字节码文件对应的Java版本号、访问标识(public final等等)、父类和接口信息
常量池：保存了字符串常量、类或接口名、字段名，主要在字节码指令中使用
字段： 当前类或接口声明的字段信息
方法： 当前类或接口声明的方法信息，核心内容为方法的字节码指令
属性： 类的属性，比如源码的文件名、内部类的列表等

通过 javac 类名.java 编译 java 文件后，会生成一个 .class 字节码文件！
以下是字节码文件：
0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 0000020 00 16 00 17 08 00 18 0a 00 19 00 1a 07 00 1b 07 0000040 00 1c 01 00 06 3c 69 6e 69 74 3e 01 00 03 28 29 0000060 56 01 00 04 43 6f 64 65 01 00 0f 4c 69 6e 65 4e 0000100 75 6d 62 65 72 54 61 62 6c 65 01 00 12 4c 6f 63 0000120 61 6c 56 61 72 69 61 62 6c 65 54 61 62 6c 65 01 0000140 00 04 74 68 69 73 01 00 1d 4c 63 6e 2f 69 74 63 0000160 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c 6f 0000200 57 6f 72 6c 64 3b 01 00 04 6d 61 69 6e 01 00 16 0000220 28 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 72 0000240 69 6e 67 3b 29 56 01 00 04 61 72 67 73 01 00 13 0000260 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 72 69 0000300 6e 67 3b 01 00 10 4d 65 74 68 6f 64 50 61 72 61 0000320 6d 65 74 65 72 73 01 00 0a 53 6f 75 72 63 65 46 0000340 69 6c 65 01 00 0f 48 65 6c 6c 6f 57 6f 72 6c 640000360 2e 6a 61 76 61 0c 00 07 00 08 07 00 1d 0c 00 1e 0000400 00 1f 01 00 0b 68 65 6c 6c 6f 20 77 6f 72 6c 64 0000420 07 00 20 0c 00 21 00 22 01 00 1b 63 6e 2f 69 74 0000440 63 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c 0000460 6f 57 6f 72 6c 64 01 00 10 6a 61 76 61 2f 6c 61 0000500 6e 67 2f 4f 62 6a 65 63 74 01 00 10 6a 61 76 61 0000520 2f 6c 61 6e 67 2f 53 79 73 74 65 6d 01 00 03 6f 0000540 75 74 01 00 15 4c 6a 61 76 61 2f 69 6f 2f 50 72 0000560 69 6e 74 53 74 72 65 61 6d 3b 01 00 13 6a 61 76 0000600 61 2f 69 6f 2f 50 72 69 6e 74 53 74 72 65 61 6d 0000620 01 00 07 70 72 69 6e 74 6c 6e 01 00 15 28 4c 6a 0000640 61 76 61 2f 6c 61 6e 67 2f 53 74 72 69 6e 67 3b 0000660 29 56 00 21 00 05 00 06 00 00 00 00 00 02 00 01 0000700 00 07 00 08 00 01 00 09 00 00 00 2f 00 01 00 01 0000720 00 00 00 05 2a b7 00 01 b1 00 00 00 02 00 0a 00 0000740 00 00 06 00 01 00 00 00 04 00 0b 00 00 00 0c 00 0000760 01 00 00 00 05 00 0c 00 0d 00 00 00 09 00 0e 00 0001000 0f 00 02 00 09 00 00 00 37 00 02 00 01 00 00 00 0001020 09 b2 00 02 12 03 b6 00 04 b1 00 00 00 02 00 0a 0001040 00 00 00 0a 00 02 00 00 00 06 00 08 00 07 00 0b 0001060 00 00 00 0c 00 01 00 00 00 09 00 10 00 11 00 00 0001100 00 12 00 00 00 05 01 00 10 00 00 00 01 00 13 00 0001120 00 00 02 00 14

根据 JVM 规范，类文件结构如下：

魔数第一行中有一串特殊的字符 cafebabe，它就是一个魔数，是 JVM 识别 class 文件的标志，JVM 会在验证阶段检查 class 文件是否以该魔数开头，如果不是则会抛出 ClassFormatError。
上面截图中
u4 magic对应字节码文件的 0~3 个字节0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09ca fe ba be ：意思是 .class 文件，不同的东西有不同的魔数，比如 jpg、png 图片等！
版本紧跟着魔数后面的四个字节 00 00 00 34 分别表示副版本号和主版本号。
u2 minor_version;u2 major_version;0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 0900 00 00 34：34H（16进制） &#x3D; 52（10进制），代表JDK8对应的版本号，副版本号为 0。
常量池参考地址：· The Java® Virtual Machine Specification (oracle.com) ·
紧跟在版本号之后的是常量池，它包含了类、接口、字段和方法的符号引用，以及字符串字面量和数值常量。这些信息在编译时被创建，并在运行时被Java虚拟机（JVM）使用。

学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 3 - Java 类加载机制</title>
    <url>/2025/05/23/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%203%20-%20Java%20%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[Java 类加载机制类的生命周期类从被加载到虚拟机内存中开始到卸载出内存为止，它的整个生命周期可以简单概括为 7 个阶段：加载、验证、准备、解析、初始化、使用和卸载。其中，验证、准备和解析这三个阶段可以统称为链接。

加载（Loading）
类加载器根据类的全限定名通过不同的渠道以二进制流的方式获取字节码信息，程序员可以使用Java代码拓展的不同的渠道。

从本地磁盘上获取文件
运行时通过动态代理生成，比如Spring框架
Applet技术通过网络获取字节码文件


类加载器在加载完类之后，Java虚拟机会将字节码中的信息保存到方法区中，方法区中生成一个InstanceKlass对象，保存类的所有信息，里边还包含实现特定功能比如多态的信息。
 

Java虚拟机同时会在堆上生成与方法区中数据类似的java.lang.Class对象，作用是在Java代码中去获取类的信息以及存储静态字段的数据（JDK8及之后）。
 


链接（Linking）链接阶段将加载的类准备好以供JVM使用，分为以下三个子阶段：
验证（Verification）此阶段会对字节码进行校验，确保其符合 Java 虚拟机规范，不会危害虚拟机的安全。验证过程包括：

文件格式验证：检查类文件的魔数（是否以0xCAFEBABE开头）、版本等基本结构。
元数据验证：检查类的内部结构，如字段、方法的描述符。
字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。
符号引用验证: 确保解析动作能正确执行。

准备（Preparation）准备阶段主要为类的静态变量分配内存，并设置其初始值（默认值）。注意一下几点：

static 变量分配空间和赋值是两个步骤，分配空间在准备阶段完成，赋值在初始化阶段完成。
这里所设置的初始值通常情况下是数据类型默认的零值(如0、0L、null、false等)。
如果 static 变量是 ﬁnal 的基本类型，以及字符串常量，那么编译阶段值就确定了，赋值在准备阶段完成
如果 static 变量是 ﬁnal 的，但属于引用类型，那么赋值也会在初始化阶段完成

解析（Resolution）解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。
初始化(Initialization)初始化阶段是类加载过程的最后一步，主要任务是执行类构造器()方法，该方法由编译器自动生成，用于初始化类的静态变量和执行静态块。初始化阶段包括：

执行静态变量的初始化赋值。
执行静态代码块。

类的初始化的懒惰的

以下情况会初始化

main 方法所在的类，总会被首先初始化
首次访问这个类的静态变量或静态方法时
子类初始化，如果父类还没初始化，会引发
子类访问父类的静态变量，只会触发父类的初始化
反射(如Class.forName)
创建类的实例，也就是new的方式


以下情况不会初始化

访问类的 static ﬁnal 静态常量（基本类型和字符串）
类对象.class 不会触发初始化
创建该类对象的数组
类加载器的.loadClass方法
Class.forNamed的参数2为false时




对上述准则的验证（注释下逐个验证）

public class Load2 &#123;    public static void main(String[] args) &#123;        // 不能初始化，final在准备阶段就已经赋值了        System.out.println(E.a);        // 不能初始化，final在准备阶段就已经赋值了        System.out.println(E.b);        // 会导致 E 类初始化，因为 Integer 是包装类        System.out.println(E.c);    &#125;&#125;class E &#123;    public static final int a = 10;    public static final String b = &quot;hello&quot;;    public static final Integer c = 20;    static &#123;        System.out.println(&quot;E cinit&quot;);    &#125;&#125;

public class Load3 &#123;    static &#123;        //在main类前面的静态代码块会优先初始化        System.out.println(&quot;main init&quot;);    &#125;    public static void main(String[] args) throws ClassNotFoundException &#123;        // 1. 静态常量（基本类型和字符串）不会触发初始化        System.out.println(B.b);        // 2. 类对象.class 不会触发初始化        System.out.println(B.class);        // 3. 创建该类的数组不会触发初始化        System.out.println(new B[0]);        // 4. 不会初始化类 B，但会加载 B、A        ClassLoader cl = Thread.currentThread().getContextClassLoader();        cl.loadClass(&quot;cn.itcast.jvm.t3.B&quot;);        // 5. 不会初始化类 B，但会加载 B、A        ClassLoader c2 = Thread.currentThread().getContextClassLoader();        Class.forName(&quot;cn.itcast.jvm.t3.B&quot;, false, c2);        // 1. 首次访问这个类的静态变量或静态方法时        System.out.println(A.a);        // 2. 子类初始化，如果父类还没初始化，会引发父类的初始化        System.out.println(B.c);        // 3. 子类访问父类静态变量，只触发父类初始化        System.out.println(B.a);        // 4. 会初始化类 B，并先初始化类 A        Class.forName(&quot;cn.itcast.jvm.t3.B&quot;);    &#125;&#125;class A &#123;    static int a = 0;    static &#123;        System.out.println(&quot;a init&quot;);    &#125;&#125;class B extends A &#123;    final static double b = 5.0;    static boolean c = false;    static &#123;        System.out.println(&quot;b init&quot;);    &#125;&#125;

使用类访问方法区内的数据结构的接口， 对象是Heap区的数据。
卸载Java虚拟机将结束生命周期的几种情况：

执行了System.exit()方法
程序正常执行结束
程序在执行过程中遇到了异常或错误而异常终止
由于操作系统出现错误而导致Java虚拟机进程终止

类加载器类加载器从 JDK 1.0 就出现了，最初只是为了满足 Java Applet（已经被淘汰） 的需要。后来，慢慢成为 Java 程序中的一个重要组成部分，赋予了 Java 类可以被动态加载到 JVM 中并执行的能力。
根据官方 API 文档的介绍:

类加载器是一个负责加载类的对象，用于实现类加载过程中的加载这一步。
每个 Java 类都有一个引用指向加载它的 ClassLoader。
数组类不是通过 ClassLoader 创建的（数组类没有对应的二进制字节流），是由 JVM 直接生成的。

简单来说，类加载器的主要作用就是动态加载 Java 类的字节码（ .class 文件）到 JVM 中（在内存中生成一个代表该类的 Class 对象）。
加载规则

动态加载机制
按需加载：Java 类在首次使用时才会被加载（如通过new实例化、调用静态方法 &#x2F; 字段等）。
运行时加载：类加载过程在程序运行期间完成，而非编译时。


类的唯一性
类的唯一性由 类加载器 + 类的全限定名（如java.lang.String） 共同确定。不同类加载器加载的同名类被视为不同的类。



类加载器类型


名称
加载的类
说明



Bootstrap ClassLoader（启动类加载器）
%JAVA_HOME%&#x2F;lib目录下的 rt.jar、resources.jar、charsets.jar等 jar 包和类
由 JVM 底层（C++）实现，Java 代码中无法直接引用。


Extension ClassLoader(拓展类加载器)
JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;ext
由sun.misc.Launcher$ExtClassLoader实现。


Application ClassLoader(应用程序类加载器)
当前应用 classpath 下的所有 jar 包和类
由sun.misc.Launcher$AppClassLoader实现，是ClassLoader类的默认加载器。


自定义类加载器
自定义
继承java.lang.ClassLoader并重写关键方法（如findClass()）。


寻找类加载器每个 ClassLoader 可以通过getParent()获取其父 ClassLoader，如果获取到 ClassLoader 为null的话，那么该类是通过 BootstrapClassLoader 加载的。
寻找类加载器例子如下:
 public class ClassLoaderTest &#123;    public static void main(String[] args) &#123;        ClassLoader loader = Thread.currentThread().getContextClassLoader();        System.out.println(loader);        System.out.println(loader.getParent());        System.out.println(loader.getParent().getParent());    &#125;&#125;   

结果如下:
sun.misc.Launcher$AppClassLoader@18b4aac2sun.misc.Launcher$ExtClassLoader@1b6d3586null

从上面的结果可以看出，并没有获取到ExtClassLoader的父Loader，原因是BootstrapLoader(引导类加载器)是由 C++ 实现，由于这个 C++ 实现的类加载器在 Java 中是没有与之对应的类的，所以拿到的结果是 null。
双亲委派模型Java采用了双亲委派模型来组织类加载器的层次结构。具体来说，当一个类加载器接收到类加载请求时，它会首先将请求委派给父类加载器处理，只有在父类加载器无法完成加载时，子类加载器才会尝试自己加载。这种机制确保了Java核心类库的安全性和一致性，避免了类的重复加载和命名冲突。
双亲委派机制过程

当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 
当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。
如果BootStrapClassLoader加载失败(例如在$JAVA_HOME&#x2F;jre&#x2F;lib里未查找到该class)，会使用ExtClassLoader来尝试加载。
若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。


loadClass源码解析：protected Class&lt;?&gt; loadClass(String name, boolean resolve)        throws ClassNotFoundException    &#123;        synchronized (getClassLoadingLock(name)) &#123;            // First, check if the class has already been loaded            //首先，检查类是否已经加载            Class&lt;?&gt; c = findLoadedClass(name);            if (c == null) &#123;                //说明该类没有被加载过                long t0 = System.nanoTime();                try &#123;                    //判断父类是否为空                    if (parent != null) &#123;                        //当父类的加载器不为空，则通过父类的loadClass来加载该类                        c = parent.loadClass(name, false);                    &#125; else &#123;                        //当父类的加载器为空，则调用启动类加载器来加载该类                        c = findBootstrapClassOrNull(name);                    &#125;                &#125; catch (ClassNotFoundException e) &#123;                    // ClassNotFoundException thrown if class not found                    // from the non-null parent class loader                    // 捕获异常但不处理，表示父类加载失败                &#125;                if (c == null) &#123;                    long t1 = System.nanoTime();                    //如果仍未找到，则调用 findClass 以查找该类。                     //用户可通过覆写该方法，来自定义类加载器                    c = findClass(name);                    // this is the defining class loader; record the stats                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);                    sun.misc.PerfCounter.getFindClasses().increment();                &#125;            &#125;            if (resolve) &#123;                resolveClass(c);            &#125;            return c;        &#125;    &#125;

自定义类加载器使用场景
想加载非 classpath 随意路径中的类文件
通过接口来使用实现，希望解耦时，常用在框架设计
这些类希望予以隔离，不同应用的同名类都可以加载，不冲突，常见于 tomcat 容器

步骤
继承ClassLoader父类
要遵从双亲委派机制，重写 ﬁndClass 方法
不是重写loadClass方法，否则不会走双亲委派机制
读取类文件的字节码
调用父类的 deﬁneClass 方法来加载类
使用者调用该类加载器的 loadClass 方法


ClassLoader 类有两个关键的方法：

protected Class loadClass(String name, boolean resolve)：加载指定二进制名称的类，实现了双亲委派机制 。name 为类的二进制名称，resolve 如果为 true，在加载时调用 resolveClass(Class&lt;?&gt; c) 方法解析该类。
protected Class findClass(String name)：根据类的二进制名称来查找类，默认实现是空方法。


学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>MySQL进阶</title>
    <url>/2025/06/10/MySQL/MySQL%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[MySQL进阶
此笔记由本人学习 B 站黑马程序员 MySQL 数据库视频进阶篇内容后，总结提取摘要制成。视频地址：黑马程序员 MySQL数据库入门到精通，从mysql安装到mysql高级、mysql优化全囊括

MySQL体系结构MySQL体系结构：连接层，服务层，引擎层，存储层。


连接层：处理客户端连接、认证和线程管理。
连接器（Connector）：
处理客户端连接请求，支持 TCP&#x2F;IP、Unix Socket、命名管道等连接方式。
验证用户身份（用户名、密码、主机权限）。
为每个连接分配线程（或从线程池获取）。


线程池（Thread Pool）：
管理数据库连接线程，减少频繁创建 &#x2F; 销毁线程的开销。
适用于高并发场景（如 MySQL Enterprise Edition）。




服务层：包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
SQL 接口（SQL Interface）：
接收 SQL 请求（SELECT、INSERT 等），返回查询结果。


查询解析器（Parser）：
对 SQL 语句进行词法和语法分析，生成解析树（Parse Tree）。
验证语句语法正确性（如关键字拼写、表名 &#x2F; 列名是否存在）。


预处理器（Preprocessor）：
进一步检查解析树的合法性（如权限检查、外键约束验证）。
替换别名、展开视图等操作。


查询优化器（Optimizer）：
生成最优执行计划（如选择索引、表连接顺序）。
支持成本优化（Cost-Based Optimization, CBO）和规则优化（Rule-Based Optimization, RBO）。


查询执行引擎（Execution Engine）：
根据执行计划调用存储引擎 API 执行查询。


缓存（Query Cache）：
缓存 SQL 语句及其结果（5.7 版本后逐渐弃用，8.0 版本移除）。
当数据发生变更时，相关缓存会被自动清除。




引擎层：负责数据的存储和检索。架构模式是插件式，服务器通过API和存储引擎进行通信。支持 InnoDB、MyISAM、Memory 等多个存储引擎。
插件式架构：支持多种存储引擎，通过统一接口与上层交互。
常见引擎：
InnoDB：默认引擎，支持事务、外键、行级锁。
MyISAM：不支持事务，表级锁，适合读多写少场景。
Memory：数据存储在内存，读写极快，重启丢失数据。
Archive：高度压缩，仅支持 INSERT&#x2F;SELECT，适合历史数据归档。


核心功能：
数据存储与检索（如 B + 树索引、哈希索引）。
事务处理（InnoDB）。
锁机制（行锁、表锁）。




存储层：MYSQL的物理存储部分，负责将数据(如: redolog、undolog、数据、索引、二进制日志、错误日志、查询 日志、慢查询日志等)存储在磁盘上。
数据文件：
.frm：存储表结构定义。
.ibd：InnoDB 独立表空间文件（存储数据和索引）。
.MYD&#x2F;.MYI：MyISAM 数据文件和索引文件。


日志文件：
二进制日志（Binlog）：记录数据变更，用于主从复制和恢复。
重做日志（Redo Log）：确保事务持久性，崩溃恢复。
回滚日志（Undo Log）：支持事务回滚和 MVCC。
错误日志（Error Log）：记录启动、运行时错误信息。
慢查询日志（Slow Query Log）：记录执行时间超过阈值的 SQL。


配置文件：
my.cnf&#x2F;my.ini：存储 MySQL 配置参数（如内存分配、字符集）。





存储引擎他是mysql数据库的核心，我们也需要在合适的场景选择合适的存储引擎。存储引擎是存储数据、建立索引、更新&#x2F;查询数据等技术的实现方式 。存储引擎是基于表的，而不是 基于库的，所以存储引擎也可被称为表类型。可以在创建表的时指定选择的存储引擎，没有指定将自动选择默认的存储引擎。

建表时指定存储引擎

CREATE TABLE 表名(字段1 字段1类型 [ COMMENT 字段1注释 ] ,......字段n 字段n类型 [COMMENT 字段n注释 ]) ENGINE = INNODB [ COMMENT 表注释 ] ;


查询当前数据库支持的存储引擎

show engines;

MySQL 支持多种存储引擎，每种引擎都有其独特的特性和适用场景。以下是常见存储引擎的对比及选择建议。
InnoDB介绍InnoDB是一种兼顾高可靠性和高性能的通用存储引擎，在 MySQL 5.5 之后，InnoDB是默认的 MySQL 存储引擎。
特点
DML操作遵循ACID模型，支持事务；
行级锁，提高并发访问性能；
支持外键FOREIGN KEY约束，保证数据的完整性和正确性；

文件结构
xxx.ibd：xxx代表的是表名，innoDB引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm-早期的 、sdi-新版的）、数据和索引。

参数：innodb_file_per_table


  show variables like &#x27;innodb_file_per_table&#x27;


  如果该参数开启，代表对于InnoDB引擎的表，每一张表都对应一个ibd文件。ibd文件中不仅存放表结构、数据还会存放该表对应的索引信息。 而该文件是基于二进制存储的，不能直接基于记事本打开，我们可以使用mysql提供的一个指令 ibd2sdi ，通过该指令就可以从ibd文件中提取sdi信息，而sdi数据字典信息中就包含该表的表结构。
逻辑存储结构

表空间 : InnoDB存储引擎逻辑结构的最高层，ibd文件其实就是表空间文件，在表空间中可以包含多个Segment段。
段 : 表空间是由各个段组成的， 常见的段有数据段、索引段、回滚段等。InnoDB中对于段的管理，都是引擎自身完成，不需要人为对其控制，一个段中包含多个区。
区 : 区是表空间的单元结构，每个区的大小为1M。 默认情况下， InnoDB存储引擎页大小为16K， 即一个区中一共有64个连续的页。
页 : 页是组成区的最小单元，页也是InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区。
行 : InnoDB 存储引擎是面向行的，也就是说数据是按行进行存放的，在每一行中除了定义表时所指定的字段以外，还包含两个隐藏字段(后面会详细介绍)。

适用场景
事务性应用（如电商、金融系统）。
高并发读写场景。
需要外键约束的表。

MyISAM介绍MyISAM是MySQL早期的默认存储引擎。
特点
不支持事务，不支持外键
支持表锁，不支持行锁
优点：更少的存储空间，支持全文索引，适用于读取频率较高、写入频率较低的应用场景

文件结构
xxx.sdi：存储表结构信息

xxx.MYD: 存储数据

xxx.MYI: 存储索引



适用场景
只读或写入少、查询多的场景（如日志表、统计数据）。
不需要事务支持的场景。

Memory介绍Memory引擎的表数据时存储在内存中的，由于受到硬件问题、或断电问题的影响，只能将这些表作为临时表或缓存使用。
特点
数据存储在内存：读写速度极快，但重启后数据丢失。
支持哈希索引：适合快速查找。
表级锁：并发性能有限。

文件结构
xxx.sdi：存储表结构信息
数据， 都在内存中

适用场景
临时表&#x2F;中间结果集： MySQL 内部自动使用。
高速缓存： 存储频繁访问的小型、非关键、可丢失的只读&#x2F;低频写数据（如会话信息、配置）。
需要极低延迟访问的只读查询。

重要警告： 绝对不要用于存储重要或持久化数据。内存有限，大表易导致 OOM。
InnoDB, MyISAM, Memory的区别，使用场景

面试题:InnoDB引擎与MyISAM引擎的区别 ?①. InnoDB引擎, 支持事务, 而MyISAM不支持。②. InnoDB引擎, 支持行锁和表锁, 而MyISAM仅支持表锁, 不支持行锁。③. InnoDB引擎, 支持外键, 而MyISAM是不支持的。

索引介绍索引（index）是帮助MySQL高效获取数据的数据结构(有序)。在数据之外，数据库系统还维护着满足 特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据， 这样就可以在这些数据结构 上实现高级查找算法，这种数据结构就是索引。它类似于书籍的目录，允许数据库快速定位特定数据，避免全表扫描。

特点


优势
劣势



提高数据检索的效率，降低数据库 的IO成本
索引列也是要占用空间的。


通过索引列对数据进行排序，降低 数据排序的成本，降低CPU的消耗。
索引大大提高了查询效率，同时却也降低更新表的速度， 如对表进行INSERT、UPDATE、DELETE时，效率降低。






索引结构概述MySQL的索引是在存储引擎层实现的，不同的存储引擎有不同的索引结构，主要包含以下几种：

上述是MySQL中所支持的所有的索引结构，接下来，我们再来看看不同的存储引擎对于索引结构的支持 情况。


注意： 我们平常所说的索引，如果没有特别指明，都是指B+树结构组织的索引。

二叉树假如说MySQL的索引结构采用二叉树的数据结构，比较理想的结构如下：

如果主键是顺序插入的，则会形成一个单向链表，结构如下：

所以，如果选择二叉树作为索引结构，会存在以下缺点：

顺序插入时，会形成一个链表，查询性能大大降低。
大数据量情况下，层级较深，检索速度慢。

此时大家可能会想到，我们可以选择红黑树，红黑树是一颗自平衡二叉树，那这样即使是顺序插入数 据，最终形成的数据结构也是一颗平衡的二叉树,结构如下:

但是，即使如此，由于红黑树也是一颗二叉树，所以也会存在一个缺点：

解决二叉树的顺序插入后，树不平衡的问题。
大数据量情况下，层级较深，检索速度慢。

B-TreeB-Tree，B树是一种多叉路衡查找树，相对于二叉树，B树每个节点可以有多个分支，即多叉。 以一颗最大度数（max-degree）为5(5阶)的b-tree为例，那这个B树每个节点最多存储4个key，5 个指针：


知识小贴士: 树的度数指的是一个节点的子节点个数。

我们可以通过一个数据结构可视化的网站来简单演示一下。B-Tree Visualization (usfca.edu)

插入一组数据： 100 65 169 368 900 556 780 35 215 1200 234 888 158 90 1000 88 120 268 250 。然后观察一些数据插入过程中，节点的变化情况。

特点：

5阶的B树，每一个节点最多存储4个key，对应5个指针。
一旦节点存储的key数量到达5，就会裂变，中间元素向上分裂。
在B树中，非叶子节点和叶子节点都会存放数据。

B+TreeB+Tree是B-Tree的变种，我们以一颗最大度数（max-degree）为4（4阶）的b+tree为例，来看一 下其结构示意图：

我们可以看到，两部分： 

绿色框框起来的部分，是索引部分，仅仅起到索引数据的作用，不存储数据。 
红色框框起来的部分，是数据存储部分，在其叶子节点中要存储具体的数据。

通过一个数据结构可视化的网站来简单演示一下。[B+ Tree Visualization (usfca.edu)

插入一组数据： 100 65 169 368 900 556 780 35 215 1200 234 888 158 90 1000 88 120 268 250 。然后观察一些数据插入过程中，节点的变化情况。

最终我们看到，B+Tree 与 B-Tree相比，主要有以下三点区别： 

所有的数据都会出现在叶子节点。 
叶子节点形成一个单向链表。
非叶子节点仅仅起到索引数据作用，具体的数据都是在叶子节点存放的。

MySQL优化后的B+ Tree：
上述我们所看到的结构是标准的B+Tree的数据结构，接下来，我们再来看看MySQL中优化之后的 B+Tree。 MySQL索引数据结构对经典的B+Tree进行了优化。在原B+Tree的基础上，增加一个指向相邻叶子节点 的链表指针，就形成了带有顺序指针的B+Tree，提高区间访问的性能，利于排序。

Hash哈希索引就是采用一定的hash算法，将键值换算成新的hash值，映射到对应的槽位上，然后存储在hash表中。

如果两个(或多个)键值，映射到一个相同的槽位上，他们就产生了hash冲突（也称为hash碰撞），可 以通过链表来解决。

特点：

Hash索引只能用于对等比较(&#x3D;，in)，不支持范围查询（between，&gt;，&lt; ，…）。
无法利用索引完成排序操作。
查询效率高，通常(不存在hash冲突的情况)只需要一次检索就可以了，效率通常要高于B+tree索引。

在MySQL中，支持hash索引的是Memory存储引擎。 而InnoDB中具有自适应hash功能，hash索引是 InnoDB存储引擎根据B+Tree索引在指定条件下自动构建的。

为什么 InnoDB 存储引擎选择使用 B+tree 索引结构?

相对于二叉树，层级更少，搜索效率高；
对于B-tree，无论是叶子节点还是非叶子节点，都会保存数据，这样导致一页中存储 的键值减少，指针跟着减少，要同样保存大量数据，只能增加树的高度，导致性能降低；
相对Hash索引，B+tree支持范围匹配及排序操作；


索引分类在MySQL数据库，将索引的具体类型主要分为以下几类：主键索引、唯一索引、常规索引、全文索引。

而在InnoDB存储引擎中，根据索引的存储形式，又可以分为以下两种：

聚集索引选取规则：

如果存在主键，主键索引就是聚集索引。 
如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引。
如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引。

聚集索引和二级索引的具体结构如下：


聚集索引的叶子节点下挂的是这一行的数据 。
二级索引的叶子节点下挂的是该字段值对应的主键值。

回表查询先到二级索引中查找数据，找到主键值，然后再到聚集索引中根据主键值，获取 数据的方式，就称之为回表查询。
当我们执行如下的SQL语句时，具体的查找过程是什么样子的。

具体过程如下:
①. 由于是根据name字段进行查询，所以先根据name&#x3D;’Arm’到name字段的二级索引中进行匹配查 找。但是在二级索引中只能查找到 Arm 对应的主键值 10。
②. 由于查询返回的数据是*，所以此时，还需要根据主键值10，到聚集索引中查找10对应的记录，最 终找到10对应的行row。
③. 最终拿到这一行的数据，直接返回即可。
思考题
以下两条SQL语句，那个执行效率高? 为什么?

​	A. select * from user where id &#x3D; 10 ;​	B. select * from user where name &#x3D; ‘Arm’ ; 备注: id为主键，name字段创建的有索引；
解答： A 语句的执行性能要高于B 语句。 因为A语句直接走聚集索引，直接返回数据。 而B语句需要先查询name字段的二级索引，然 后再查询聚集索引，也就是需要进行回表查询。

InnoDB主键索引的B+tree高度为多高呢?

假设: 一行数据大小为1k，一页中可以存储16行这样的数据。InnoDB的指针占用6个字节的空 间，主键即使为bigint，占用字节数为8。 
关键公式：每个非叶子节点的索引条目数 n 需满足：n × 主键大小 + (n + 1) × 指针大小 ≤ 页大小。

n × 8 ：n 个主键值的总字节数；
(n + 1) × 6 ：n+1 个指针的总字节数（每个节点至少有 n+1 个指针指向子节点）。
算出n约为 1170，也就是说每个非叶子节点最多存储 1170 个索引条目，对应 1171 个子节点（n+1）。

B + 树高度为 2 时的最大数据量：

树结构：非叶子节点（根节点）+ 叶子节点。
叶子节点数量：根节点的子节点数 &#x3D; 1171 个。
每个叶子节点存储数据量：16 行（由页大小决定）。
总数据量：1170 × 16 = 18,720条。可以存储 18000 多条记录。

B + 树高度为 3 时的最大数据量：

树结构：根节点 + 中间层 + 叶子层。
叶子节点数量：根节点的子节点数 &#x3D; 1171 个。
每个叶子节点存储数据量：16 行（由页大小决定）。
总数据量：1170 × 1170 × 16 = 21,902,400条。可以存储 2190w 多条记录。

索引语法
创建索引

CREATE [ UNIQUE | FULLTEXT ] INDEX index_name ON table_name (index_col_name,... ) ;


查看索引

SHOW INDEX FROM table_name ;


删除索引

DROP INDEX index_name ON table_name ;

SQL性能分析SQL执行频率MySQL 客户端连接成功后，通过 show [session|global] status 命令可以提供服务器状态信 息。通过如下指令，可以查看当前数据库的INSERT、UPDATE、DELETE、SELECT的访问频次：

– session 是查看当前会话 ; 
– global 是查询全局数据 ; 
SHOW GLOBAL STATUS LIKE ‘Com_______’

通过查询SQL的执行频次，我们就能够知道当前数据库到底是增删改为主，还是查询为主。 那假 如说是以查询为主，我们又该如何定位针对于那些查询语句进行优化呢？ 次数我们可以借助于慢查询 日志。
慢查询日志慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有 SQL语句的日志。
MySQL的慢查询日志默认没有开启，我们可以查看一下系统变量 slow_query_log。（默认是关闭的）。
show variables like &#x27;slow_query_log&#x27;;

如果要开启慢查询日志，需要在MySQL的配置文件中配置如下信息：

Windows 下通常位于 MySQL 安装目录或 C:\ProgramData\MySQL\MySQL Server X.Y。
Linux 下（&#x2F;etc&#x2F;my.cnf）。

[mysqld]# 启用慢查询日志slow_query_log = 1# 指定慢查询日志文件路径slow_query_log_file = &quot;C:/ProgramData/MySQL/MySQL Server 8.0/slow_query.log&quot;# 设置慢查询阈值（单位：秒）long_query_time = 10# 可选：记录未使用索引的查询# log_queries_not_using_indexes = 1# 可选：记录管理语句（如 OPTIMIZE TABLE）# log_slow_admin_statements = 1

重启MySQL 服务，然后，再次查看开关情况，慢查询日志就已经打开了。
测试：

执行如下SQL语句 ：
SELECT SLEEP(11);

打开慢日志文件，检查慢查询日志 ：
# Time: 2025-06-16T08:26:30.451314Z# User@Host: root[root] @ localhost [::1]  Id:     4# Query_time: 11.007434  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 0use huanyuan2;SET timestamp=1750062390;SELECT SLEEP(11);

那这样，通过慢查询日志，就可以定位出执行效率比较低的SQL，从而有针对性的进行优化。


profile详情show profiles 能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。

通过have_profiling 参数，能够看到当前MySQL是否支持profile操作：
SELECT @@have_profiling ;



查看当前数据库是否打开了 profiling ：
select @@profiling;




可以看到，当前MySQL是支持 profile操作的，但是开关是关闭的。可以通过set语句在 session/global级别开启profiling：
SET profiling = 1;

profile 开关打开后，我们所执行的SQL语句，都会被MySQL记录，并记录执行时间消耗到哪儿去 了。
可以通过如下指令查看指令的执行耗时：
-- 查看每一条SQL的耗时基本情况show profiles;-- 查看指定query_id的SQL语句各个阶段的耗时情况show profile for query query_id;-- 查看指定query_id的SQL语句CPU的使用情况show profile cpu for query query_id;

explainEXPLAIN 或者 DESC命令获取 MySQL 如何执行 SELECT 语句的信息，包括在 SELECT 语句执行 过程中表如何连接和连接的顺序。
-- 直接在select语句之前加上关键字 explain / descEXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件 ;


Explain 执行计划中各个字段的含义:



字段
含义



id
select查询的序列号，表示查询中执行select子句或者是操作表的顺序 (id相同，执行顺序从上到下；id不同，值越大，越先执行)。


select_type
表示 SELECT 的类型，常见的取值有 SIMPLE（简单表，即不使用表连接 或者子查询）、PRIMARY（主查询，即外层的查询）、 UNION（UNION 中的第二个或者后面的查询语句）、 SUBQUERY（SELECT&#x2F;WHERE之后包含了子查询）等


type
表示连接类型，性能由好到差的连接类型为NULL、system、const、 eq_ref、ref、range、 index、all 。


possible_key
显示可能应用在这张表上的索引，一个或多个。


key
实际使用的索引，如果为NULL，则没有使用索引。


key_len
表示索引中使用的字节数， 该值为索引字段最大可能长度，并非实际使用长 度，在不损失精确性的前提下， 长度越短越好 。


rows
MySQL认为必须要执行查询的行数，在innodb引擎的表中，是一个估计值， 可能并不总是准确的。


filtered
表示返回结果的行数占需读取行数的百分比， filtered 的值越大越好。


Extra
包含查询的额外信息，是优化的重要参考


Extra关键值解析：

Using index：使用 “覆盖索引”（查询的列都在索引中，无需回表查数据），效率高。
Using where：使用WHERE子句过滤行，但未使用索引（可能是全表扫描后过滤）。
Using temporary：MySQL 需要创建临时表存储结果（如GROUP BY非索引列、DISTINCT处理），性能较差，需优化。
Using filesort：MySQL 需要对结果进行排序（未使用索引排序），需优化（如添加排序索引）。
Using join buffer：多表关联时未使用索引，使用连接缓冲区，效率低。
Impossible WHERE：WHERE条件永远为FALSE（如WHERE 1=0），无数据返回。
Range checked for each record：MySQL 无法确定合适的索引，需为每行检查可能的索引，效率低。

索引使用优化单列索引与联合索引单列索引：即一个索引只包含单个列。
联合索引：即一个索引包含了多个列。
我们先来看看 tb_user 表中目前的索引情况:

在查询出来的索引中，既有单列索引，又有联合索引。
接下来，我们来执行一条SQL语句，看看其执行计划：

通过上述执行计划我们可以看出来，在and连接的两个字段 phone、name上都是有单列索引的，但是最终mysql只会选择一个索引，也就是说，只能走一个字段的索引，此时是会回表查询的。
接着，我们再来创建一个phone和name字段的联合索引来查询一下执行计划。
create unique index idx_user_phone_name on tb_user(phone,name);


此时，查询时，就走了联合索引，而在联合索引中包含 phone、name的信息，在叶子节点下挂的是对 应的主键id，所以查询是无需回表查询的。

在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引， 而非单列索引。

.ijvgqrhgqssf{zoom:67%;}

前缀索引当字段类型为字符串（varchar，text，longtext等）时，有时候需要索引很长的字符串，这会让 索引变得很大，查询时，浪费大量的磁盘IO， 影响查询效率。此时可以只将字符串的一部分前缀，建立索引，这样可以大大节约索引空间，从而提高索引效率。

语法
create index idx_xxxx on table_name(column(n)) ;

前缀长度
可以根据索引的选择性来决定，而选择性是指不重复的索引值（基数）和数据表的记录总数的比值， 索引选择性越高则查询效率越高， 唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。
# 查询使用email整个字符串的索引选择比   1.0000select count(distinct email) / count(*) from tb_user;# 查询使用email 使用前缀5个字符串的索引选择比  0.9583select count(distinct substring(email,1,5)) / count(*) from tb_user ;# 查询使用email 使用前缀2个字符串的索引选择比   0.9167select count(distinct substring(email,1,2)) / count(*) from tb_user ;# 对字段email建立前缀索引，前缀长度为5  create index email_idx on tb_user(email(5));# 查看使用email前缀索引进行查询的执行结构explain select * from tb_user where email = &#x27;xiaoyu666@qq.com&#x27;; 

前缀索引的查询流程



最左前缀法则如果索引了多列（联合索引），要遵守最左前缀法则。最左前缀法则指的是查询条件必须从复合索引的最左列开始，并且不能跳过中间列。如果跳跃某一列，索引将会部分失效(后面的字段索引失效)。
🧩 四种典型使用场景分析CREATE INDEX idx_name_age_city ON users (    last_name,  -- 最左列    age,        -- 中间列    city        -- 最右列);

✅ 场景 1：完整使用索引 (最佳)SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;   AND age = 30   AND city = &#x27;New York&#x27;;

索引使用：(last_name, age, city) 三列全使用👉 查询效率最高
✅ 场景 2：使用最左连续列SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;   AND age = 30;

索引使用：(last_name, age) 两列👉 有效使用索引
✅ 场景 3：仅使用最左列SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;;

索引使用：(last_name) 单列👉 有效但非最优
❌ 场景 4：违反最左前缀（常见错误）-- 错误1：跳过最左列SELECT * FROM users WHERE age = 30;-- 错误2：缺少中间列SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;   AND city = &#x27;New York&#x27;; -- 跳过age列

索引使用：无法使用索引或仅部分使用👉 全表扫描风险
✅ 场景 5：条件编写的先后顺序以下代码索引会失效吗？
SELECT * FROM users WHERE  age = 30  AND  city = &#x27;New York&#x27;  AND  last_name = &#x27;Smith&#x27;;

答案：不会，MySQL 优化器会自动重排条件顺序：
-- 优化器重写后的等效查询SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;  -- 最左列  AND age = 30            -- 第二列  AND city = &#x27;New York&#x27;;  -- 第三列


注意 ： 最左前缀法则中指的最左边的列，是指在查询时，联合索引的最左边的字段(即是 第一个字段)必须存在，与我们编写SQL时，条件编写的先后顺序无关。

索引失效情况🚫 1. 违反最左前缀法则（复合索引）-- 复合索引: (last_name, age, city)SELECT * FROM users WHERE age = 30; -- 缺少最左列SELECT * FROM users WHERE city = &#x27;New York&#x27;; -- 缺少最左列SELECT * FROM users WHERE last_name = &#x27;Smith&#x27; AND city = &#x27;New York&#x27;; -- 跳过中间列

✅ 解决方案：

调整查询条件顺序
创建新索引：CREATE INDEX idx_age_city ON users(age, city)

🚫 2. 在索引列上使用函数或计算-- 索引: created_atSELECT * FROM orders WHERE YEAR(created_at) = 2023; -- 函数操作SELECT * FROM products WHERE price * 1.1 &gt; 100; -- 计算操作

✅ 解决方案：

使用范围查询替代：
SELECT * FROM orders WHERE created_at BETWEEN &#x27;2023-01-01&#x27; AND &#x27;2023-12-31&#x27;;

预先计算存储：
ALTER TABLE products ADD COLUMN price_with_tax DECIMAL(10,2) AS (price * 1.1);CREATE INDEX idx_price_tax ON products(price_with_tax);

🚫 3. 隐式类型转换-- phone 是 VARCHAR 索引列SELECT * FROM customers WHERE phone = 13800138000; -- 数字 vs 字符串

✅ 解决方案：
SELECT * FROM customers WHERE phone = &#x27;13800138000&#x27;; -- 保持类型一致

🚫 4. 使用 OR 连接非索引列-- 只有 name 有索引SELECT * FROM users WHERE name = &#x27;John&#x27; OR email = &#x27;john@example.com&#x27;; -- email 无索引

用or分割开的条件， 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会 被用到。
✅ 解决方案：

创建联合索引

拆分为两个查询 UNION：
SELECT * FROM users WHERE name = &#x27;John&#x27;UNIONSELECT * FROM users WHERE email = &#x27;john@example.com&#x27;;

🚫 5. LIKE 以通配符开头如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。
-- 索引: emailSELECT * FROM users WHERE email LIKE &#x27;@gmail.com%&#x27;; -- 后导通配符SELECT * FROM users WHERE email LIKE &#x27;%@gmail.com&#x27;; -- 前导通配符 索引失效

🚫 6. 范围查询后的列失效联合索引中，出现范围查询(&gt;,&lt;)，范围查询右侧的列索引失效。
-- 复合索引: (category, price, rating)SELECT * FROM products WHERE category = &#x27;Electronics&#x27;   AND price &gt; 1000   AND rating &gt; 4; -- rating 无法使用索引

✅ 解决方案：

调整索引列顺序：
CREATE INDEX idx_category_rating_price ON products(category, rating, price); -- 让等值条件和高选择性范围查询优先使用索引

使用覆盖索引：
CREATE INDEX idx_cover ON products(category, price, rating, product_id);

使用 &gt;&#x3D;：
SELECT * FROM products WHERE category = &#x27;Electronics&#x27;   AND price &gt;= 1000   AND rating &gt; 4; -- 在业务允许的情况下，尽可能的使用类似于 &gt;= 或 &lt;= 这类的范围查询，而避免使用 &gt; 或 &lt; 。

🚫 7. 使用 != 或 &lt;&gt;-- 索引: statusSELECT * FROM orders WHERE status != &#x27;completed&#x27;;

✅ 解决方案：

改为范围查询：
SELECT * FROM orders WHERE status &lt; &#x27;completed&#x27; OR status &gt; &#x27;completed&#x27;;

使用特定值列表：
SELECT * FROM orders WHERE status IN (&#x27;pending&#x27;, &#x27;processing&#x27;, &#x27;cancelled&#x27;);

🚫 8. 索引列使用 IS NULL&#x2F;IS NOT NULL-- 索引: phoneSELECT * FROM customers WHERE phone IS NOT NULL; -- 可能失效

✅ 解决方案：

添加条件限制：
SELECT * FROM customers WHERE phone IS NOT NULL AND phone &gt; &#x27;&#x27;; -- 利用索引扫描

使用覆盖索引：
CREATE INDEX idx_phone_cover ON customers(phone) INCLUDE (name, email);

🚫 9. 数据分布不均导致优化器放弃索引-- 索引: status (90% 值为 &#x27;active&#x27;)SELECT * FROM products WHERE status = &#x27;active&#x27;; -- 可能全表扫描

✅ 解决方案：

强制使用索引：
SELECT * FROM products FORCE INDEX(idx_status) WHERE status = &#x27;active&#x27;;

调整优化器设置：
SET optimizer_switch=&#x27;index_condition_pushdown=off&#x27;;

🚫 10. 使用 NOT IN-- 索引: categorySELECT * FROM products WHERE category NOT IN (&#x27;Books&#x27;, &#x27;Clothing&#x27;);

✅ 解决方案：

改用 NOT EXISTS：
SELECT * FROM products pWHERE NOT EXISTS (  SELECT 1 FROM excluded_categories e   WHERE e.category = p.category);

使用左连接：
SELECT p.* FROM products pLEFT JOIN excluded_categories e ON p.category = e.categoryWHERE e.category IS NULL;

SQL提示SQL提示，是优化数据库的一个重要手段，简单来说，就是在SQL语句中加入一些人为的提示来达到优化操作的目的。

use index ： 建议MySQL使用哪一个索引完成此次查询（仅仅是建议，mysql内部还会再次进 行评估）。

   explain select * from tb_user use index(idx_user_pro) where profession = &#x27;软件工程&#x27;;


ignore index ： 忽略指定的索引。

   explain select * from tb_user ignore index(idx_user_pro) where profession = &#x27;软件工程&#x27;;


force index ： 强制使用索引。
explain select * from tb_user force index(idx_user_pro) where profession = &#x27;软件工程&#x27;;

覆盖索引尽量使用覆盖索引，减少select *。 那么什么是覆盖索引呢？ 覆盖索引是指查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到 。
执行计划 EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件  查询结果中 Extra 的含义：



Extra
含义



Using where; Using Index
查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据


Using index condition
查找使用了索引，但是需要回表查询数据


为了更清楚理解，什么是覆盖索引，什么是回表查询，我们一起再来看下面的这组SQL的执行过程。





思考题：
​	一张表, 有四个字段(id, username, password, status), 由于数据量大, 需要对以下SQL语句进行优化, 该如何进行才是最优方案?
​	select id,username,password from tb_user where username &#x3D; ‘itcast’
​	答案: 
​		针对于 username, password建立联合索引, sql为: create index idx_user_name_pass on tb_user(username,password);
​	这样可以避免上述的SQL语句，在查询的过程中，出现回表查询。

索引设计原则
针对于数据量较大，且查询比较频繁的表建立索引。
针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引。
尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高。
如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。
尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间， 避免回表，提高查询效率。
要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增 删改的效率。
如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含 NULL值时，它可以更好地确定哪个索引最有效地用于查询。

SQL优化（后面在做）视图&#x2F;存储过程&#x2F;触发器视图视图（View）是一种虚拟存在的表。视图中的数据并不在数据库中实际存在，行和列数据来自定义视 图的查询中使用的表，并且是在使用视图时动态生成的。 通俗的讲，视图只保存了查询的SQL逻辑，不保存查询结果。所以我们在创建视图的时候，主要的工作 就落在创建这条SQL查询语句上。
基本语法
创建
CREATE [OR REPLACE] VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [CASCADED | LOCAL ] CHECK OPTION ]

查询
查看创建视图语句：SHOW CREATE VIEW 视图名称;查看视图数据：SELECT * FROM 视图名称 ...... ;

修改
方式一：CREATE [OR REPLACE] VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]方式二：ALTER VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]

删除
DROP VIEW [IF EXISTS] 视图名称 [,视图名称] ...

检查选项当使用WITH CHECK OPTION子句创建视图时，MySQL会通过视图检查正在更改的每个行，例如插 入，更新，删除，以使其符合视图的定义。 MySQL允许基于另一个视图创建视图，它还会检查依赖视 图中的规则以保持一致性。为了确定检查的范围，mysql提供了两个选项： CASCADED 和 LOCAL ，默认值为 CASCADED 。

CASCADED 级联

   比如，v2视图是基于v1视图的，如果在v2视图创建的时候指定了检查选项为 cascaded，但是v1视图 创建时未指定检查选项。 则在执行检查时，不仅会检查v2，还会级联检查v2的关联视图v1。
   

LOCAL 本地
比如，v2视图是基于v1视图的，如果在v2视图创建的时候指定了检查选项为 local ，但是v1视图创 建时未指定检查选项。 则在执行检查时，只会检查v2，不会检查v2的关联视图v1。



视图的更新要使视图可更新，视图中的行与基础表中的行之间必须存在一对一的关系。如果视图包含以下任何一 项，则该视图不可更新：

聚合函数或窗口函数（SUM()、 MIN()、 MAX()、 COUNT()等）

DISTINCT

GROUP BY

HAVING

UNION 或者 UNION ALL



视图的作用
简单：视图不仅可以简化用户对数据的理解，也可以简化他们的操作。那些被经常使用的查询可以被定义为视图，从而使得用户不必为以后的操作每次指定全部的条件。
安全：数据库可以授权，但不能授权到数据库特定行和特定的列上。通过视图用户只能查询和修改他们所能见到的数据。
数据独立：视图可帮助用户屏蔽真实表结构变化带来的影响。

存储过程存储过程是事先经过编译并存储在数据库中的一段 SQL 语句的集合，调用存储过程可以简化应用开发 人员的很多工作，减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是有好处的。 存储过程思想上很简单，就是数据库 SQL 语言层面的代码封装与重用。
特点
封装，复用：可以把某一业务SQL封装在存储过程中，需要用到 的时候直接调用即可。
可以接收参数，也可以返回数据：在存储过程中，可以传递参数，也可以接收返回值。
减少网络交互，效率提升：如果涉及到多条SQL，每执行一次都是一次网络传输。 而如果封装在存储过程中，我们只需要网络交互一次可能就可以了。

基本语法
创建
CREATE PROCEDURE 存储过程名称 ([ 参数列表 ])BEGIN-- SQL语句END ;

调用
CALL 名称 ([ 参数 ]);

查看
SELECT * FROM INFORMATION_SCHEMA.ROUTINES WHERE ROUTINE_SCHEMA = &#x27;xxx&#x27;; -- 查询指定数据库的存储过程及状态信息SHOW CREATE PROCEDURE 存储过程名称 ; -- 查询某个存储过程的定义

删除
1 DROP PROCEDURE [ IF EXISTS ] 存储过程名称 ；

案例

注意: 在命令行中，执行创建存储过程的SQL时，需要通过关键字 delimiter 指定SQL语句的 结束符。

-- 存储过程基本语法-- 创建create procedure p1()beginselect count(*) from student;end;-- 调用call p1();-- 查看select * from information_schema.ROUTINES where ROUTINE_SCHEMA = &#x27;itcast&#x27;;show create procedure p1;-- 删除drop procedure if exists p1;

变量在MySQL中变量分为三种类型: 系统变量、用户定义变量、局部变量。

系统变量
系统变量是MySQL服务器提供，不是用户定义的，属于服务器层面。分为全局变量（GLOBAL）、会话变量（SESSION）。

全局变量(GLOBAL): 全局变量针对于所有的会话。

会话变量(SESSION): 会话变量针对于单个会话，在另外一个会话窗口就不生效了。

如果没有指定SESSION&#x2F;GLOBAL，默认是SESSION会话变量。

mysql服务重新启动之后，所设置的全局参数会失效，要想不失效，可以在 &#x2F;etc&#x2F;my.cnf 中配置。



查看&amp;设置 系统变量
# 查看系统变量SHOW [ SESSION | GLOBAL ] VARIABLES ; -- 查看所有系统变量SHOW [ SESSION | GLOBAL ] VARIABLES LIKE &#x27;......&#x27;; -- 可以通过LIKE模糊匹配方式查找变量SELECT @@[SESSION | GLOBAL] 系统变量名; -- 查看指定变量的值# 设置系统变量SET [ SESSION | GLOBAL ] 系统变量名 = 值 ;SET @@[SESSION | GLOBAL]系统变量名 = 值 ;

用户定义变量
用户定义变量是用户根据需要自己定义的变量，用户变量不用提前声明，在用的时候直接用 “@变量 名” 使用就可以。其作用域为当前连接。

赋值，可以使用 &#x3D; ，也可以使用 :&#x3D; 。
方式一:	SET @var_name = expr [, @var_name = expr] ... ;	SET @var_name := expr [, @var_name := expr] ... ;方式一:	SELECT @var_name := expr [, @var_name := expr] ... ;	SELECT 字段名 INTO @var_name FROM 表名;

使用
SELECT @var_name ;


注意: 用户定义的变量无需对其进行声明或初始化，只不过获取到的值为NULL。


局部变量
局部变量 是根据需要定义的在局部生效的变量，访问之前，需要DECLARE声明。可用作存储过程内的局部变量和输入参数，局部变量的范围是在其内声明的BEGIN … END块。

声明
DECLARE 变量名 变量类型 [DEFAULT ... ] ;-- 变量类型就是数据库字段类型：INT、BIGINT、CHAR、VARCHAR、DATE、TIME等。

赋值
SET 变量名 = 值 ;SET 变量名 := 值 ;SELECT 字段名 INTO 变量名 FROM 表名 ... ;

使用
select 变量名;



ifif 用于做条件判断，具体的语法结构为：
IF 条件1 THEN.....ELSEIF 条件2 THEN -- 可选.....ELSE -- 可选.....END IF;# ---------------------举例：根据定义参数score，判定当前分数对应等级--------------------drop procedure if exists p3;create procedure p3()begin    declare score int default 58; #声明变量score为58，判断其分数等级    declare grade varchar(10); #用于接收等级    if score &gt;= 85 then        set grade := &#x27;优秀&#x27;;    elseif score &gt;= 60 then        set grade := &#x27;及格&#x27;;    else        set grade := &#x27;不及格&#x27;;    end if;    select grade;end;call p3; # 不及格


在if条件判断的结构中，ELSE IF 结构可以有多个，也可以没有。 ELSE结构可以有，也可以没有。

参数参数的类型，主要分为以下三种：IN、OUT、INOUT。 具体的含义如下：



类型
含义
备注



IN
该类参数作为输入，也就是需要调用时传入值
默认


OUT
该类参数作为输出，也就是该参数可以作为返回值



INOUT
既可以作为输入参数，也可以作为输出参数



用法：
CREATE PROCEDURE 存储过程名称 ([ IN/OUT/INOUT 参数名 参数类型 ])BEGIN	-- SQL语句END ;

案例
-- 案例一 根据传入参数score，判定当前分数对应的分数等级，并返回。-- score &gt;= 85分，等级为优秀。-- score &gt;= 60分 且 score &lt; 85分，等级为及格。-- score &lt; 60分，等级为不及格。DROP PROCEDURE if EXISTS p1;CREATE PROCEDURE p1(IN score INT,OUT result VARCHAR(10))BEGIN		if score &gt;= 85 THEN		SET result = &#x27;优秀&#x27;;	ELSEIF score &gt; 60 THEN		SET result := &#x27;及格&#x27;;	ELSE 		SET result = &#x27;不及格&#x27;;	END if;END;-- 定义用户变量 @result来接收返回的数据, 用户变量可以不用声明call p1(99, @result);select @result; -- 优秀-- 案例二 将传入的200分制的分数，进行换算，换算成百分制，然后返回。DROP PROCEDURE if EXISTS p2;CREATE PROCEDURE p2(INOUT score DOUBLE)BEGIN	set score := score * 0.5;END;SET @score = 60;call p2(@score);SELECT @score; -- 30

casecase结构及作用，和我们在基础篇中所讲解的流程控制函数很类似。有两种语法格式：

语法1：
-- 含义： 当case_value的值为 when_value1时，执行statement_list1，当值为 when_value2时，执行statement_list2， 否则就执行 statement_listCASE case_value	WHEN when_value1 THEN statement_list1	[ WHEN when_value2 THEN statement_list2] ...	[ ELSE statement_list ]END CASE;

语法2：
-- 含义： 当条件search_condition1成立时，执行statement_list1，当条件search_condition2成立时，执行statement_list2， 否则就执行 statement_listCASE	WHEN search_condition1 THEN statement_list1	[WHEN search_condition2 THEN statement_list2] ...	[ELSE statement_list]END CASE;

案例：
# 根据传入的月份，判定月份所属的季节（要求采用case结构）。# 1-3月份，为第一季度# 4-6月份，为第二季度# 7-9月份，为第三季度# 10-12月份，为第四季度DROP PROCEDURE if EXISTS p3;CREATE PROCEDURE p3(IN month INT)BEGIN	DECLARE season VARCHAR(10);	CASE 		WHEN month &gt;= 1 and month &lt;= 3 THEN			SET season := &#x27;第一季度&#x27;;		WHEN month &gt;= 4 and month &lt;= 6 THEN			SET season := &#x27;第二季度&#x27;;		WHEN month &gt;= 7 and month &lt;= 9 THEN			SET season := &#x27;第三季度&#x27;;		WHEN month &gt;= 10 and month &lt;= 12 THEN			SET season := &#x27;第四季度&#x27;;		ELSE			SET season := &#x27;非法参数&#x27;;	END CASE;	select concat(&#x27;您输入的月份为: &#x27;,month, &#x27;, 所属的季度为: &#x27;,season);END;call p3(10);# 您输入的月份为: 10, 所属的季度为: 第四季度


注意：如果判定条件有多个，多个条件之间，可以使用 and 或 or 进行连接。

whilewhile 循环是有条件的循环控制语句。满足条件后，再执行循环体中的SQL语句。具体语法为：
-- 先判定条件，如果条件为true，则执行逻辑，否则，不执行逻辑WHILE 条件 DO	SQL逻辑...END WHILE;

案例
# 计算从1累加到n的值，n为传入的参数值。-- A. 定义局部变量, 记录累加之后的值;-- B. 每循环一次, 就会对n进行减1 , 如果n减到0, 则退出循环DROP PROCEDURE if EXISTS p4;CREATE PROCEDURE p4(IN num INT)BEGIN	declare result INT DEFAULT 0; 	WHILE num &gt; 0 DO		set result := result + num;		set num := num - 1;	END WHILE;	SELECT result;END;call p4(10); # 55

repeatrepeat是有条件的循环控制语句, 当满足until声明的条件的时候，则退出循环 。具体语法为：
-- 先执行一次逻辑，然后判定UNTIL条件是否满足，如果满足，则退出。如果不满足，则继续下一次循环REPEAT	SQL逻辑...	UNTIL 条件END REPEAT;

案例
# 计算从1累加到n的值，n为传入的参数值。(使用repeat实现)-- A. 定义局部变量, 记录累加之后的值;-- B. 每循环一次, 就会对n进行减1 , 如果n减到0, 则退出循环DROP PROCEDURE if EXISTS p5;CREATE PROCEDURE p5(IN num INT)BEGIN	declare result INT DEFAULT 0; 	REPEAT		set result := result + num;		set num := num - 1;		UNTIL num &lt;= 0	END REPEAT;	SELECT result;END;call p5(10); # 

loopLOOP 实现简单的循环，如果不在SQL逻辑中增加退出循环的条件，可以用其来实现简单的死循环。 LOOP可以配合一下两个语句使用：

LEAVE ：配合循环使用，退出循环。
ITERATE：必须用在循环中，作用是跳过当前循环剩下的语句，直接进入下一次循环。

[begin_label:] LOOP	SQL逻辑...END LOOP [end_label];LEAVE label; -- 退出指定标记的循环体ITERATE label; -- 直接进入下一次循环-- 上述语法中出现的 begin_label，end_label，label 指的都是我们所自定义的标记。

案例
#  案例一# 计算从1累加到n的值，n为传入的参数值。-- A. 定义局部变量, 记录累加之后的值;-- B. 每循环一次, 就会对n进行-1 , 如果n减到0, 则退出循环 ----&gt; leave xxDROP PROCEDURE if EXISTS p6;CREATE PROCEDURE p6(IN num INT)BEGIN	DECLARE result INT DEFAULT 0; 	getSum: LOOP		IF num &lt;= 0 THEN			LEAVE getSum; 		END IF; 		set result := result + num;		set num := num - 1;	END LOOP getSum;	SELECT result;END;call p6(10); # 55#  案例二# 计算从1到n之间的偶数累加的值，n为传入的参数值。-- A. 定义局部变量, 记录累加之后的值;-- B. 每循环一次, 就会对n进行-1 , 如果n减到0, 则退出循环 ----&gt; leave xx-- C. 如果当次累加的数据是奇数, 则直接进入下一次循环. --------&gt; iterate xxDROP PROCEDURE if EXISTS p7;CREATE PROCEDURE p7(IN num INT)BEGIN	DECLARE result INT DEFAULT 0; 	getSum: LOOP		IF num &lt;= 0 THEN			LEAVE getSum; 		END IF; 				if num%2 = 1 then			set num := num - 1;			iterate getSum;		end if;		set result := result + num;		set num := num - 1;			END LOOP getSum;	SELECT result;END;call p7(10); # 30

游标游标（CURSOR）是用来存储查询结果集的数据类型 , 在存储过程和函数中可以使用游标对结果集进行循环的处理。游标的使用包括游标的声明、OPEN、FETCH 和 CLOSE，其语法分别如下。
# 声明游标DECLARE 游标名称 CURSOR FOR 查询语句 ;# 打开游标OPEN 游标名称 ;# 获取游标记录FETCH 游标名称 INTO 变量 [, 变量 ] ;# 关闭游标CLOSE 游标名称 ;

案例
#  根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名#（name）和专业（profession），并将用户的姓名和专业插入到所创建的一张新表# (id,name,profession)中。-- 逻辑:-- A. 声明游标, 存储查询结果集-- B. 准备: 创建表结构-- C. 开启游标-- D. 获取游标中的记录-- E. 插入数据到新表中-- F. 关闭游标DROP PROCEDURE if EXISTS p8;CREATE PROCEDURE p8(IN iage INT)BEGIN	# 有先后顺序：先声明普通变量，再声明游标	declare uname varchar(100);	declare upro varchar(100);	# 1.声明游标 存储查询结果集	DECLARE u_cursor CURSOR FOR SELECT `name`,profession FROM tb_user WHERE age &lt;= iage;	# 2.创建新表的 表结构	drop table if exists tb_user_pro;	create table if not exists tb_user_pro(		id int primary key auto_increment,		name varchar(100),		profession varchar(100)	);	# 3.开启游标	OPEN u_cursor;	# 4.获取游标中的记录	while true do		fetch u_cursor into uname,upro;		# 5.插入数据到新表中		insert into tb_user_pro values (null, uname, upro);	end while;	# 6.关闭游标	CLOSE u_cursor;END;call p8(30);

上述的存储过程，最终我们在调用的过程中，会报错，之所以报错是因为上面的while循环中，并没有 退出条件。当游标的数据集获取完毕之后，再次获取数据，就会报错，从而终止了程序的执行。

但是此时，tb_user_pro表结构及其数据都已经插入成功了，我们可以直接刷新表结构，检查表结构中的数据。上述的功能，虽然我们实现了，但是逻辑并不完善，而且程序执行完毕，获取不到数据，数据库还报 错。 接下来，我们就需要来完成这个存储过程，并且解决这个问题。 要想解决这个问题，就需要通过MySQL中提供的条件处理程序 Handler 来解决。
条件处理程序条件处理程序（Handler）可以用来定义在流程控制结构执行过程中遇到问题时相应的处理步骤。具体语法为：
DECLARE handler_action HANDLER FOR condition_value [, condition_value] ... statement ;handler_action 的取值：    CONTINUE: 继续执行当前程序    EXIT: 终止执行当前程序condition_value 的取值：    SQLSTATE sqlstate_value: 状态码，如 02000    SQLWARNING: 所有以01开头的SQLSTATE代码的简写    NOT FOUND: 所有以02开头的SQLSTATE代码的简写    SQLEXCEPTION: 所有没有被SQLWARNING 或 NOT FOUND捕获的SQLSTATE代码的简写

案例

通过SQLSTATE指定具体的状态码
# 我们继续来完成在上一小节提出的这个需求，并解决其中的问题。#  根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名#（name）和专业（profession），并将用户的姓名和专业插入到所创建的一张新表# (id,name,profession)中。-- 逻辑:-- A. 声明游标, 存储查询结果集-- B. 准备: 创建表结构-- C. 开启游标-- D. 获取游标中的记录-- E. 插入数据到新表中-- F. 关闭游标DROP PROCEDURE if EXISTS p8;CREATE PROCEDURE p8(IN iage INT)BEGIN	# 有先后顺序：先声明普通变量，再声明游标	declare uname varchar(100);	declare upro varchar(100);	# 1.声明游标 存储查询结果集	DECLARE u_cursor CURSOR FOR SELECT `name`,profession FROM tb_user WHERE age &lt;= iage;		-- 声明条件处理程序 ： 当SQL语句执行抛出的状态码为02000时，将关闭游标u_cursor，并退出	declare exit handler for SQLSTATE &#x27;02000&#x27; close u_cursor;		# 2.创建新表的 表结构	drop table if exists tb_user_pro;	create table if not exists tb_user_pro(		id int primary key auto_increment,		name varchar(100),		profession varchar(100)	);	# 3.开启游标	OPEN u_cursor;	# 4.获取游标中的记录	while true do		fetch u_cursor into uname,upro;		# 5.插入数据到新表中		insert into tb_user_pro values (null, uname, upro);	end while;	# 6.关闭游标	CLOSE u_cursor;END;call p8(30);

通过SQLSTATE的代码简写方式 NOT FOUND。02 开头的状态码，代码简写为 NOT FOUND
# 我们继续来完成在上一小节提出的这个需求，并解决其中的问题。#  根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名#（name）和专业（profession），并将用户的姓名和专业插入到所创建的一张新表# (id,name,profession)中。-- 逻辑:-- A. 声明游标, 存储查询结果集-- B. 准备: 创建表结构-- C. 开启游标-- D. 获取游标中的记录-- E. 插入数据到新表中-- F. 关闭游标DROP PROCEDURE if EXISTS p8;CREATE PROCEDURE p8(IN iage INT)BEGIN	# 有先后顺序：先声明普通变量，再声明游标	declare uname varchar(100);	declare upro varchar(100);	# 1.声明游标 存储查询结果集	DECLARE u_cursor CURSOR FOR SELECT `name`,profession FROM tb_user WHERE age &lt;= iage;		-- 声明条件处理程序 ： 当SQL语句执行抛出的状态码为02开头时，将关闭游标u_cursor，并退出	declare exit handler for not found close u_cursor;		# 2.创建新表的 表结构	drop table if exists tb_user_pro;	create table if not exists tb_user_pro(		id int primary key auto_increment,		name varchar(100),		profession varchar(100)	);	# 3.开启游标	OPEN u_cursor;	# 4.获取游标中的记录	while true do		fetch u_cursor into uname,upro;		# 5.插入数据到新表中		insert into tb_user_pro values (null, uname, upro);	end while;	# 6.关闭游标	CLOSE u_cursor;END;call p8(30);


具体的错误状态码，可以参考官方文档：https://dev.mysql.com/doc/refman/8.0/en/declare-handler.htmlhttps://dev.mysql.com/doc/mysql-errors/8.0/en/server-error-reference.html

存储函数存储函数是有返回值的存储过程，存储函数的参数只能是IN类型的。具体语法如下：
CREATE FUNCTION 存储函数名称 ([ 参数列表 ])RETURNS type [characteristic ...]BEGIN    -- SQL语句    RETURN ...;END ;

characteristic说明：

DETERMINISTIC：相同的输入参数总是产生相同的结果
NO SQL ：不包含 SQL 语句
READS SQL DATA：包含读取数据的语句，但不包含写入数据的语句

案例
# 计算从1累加到n的值，n为传入的参数值。CREATE FUNCTION fun1 (n INT)RETURNS INT DETERMINISTICBEGIN    declare sum int default 0;    while n &gt; 0 do        set sum := sum + n;        set n := n - 1;    end while;    return sum;END ;select fun1(100); # 5050

触发器触发器是与表有关的数据库对象，指在insert&#x2F;update&#x2F;delete之前(BEFORE)或之后(AFTER)，触发并执行触发器中定义的SQL语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性 , 日志记录 , 数据校验等操作 。
使用别名OLD和NEW来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还 只支持行级触发，不支持语句级触发。



触发器类型
NEW 和 OLD



INSERT 型触发器
NEW 表示将要或者已经新增的数据


UPDATE 型触发器
OLD 表示修改之前的数据 , NEW 表示将要或已经修改后的数据


DELETE 型触发器
OLD 表示将要或者已经删除的数据


基本语法
创建
CREATE TRIGGER trigger_nameBEFORE/AFTER INSERT/UPDATE/DELETEON tbl_name FOR EACH ROW -- 行级触发器BEGIN	trigger_stmt ;END;

查看
SHOW TRIGGERS ;

删除
DROP TRIGGER [schema_name.]trigger_name ; -- 如果没有指定 schema_name，默认为当前数据库。

案例
通过触发器记录 tb_user 表的数据变更日志，将变更日志插入到日志表user_logs中, 包含增加, 修改 , 删除 。
表结构准备:
-- 准备工作 : 日志表 user_logscreate table user_logs(    id int(11) not null auto_increment,    operation varchar(20) not null comment &#x27;操作类型, insert/update/delete&#x27;,    operate_time datetime not null comment &#x27;操作时间&#x27;,    operate_id int(11) not null comment &#x27;操作的ID&#x27;,    operate_params varchar(500) comment &#x27;操作参数&#x27;,    primary key(`id`))engine=innodb default charset=utf8;


插入数据触发器
-- 创建插入触发器CREATE TRIGGER tb_user_insert_trigger AFTER INSERT ON tb_user FOR EACH ROWBEGIN		INSERT INTO user_logs ( id, operation, operate_time, operate_id, operate_params )	VALUES		(NULL,&#x27;insert&#x27;,now(),new.id,		concat(&#x27;插入的数据内容为:id=&#x27;,new.id,&#x27;name=&#x27;,new.NAME,&#x27;, phone=&#x27;,NEW.phone,&#x27;, email=&#x27;,NEW.email,&#x27;,profession=&#x27;,NEW.profession ));END;-- 查看触发器SHOW TRIGGERS;-- 插入数据到tb_userinsert into tb_user(id, name, phone, email, profession, age, gender, status,createtime) VALUES (26,&#x27;三皇子&#x27;,&#x27;18809091212&#x27;,&#x27;erhuangzi@163.com&#x27;,&#x27;软件工程&#x27;,23,&#x27;1&#x27;,&#x27;1&#x27;,now());-- 查询插入触发器SELECT * FROM user_logs;

修改数据触发器
-- 创建更新触发器CREATE TRIGGER tb_user_update_trigger AFTER UPDATE ON tb_user FOR EACH ROWBEGIN		INSERT INTO user_logs ( id, operation, operate_time, operate_id, operate_params )	VALUES		(NULL,&#x27;update&#x27;,now(),new.id,		concat(&#x27;更新前的数据内容为:id=&#x27;,old.id,&#x27;name=&#x27;,old.NAME,&#x27;, phone=&#x27;,old.phone,&#x27;, email=&#x27;,old.email,&#x27;,profession=&#x27;,old.profession,					&#x27;,更新后的数据内容为:id=&#x27;,new.id,&#x27;name=&#x27;,new.NAME,&#x27;, phone=&#x27;,new.phone,&#x27;, email=&#x27;,new.email,&#x27;,profession=&#x27;,new.profession));END;-- 查看触发器SHOW TRIGGERS;-- 更新tb_user数据update tb_user set profession = &#x27;会计&#x27; where id = 23;-- 查询更新触发器SELECT * FROM user_logs;

删除数据触发器
-- 创建删除触发器CREATE TRIGGER tb_user_delete_trigger AFTER DELETE ON tb_user FOR EACH ROWBEGIN		INSERT INTO user_logs ( id, operation, operate_time, operate_id, operate_params )	VALUES		(NULL,&#x27;delete&#x27;,now(),old.id,		concat(&#x27;删除的数据内容为:id=&#x27;,old.id,&#x27;name=&#x27;,old.NAME,&#x27;, phone=&#x27;,old.phone,&#x27;, email=&#x27;,old.email,&#x27;,profession=&#x27;,old.profession));END;-- 查看触发器SHOW TRIGGERS;-- 删除tb_user数据delete from tb_user WHERE id=26;-- 查询删除触发器SELECT * FROM user_logs;

锁锁是计算机协调多个进程或线程并发访问某一资源的机制。在数据库中，除传统的计算资源（CPU、 RAM、I&#x2F;O）的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。
MySQL中的体系全景图
graph TD
    A[MySQL 锁体系] --&gt; B[按粒度划分]
    A --&gt; C[按功能划分]
    A --&gt; D[按模式划分]
    
    B --&gt; B1[全局锁]
    B --&gt; B2[表级锁]
    B --&gt; B3[行级锁]
    B --&gt; B4[页级锁]
    
    C --&gt; C1[共享锁 S]
    C --&gt; C2[排他锁 X]
    C --&gt; C3[意向共享锁 IS]
    C --&gt; C4[意向排他锁 IX]
    
    D --&gt; D1[悲观锁]
    D --&gt; D2[乐观锁]

共享锁 (S Lock)一个事务已获取共享锁，当另一个事务尝试对具备共享锁的数据进行读操作时，可正常读；进行写操作时，会被共享锁排斥。

特性：允许多事务并发读取

兼容性：兼容其他 S 锁，排斥 X 锁

使用场景：
-- 保证读取期间数据不变SELECT * FROM table WHERE ... LOCK IN SHARE MODE;-- MySQL8.0之后也优化了写法，如下：SELECT ... FOR SHARE;

排他锁 (X Lock)当一个线程获取到独占锁后，会排斥其他线程（进行读写操作），如若其他线程也想对共享资源&#x2F;同一数据进行操作，必须等到当前线程释放锁并竞争到锁资源才行。

特性：独占资源，禁止其他操作

兼容性：排斥所有其他锁

使用场景：
SELECT * FROM table WHERE ... FOR UPTATE;

全局锁 (Global Lock)全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DML的写语句，DDL语句，已经更新操作的事务提交语句都将被阻塞。
典型的使用场景是做全库的逻辑备份。

不加全局锁：进行数据备份时，对数据进行DML语句，会导致备份前后数据不一致问题。
加了全局锁：对数据库进行进行逻辑备份之前，先对整个数据库加上全局锁，一旦加了全局锁之后，其他的DDL、 DML全部都处于阻塞状态，但是可以执行DQL语句，也就是处于只读状态，而数据备份就是查询操作。 那么数据在进行逻辑备份的过程中，数据库中的数据就是不会发生变化的，这样就保证了数据的一致性和完整性。

基本语法加全局锁
flush tables with read lock;

数据备份
mysqldump -u username -p database_name &gt; backup.sql -- （备份指定数据库到 backup.sql，执行后输入密码 ）

释放全局锁
unlock tables;

特点数据库中加全局锁，是一个比较重的操作，存在以下问题：

如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。
如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志（binlog），会导致主从延迟。


在InnoDB引擎中，我们可以在备份时加上参数 –single-transaction 参数来完成不加锁的一致 性数据备份。
mysqldump –single-transaction -u username -p database_name &gt; backup.sql

表级锁 (Table Lock)表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在MyISAM、InnoDB、BDB等存储引擎中。
使用表锁的开销相对较小，加锁快，不会产生死锁；但是加锁粒度大，发生锁冲突的概率更高，并发度更低。在innoDB存储引擎中不推荐使用表锁，只有在没有事务支持的存储引擎中才会使用，如MyISAM
对于表级锁，主要分为以下三类：

表锁
元数据锁
意向锁

表锁对于表锁，分为两类：

表共享读锁（read lock）
表独占写锁（write lock）

基本语法
加锁
lock tables 表名... read/write。

释放锁
unlock tables / 客户端断开连接 。

特点
读锁：


写锁：



结论: 读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞其他客户端的写。
元数据锁（meta data lock, MDL）MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL锁主要作用是维护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。为了避免DML与 DDL冲突，保证读写的正确性。
这里的元数据，大家可以简单理解为就是一张表的表结构。 也就是说，某一张表涉及到未提交的事务时，是不能够修改这张表的表结构的。
在MySQL5.5中引入了MDL，当对一张表进行增删改查的时候，加MDL读锁(共享)；当对表结构进行变更操作的时候，加MDL写锁(排他)。
常见的SQL操作时，所添加的元数据锁：



对应SQL
锁类型
说明



lock tables xxx read &#x2F; write（表锁）
SHARED_READ_ONLY &#x2F; SHARED_NO_READ_WRITE



select 、select … lock in share mode（普通读、共享锁）
SHARED_READ（元数据共享锁）
与SHARED_READ、 SHARED_WRITE兼容，与 EXCLUSIVE互斥


insert 、update、 delete、select … for update（增、改、删、排他锁）
SHARED_WRITE（元数据共享锁）
与SHARED_READ、 SHARED_WRITE兼容，与 EXCLUSIVE互斥


alter table …（修改表结构）
EXCLUSIVE（元数据排他锁）
与其他的MDL都互斥


案例
当执行SELECT、INSERT、UPDATE、DELETE等语句时，添加的是元数据共享锁（SHARED_READ &#x2F; SHARED_WRITE），之间是兼容的。

当执行SELECT语句时，添加的是元数据共享锁（SHARED_READ），会阻塞元数据排他锁 （EXCLUSIVE），之间是互斥的。

我们可以通过下面的SQL，来查看数据库中的元数据锁的情况：
select object_type,object_schema,object_name,lock_type,lock_duration from performance_schema.metadata_locks ;

我们在操作过程中，可以通过上述的SQL语句，来查看元数据锁的加锁情况。

意向锁（Intention Lock）为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查。

分类

意向共享锁（IS）：由语句select … lock in share mode添加，与表锁共享锁（read）兼容，与表锁排他锁（write）互斥。在准备给表数据添加一个S锁时，需要先获得该表的IS锁
意向排他锁（IX）：由insert、update、delete、select…for update添加 。与表锁共享锁(read)及排他锁(write)都互斥，意向锁之间不会互斥。在准备给表数据添加一个X锁时，需要先获得该表的IX锁


一旦事务提交了，意向共享锁、意向排他锁，都会自动释放。

可以通过以下SQL，查看意向锁及行锁的加锁情况：
select object_schema,object_name,index_name,lock_type,lock_mode,lock_data from performance_schema.data_locks;

案例
A.意向共享锁与表读锁是兼容的

B.意向排他锁与表读锁、写锁都是互斥的

兼容矩阵：



请求\持有
X
IX
S
IS



X（共享锁）
❌
❌
❌
❌


IX（意向排他锁）
❌
✅
❌
✅


S（排他锁）
❌
❌
✅
✅


IS（意向共享锁）
❌
✅
✅
✅


行级锁 (Row Lock)行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应用在 InnoDB存储引擎中。InnoDB的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁。对于行级锁，主要分为以下三类：

行锁（Record Lock）

间隙锁（Gap Lock）

临键锁（Next-Key Lock）


行锁 &#x2F; 记录锁（Record Lock）锁定单个行记录的锁，防止其他事务对此行进行update和delete。在RC、RR隔离级别下都支持。

InnoDB实现了以下两种类型的行锁：

共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。
排他锁（X）：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他锁。

两种行锁的兼容情况如下:

常见的SQL语句，在执行时，所加的行锁如下：

案例
默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。

针对唯一索引进行检索时，对已存在的记录进行等值匹配时，将会自动优化为行锁。
InnoDB的行锁是针对于索引加的锁，不通过索引条件检索数据，那么InnoDB将对表中的所有记录加锁，此时就会升级为表锁。

可以通过以下SQL，查看意向锁及行锁的加锁情况：
select object_schema,object_name,index_name,lock_type,lock_mode,lock_data from performance_schema.data_locks;

间隙锁（Gap Lock）锁定索引记录间隙（不含该记录），左右开区间，确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR隔离级别下都支持。

默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。
加间隙锁的规则

索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁 。
索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。
索引上的范围查询(唯一索引)–会访问到不满足条件的第一个值为止。


注意：间隙锁唯一目的是防止其他事务插入间隙。间隙锁可以共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁。

临键锁（Next-Key Lock）行锁和间隙锁组合，同时锁住数据，并锁住数据前面的间隙Gap，左开右闭。 在RR隔离级别下支持。
 
案例
A. 索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁 

B. 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。 
分析： InnoDB的B+树索引，叶子节点是有序的双向链表。 假如，我们要根据这个二级索引查询值为18的数据，并加上共享锁，我们是只锁定18这一行就可以了吗？ 并不是，因为是非唯一索引，这个结构中可能有多个18的存在，所以，在加锁时会继续往后找，找到一个不满足条件的值（当前案例中也 就是29）。此时会对18加临键锁，并对29之前的间隙加锁。

C. 索引上的范围查询(唯一索引)–会访问到不满足条件的第一个值为止。

查询的条件为id&gt;&#x3D;19，并添加共享锁。此时我们可以根据数据库表中现有的数据，将数据分为三个部分： [19] (19,25] (25,+∞] 所以数据库数据在加锁是，就是将19加了行锁，25的临键锁（包含25及25之前的间隙），正无穷的临键锁(正无穷及之前的间隙)。
乐观锁&#x2F;悲观锁悲观锁（Pessimistic Locking）
假设冲突必然发生，因此在访问数据前先加锁，阻止其他事务同时修改。
适用场景：写操作频繁、并发冲突概率高的场景（如库存扣减、金融转账）。

实现方式：
-- 行级锁-- 共享锁（S锁）：允许多事务同时读SELECT * FROM products WHERE id = 1 LOCK IN SHARE MODE;-- 排他锁（X锁）：阻止其他事务读写SELECT * FROM products WHERE id = 1 FOR UPDATE;-- 表级锁LOCK TABLES products WRITE;  -- 写锁（排他）UNLOCK TABLES;


优点：确保数据一致性，避免脏写。
缺点：
增加锁等待时间，降低并发性能。
可能导致死锁（如事务循环等待锁）。



乐观锁（Optimistic Locking）
假设冲突很少发生，不提前加锁，而是在提交时检查数据是否被修改。
适用场景：读操作频繁、冲突概率低的场景（如商品浏览量统计）。

实现方式：

版本号（Version）：
-- 表结构增加 version 字段CREATE TABLE products (  id INT PRIMARY KEY,  stock INT,  version INT DEFAULT 0);-- 事务1：读取数据SELECT stock, version FROM products WHERE id = 1;-- 事务1：更新时校验 versionUPDATE products SET stock = stock - 1, version = version + 1 WHERE id = 1 AND version = 上次读取的version;

时间戳（Timestamp）：类似版本号，使用时间戳字段记录数据修改时间。

优点：

无需加锁，提升并发性能。
避免死锁。


缺点：

需要应用层处理冲突（如重试机制）。
不适合高冲突场景（重试频繁会降低效率）。



InnoDB引擎InnoDB的逻辑存储结构

表空间
表空间是InnoDB存储引擎逻辑结构的最高层， 如果用户启用了参数 innodb_file_per_table(在 8.0版本中默认开启) ，则每张表都会有一个表空间（xxx.ibd），一个mysql实例可以对应多个表空间，用于存储记录、索引等数据。

段
段，分为数据段（Leaf node segment）、索引段（Non-leaf node segment）、回滚段 （Rollback segment），InnoDB是索引组织表，数据段就是B+树的叶子节点， 索引段即为B+树的 非叶子节点。段用来管理多个Extent（区）。

区
区，表空间的单元结构，每个区的大小为1M。 默认情况下，InnoDB存储引擎页大小为16K， 即一 个区中一共有64个连续的页。

页
页，是InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区。

行
行，InnoDB 存储引擎数据是按行进行存放的。 
在行中，默认有两个隐藏字段：

Trx_id：每次对某条记录进行改动时，都会把对应的事务id赋值给trx_id隐藏列。
Roll_pointer：每次对某条引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。



架构MySQL5.5 版本开始，默认使用InnoDB存储引擎，它擅长事务处理，具有崩溃恢复特性，在日常开发中使用非常广泛。下面是InnoDB架构图，左侧为内存结构，右侧为磁盘结构。

内存结构在左侧的内存结构中，主要分为这么四大块儿： Buffer Pool、Change Buffer、Adaptive Hash Index、Log Buffer。 接下来介绍一下这四个部分。

Buffer Pool
InnoDB存储引擎基于磁盘文件存储，访问物理硬盘和在内存中进行访问，速度相差很大，为了尽可能弥补这两者之间的I&#x2F;O效率的差值，就需要把经常使用的数据加载到缓冲池中，避免每次访问都进行磁盘I&#x2F;O。
在InnoDB的缓冲池中不仅缓存了索引页和数据页，还包含了undo页、插入缓存、自适应哈希索引以及 InnoDB的锁信息等等。
缓冲池 Buffer Pool，是主内存中的一个区域，里面可以缓存磁盘上经常操作的真实数据，在执行增、删、改、查操作时，先操作缓冲池中的数据（若缓冲池没有数据，则从磁盘加载并缓存），然后再以一定频率刷新到磁盘，从而减少磁盘IO，加快处理速度。
缓冲池以Page页为单位，底层采用链表数据结构管理Page。根据状态，将Page分为三种类型：

free page：空闲page，未被使用
clean page：被使用page，数据没有被修改过
dirty page：脏页，被使用page，数据被修改过，页中数据与磁盘的数据产生了不一致


在专用服务器上，通常将多达80％的物理内存分配给缓冲池 。参数设置： show variables like ‘innodb_buffer_pool_size’;


Change Buffer
Change Buffer，更改缓冲区（针对于非唯一二级索引页），在执行DML语句时，如果这些数据Page 没有在Buffer Pool中，是不会直接操作磁盘，而是会将数据变更存在更改缓冲区 Change Buffer 中，在以后数据被读取时，再将数据合并恢复到Buffer Pool中，再将合并后的数据刷新到磁盘中。
意义：与聚集索引不同，二级索引通常是非唯一的，并且以相对随机的顺序插入二级索引。同样，删除和更新可能会影响索引树中不相邻的二级索引页，如果每一次都操作磁盘，会造成大量的磁盘IO。有了 ChangeBuffer 之后，我们可以在缓冲池中进行合并处理，减少磁盘IO。

Adaptive Hash Index


   自适应hash索引，用于优化对Buffer Pool数据的查询。MySQL的innoDB引擎中虽然没有直接支持 hash索引，但是给我们提供了一个功能就是这个自适应hash索引。hash索引在 进行等值匹配时，一般性能是要高于B+树的，因为hash索引一般只需要一次IO即可，而B+树，可能需要几次匹配，所以hash索引的效率要高，但是hash索引又不适合做范围查询、模糊匹配等。
   InnoDB存储引擎会监控对表上各索引页的查询，如果观察到在特定的条件下hash索引可以提升速度， 则建立hash索引，称之为自适应hash索引。自适应哈希索引，无需人工干预，是系统根据情况自动完成。
   参数： adaptive_hash_index


Log Buffer
日志缓冲区，用来保存要写入到磁盘中的log日志数据（redo log 、undo log）， 默认大小为 16MB，日志缓冲区的日志会定期刷新到磁盘中。如果需要更新、插入或删除许多行的事务，增加日志缓冲区的大小可以节省磁盘 I&#x2F;O。
参数

innodb_log_buffer_size：缓冲区大小
innodb_flush_log_at_trx_commit：日志刷新到磁盘时机，取值主要包含以下三个：
1：日志在每次事务提交时写入并刷新到磁盘，默认值
0: 每秒将日志写入并刷新到磁盘一次
2: 日志在每次事务提交后写入，并每秒刷新到磁盘一次





磁盘结构

System Tablespace
系统表空间是更改缓冲区的存储区域。如果表是在系统表空间而不是每个表文件或通用表空间中创建的，它也可能包含表和索引数据。(在MySQL5.x版本中还包含InnoDB数据字典、undolog等)。参数：innodb_data_file_path。系统表空间，默认的文件名叫 ibdata1。

File-Per-Table Tablespaces
如果开启了innodb_file_per_table开关 ，则每个表的文件表空间包含单个InnoDB表的数据和索 引 ，并存储在文件系统上的单个数据文件中。 开关参数：innodb_file_per_table ，该参数默认开启。我们每创建一个表，都会产生一个表空间文件（.ibd）。

General Tablespaces


   通用表空间，需要通过 CREATE TABLESPACE 语法创建通用表空间，在创建表时，可以指定该表空间。

创建表空间
CREATE TABLESPACE ts_name ADD DATAFILE &#x27;file_name&#x27; ENGINE = engine_name;

创建表时指定表空间
CREATE TABLE xxx ... TABLESPACE ts_name;


Undo Tablespaces
撤销表空间，MySQL实例在初始化时会自动创建两个默认的undo表空间（初始大小16M），用于存储 undo log日志。

Temporary Tablespaces
InnoDB 使用会话临时表空间和全局临时表空间。存储用户创建的临时表等数据。

Doublewrite Buffer Files
双写缓冲区，innoDB引擎将数据页从Buffer Pool刷新到磁盘前，先将数据页写入双写缓冲区文件 中，便于系统异常时恢复数据。


Redo Log
重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中, 用于在刷新脏页到磁盘时,发生错误时, 进行数据恢复使用。以循环方式写入重做日志文件，涉及两个文件：



后台线程在Innodb存储引擎中，后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据。此外它会将已经修改的数据文件刷新到磁盘文件中，保证在不发生异常的情况下，Innodb能够恢复到正常的运行状态。


Master Thread核心后台线程，负责调度其他线程，还负责将缓冲池中的数据异步刷新到磁盘中, 保持数据的一致性， 还包括脏页的刷新、合并插入缓存、undo页的回收 。
IO Thread在InnoDB存储引擎中大量使用了AIO来处理IO请求, 这样可以极大地提高数据库的性能，而IO Thread主要负责这些IO请求的回调。



线程类型
默认个数
职责



Read thread
4
负责读操作


Write thread
4
负责写操作


Log thread
1
负责将日志缓冲区刷新到磁盘


Insert buffer thread
1
负责将写缓冲区内容刷新到磁盘


我们可以通过以下的这条指令，查看到InnoDB的状态信息，其中就包含IO Thread信息。
show engine innodb status \G;


Purge Thread主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收。
Page Cleaner Thread协助 Master Thread 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞。
事务原理事务：是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。
事务特性：

原子性（Atomicity）：事务是不可分割的最小操作单元，要么全部成功，要么全部失败。 
一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态。
隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。
持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。



redo log重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。
该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log file）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中,用于在刷新脏页到磁盘,发生错误时,进行数据恢复使用。

没有redo log，可能会存在什么问题

在InnoDB引擎中的内存结构中，主要的内存区域就是缓冲池，在缓冲池中缓存了很多的数据页。 

当我们在一个事务中，执行多个增删改的操作时，InnoDB引擎会先操作缓冲池中的数据，如果缓冲区没有对应的数据，会通过后台线程将磁盘中的数据加载出来，存放在缓冲区中。

然后将缓冲池中的数据修改，修改后的数据页我们称为脏页。

脏页会在一定的时机，通过后台线程将缓冲区的数据刷新到磁盘中，从而保证缓冲区与磁盘的数据一致。 

但是缓冲区的脏页数据并不是实时刷新的，而是一段时间之后将缓冲区的数据刷新到磁盘中，假如刷新到磁盘的过程出错了，而提示给用户事务提交成功，而数据却没有持久化下来，这就出现问题了，没有保证事务的持久性。




InnoDB中提供了一份日志 redo log

有了redolog之后，当对缓冲区的数据进行增删改之后，会首先将操作的数据页的变化，记录在redo log buffer中。

在事务提交时，会将redo log buffer中的数据刷新到redo log磁盘文件中。

过一段时间之后，如果刷新缓冲区的脏页到磁盘时，发生错误，此时就可以借助于redo log进行数据恢复，这样就保证了事务的持久性。

而如果脏页成功刷新到磁盘或者涉及到的数据已经落盘，此时redolog就没有作用了，就可以删除了，所以存在的两个redolog文件是循环写的。

为什么每一次提交事务，要刷新redo log 到磁盘中呢，而不是直接将buffer pool中的脏页刷新到磁盘呢 ?
因为在业务操作中，我们操作数据一般都是随机读写磁盘的，而不是顺序读写磁盘。 而redo log在往磁盘文件中写入数据时，由于是日志文件，所以都是顺序写的。顺序写的效率，要远大于随机写。 这种先写日志的方式，称之为 WAL（Write-Ahead Logging）。






undo log回滚日志，用于记录数据被修改前的信息 , 作用包含两个 : 提供回滚(保证事务的原子性) 和 MVCC(多版本并发控制) 。
undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的 update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。

Undo log存储：undo log采用段的方式进行管理和记录，存放在前面介绍的 rollback segment 回滚段中，内部包含1024个undo log segment。
Undo log销毁：undo log在事务执行时产生，事务提交时，并不会立即删除undo log，因为这些日志可能还用于MVCC。

MVCC基本概念
当前读
读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。对于我们日常的操作，如：select … lock in share mode(共享锁)，select … for update、update、insert、delete(排他锁)都是一种当前读。
案例


上面案例中当前隔离级别是RC（可重复读）中，同时开启两个事务。在事务A中，使用普通select 查询语句无法查询事务B中修改的数据。
但是在查询语句后面加上了 lock in share mode 共享锁，此时是当前读操作。当然，我们加排他锁的时候，也是当前读操作。可以读取到事务B最新提交的内容。


快照读
简单的select（不加锁）就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读。

Read Committed 读已提交：每次select，都生成一个快照读
Repeatable Read 可重复高读：开启事务后第一个select语句才是快照读的地方。即第一次select查询产生快照读，后面的select查询直接使用前面的快照数据
Serializable 串行化：快照读会退化为当前读，每次读取都需要加锁

案例

在测试中,我们看到即使事务B提交了数据,事务A中也查询不到。原因就是因为普通的select是快照读，而在当前默认的RR隔离级别下，开启事务后第一个select语句才是快照读的地方，后面执行相同的select语句都是从快照中获取数据，可能不是当前的最新数据，这样也就保证了可重复读。

MVCC


   全称 Multi-Version Concurrency Control，多版本并发控制。指维护一个数据的多个版本， 使得读写操作没有冲突，快照读为MySQL实现MVCC提供了一个非阻塞读功能。MVCC的具体实现，还需要依赖于数据库记录中的三个隐式字段、undo log日志、readView。
隐藏字段当我们创建表的时候，除了我们自己定义的字段以为，InnoDB还会自动的给我们添加三个隐藏字段。


 前两个字段是肯定会添加的，是否添加最后一个字段DB_ROW_ID，得看当前表有没有主键，如果有主键，则不会添加该隐藏字段。

undo log
回滚日志，在insert、update、delete的时候产生的便于数据回滚的日志。
当insert的时候，产生的undo log日志只在回滚时需要，在事务提交后，可被立即删除。
而update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读时也需要，不会立即被删除。

undo log 版本链
演示：如果四个事务需要同时访问同一条记录时。


DB_TRX_ID : 代表最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID，是自增的。 DB_ROLL_PTR ： 由于这条数据是才插入的，没有被更新过，所以该字段值为null。



不同事务或相同事务对同一条记录进行修改，会导致该记录的undolog生成一条 记录版本链表，链表的头部是最新的旧记录，链表尾部是最早的旧记录。

readviewReadView（读视图）是 快照读 SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务（未提交的）id。


不同的隔离级别，生成ReadView的时机不同： 

READ COMMITTED：在事务中每一次执行快照读时生成ReadView。 
REPEATABLE READ：仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。

原理分析
RC隔离级别
RC隔离级别下，在事务中每一次执行快照读时生成ReadView。

分析：

将左下记录根据 DB_TRX_ID （当前事务id  为4）带入右下版本链规则 ①②③④ 中，发现都不成立。说明本次快照读查找的数据不是事务id为4的记录。
按照版本链往下找（根据表尾地址查找）下一条记录，找到事务id为3的记录，在 ①②③④ 都不成立，继续向下寻找。
找到一条事务id为2的记录，发现②成立。说明本次快照读查找的数据&#x3D;是事务id为2的记录。


RR隔离级别
RR隔离级别下，仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。 而RR 是可重复读，在一个事务中，执行两次相同的select语句，查询到的结果是一样的。

在RR隔离级别下，只是在事务中第一次快照读时生成ReadView，后续都是复用该 ReadView，那么既然ReadView都一样， ReadView的版本链匹配规则也一样， 那么最终快照读返回的结果也是一样的。


结论：MVCC的实现原理就是通过 InnoDB表的隐藏字段、UndoLog 版本链、ReadView来实现的。 而MVCC + 锁，则实现了事务的隔离性。 而一致性则是由redolog 与 undolog保证。

]]></content>
      <categories>
        <category>MySQL</category>
        <category>MySQL进阶</category>
      </categories>
      <tags>
        <tag>MySQL进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 4 - JVM 内存结构&#39;</title>
    <url>/2025/05/24/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%204%20-%20JVM%20%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[运行时数据区Java虚拟机在运行Java程序过程中管理的内存区域，称之为运行时数据区。《Java虚拟机规范》中规定了每一部分的作用。

根据 Java 虚拟机规范的规定，运行时数据区可以分为以下几个部分：

程序计数器（Program Counter Register）
Java 虚拟机栈（Java Virtual Machine Stacks）
本地方法栈（Native Method Stack）
堆（Heap）
方法区（Method Area）


程序计数器定义|作用程序计数器（Program Counter Register）也叫PC寄存器，用来存储指向下一条指令的地址，即将要执行的指令代码。由执行引擎读取下一条指令。
当我们的java程序被编译成二进制字节码文件后，如下图：

右面，是我们写的代码，左面是二进制字节码形式（.class）
它们将由我们的解释器来将他们转换为机械码，从而让机器运行。
细心的你会发现，每个二进制字节码的前面都有一个类似于索引的数字。他们的作用也跟索引差不多，为当前程序标一个序号，记上他们的地址。
即使有了地址，解释器也不知道他们的顺序是什么样的，他只负责运行。
于是，便有了程序计数器，程序计数器记下了字节码运行的顺序，每当一行字节码走完，他就会立即告诉解释器下一个该走哪里。
双双配合，最终实现全部代码。
这就是程序计数器的作用，不断为解释器寻找下一个要执行的程序。
特点
它是唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError 情况的区域

内存溢出（ OutOfMemoryError ）指的是程序在使用某一块内存区域时，存放的数据需要占用的内存大小超过了虚拟机能提供的内存上限。


它是一块很小的内存空间，几乎可以忽略不计。也是运行速度最快的存储区域

在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致

任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined）

它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成

字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令


Java虚拟机栈定义|作用Java虚拟机栈（Java Virtual Machine Stack）采用栈的数据结构来管理方法调用中的基本数据，先进后出（First In Last Out）,每一个方法的调用使用一个栈帧（Stack Frame）来保存。
Java虚拟机栈的栈帧（Frame）中主要包含以下内容：

局部变量表（Local Variables）：局部变量表的作用是在运行过程中存放所有的局部变量
操作数栈（Operand Stack）：操作数栈是栈帧中虚拟机在执行指令过程中用来存放临时数据的一块区域
帧数据：帧数据主要包含动态链接、方法出口、异常表的引用
动态链接（Dynamic Linking）：指向运行时常量池的方法引用
方法返回地址（Return Address）：方法正常退出或异常退出的地址
异常表



栈帧的内部结构局部变量表
存储基本数据类型 + 对象引用 + returnAddress 类型（指向了一条字节码指令的地址，已被异常表取代）
以**变量槽(Slot)**为最小单位（32位，64位数据占2个Slot）
编译期确定大小，运行期不改变

举个栗子：
以下代码的局部变量表中会占用几个槽？
public void test4(int k,int m)&#123;    &#123;        int a = 1;        int b = 2;    &#125;    &#123;        int c = 1;    &#125;    int i = 0;    long j = 1;&#125;

分析：

为了节省空间，局部变量表中的槽是可以复用的，一旦某个局部变量不再生效，当前槽就可以再次被使用。


方法执行时，实例对象this、k、m 会被放入局部变量表中，占用3个槽



将1的值放入局部变量表下标为3的位置上，相当于给a进行赋值。



将2放入局部变量表下标为4的位置，给b赋值为2。



ab已经脱离了生效范围，所以下标为3和4的这两个位置可以复用。此时c的值1就可以放入下标为3的位置。



脱离c的生效范围之后，给i赋值就可以复用c的位置。



最后放入j，j是一个long类型，占用两个槽。但是可以复用b所在的位置，所以占用4和5这两个位置


所以，局部变量表数值的长度为6。这一点在编译期间就可以确定了，运行过程中只需要在栈帧中创建长度为6的数组即可。

操作数栈
方法执行的工作区（类似CPU寄存器）
存储计算过程的中间结果

举个栗子：
public int calculate() &#123;    int a = 5;    int b = 3;    int c = a + b;  // 操作过程：                   // 1. iload_0 (压入a [将局部变量表中下标为 0 的 int 类型变量加载到操作数栈上])                   // 2. iload_1 (压入b [将局部变量表中下标为 1 的 int 类型变量加载到操作数栈上])                   // 3. iadd   (弹出两个值，相加后压回)                   // 4. istore_2(存储结果)    return c;&#125;

ps：操作数中的数据类型必须与字节码指令匹配，以上面的 iadd 指令为例，该指令只能用于整型数据的加法运算，它在执行的时候，栈顶的两个数据必须是 int 类型的，不能出现一个 long 型和一个 double 型的数据进行 iadd 命令相加的情况。
帧数据帧数据主要包含动态链接、方法返回地址、异常表的引用。
动态链接(Dynamic Linking)当前类的字节码指令引用了其他类的属性或者方法时，需要将符号引用（编号）转换成对应的运行时常量池中的内存地址。动态链接就保存了编号到运行时常量池的内存地址的映射关系。

指向运行时常量池的方法引用
支持多态特性（后期绑定）

方法返回地址(Return Address)方法出口指的是方法在正确或者异常结束时，当前栈帧会被弹出，同时程序计数器应该指向上一个栈帧中的下一条指令的地址。所以在当前栈帧中，需要存储此方法出口的地址。

存储调用者的程序计数器值
包含正常返回和异常返回两种路径

异常表异常表存放的是代码中异常的处理信息，包含了异常捕获的生效范围以及异常发生后跳转到的字节码指令位置。
栈内存异常StackOverflowError
原因：栈深度超过虚拟机限制（通常由无限递归引起）
// 典型示例：无限递归public void infiniteRecursion() &#123;    infiniteRecursion();&#125;

调节栈大小
-Xss256k-XX:ThreadStackSize=1024Windows（64位）下的JDK8测试最小值为180k，最大值为1024m。

OutOfMemoryError
原因：线程创建过多导致栈空间耗尽
场景：大量线程并发执行（通常需数千线程）

本地方法栈Java虚拟机栈存储了Java方法调用时的栈帧，而本地方法栈存储的是native本地方法的栈帧。
在Hotspot虚拟机中，Java虚拟机栈和本地方法栈实现上使用了同一个栈空间。本地方法栈会在栈内存上生成一个栈帧，临时保存方法的参数同时方便出现异常时也把本地方法的栈信息打印出来。

堆对于大多数应用，Java 堆是 Java 虚拟机管理的内存中最大的一块，被所有线程共享。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数据都在这里分配内存。
为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）：

新生带（年轻代）：新对象和没达到一定年龄的对象都在新生代
老年代（养老区）：被长时间使用的对象，老年代的内存空间应该要比年轻代更大
元空间（JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存

堆内存溢出
**java.lang.OutOfMemoryError: GC Overhead Limit Exceeded**：当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。
java.lang.OutOfMemoryError: Java heap space :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发此错误。和本机的物理内存无关，和我们配置的虚拟机内存大小有关！

设置堆的大小要修改堆的大小，可以使用虚拟机参数 –Xmx（max最大值）和-Xms (初始的total)。
语法：-Xmx值 -Xms值
单位：字节（默认，必须是 1024 的倍数）、k或者K(KB)、m或者M(MB)、g或者G(GB)
限制：Xmx必须大于 2 MB，Xms必须大于1MB
堆内存诊断
jps 工具查看当前系统中有哪些 java 进程
jmap 工具查看堆内存占用情况 jmap - heap 进程id
jconsole 工具图形界面的，多功能的监测工具，可以连续监测
jvisualvm 工具

方法区方法区属于是 JVM 运行时数据区域的一块逻辑区域，是各个线程共享的内存区域。在不同的 JDK 版本上有着不同的实现。在 JDK 7 的时候，方法区被称为永久代（PermGen），而在 JDK 8 的时候，永久代被彻底移除，取而代之的是元空间。
它的结构如下：

方法区内存溢出
JDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小。

-XX:PermSize=N &#x2F;&#x2F;方法区 (永久代) 初始大小

-XX:MaxPermSize=N &#x2F;&#x2F;方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen



JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是本地内存。

-XX:MetaspaceSize=N &#x2F;&#x2F;设置 Metaspace 的初始（和最小大小）
-XX:MaxMetaspaceSize=N &#x2F;&#x2F;设置 Metaspace 的最大大小



运行时常量池常量池就是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量信息。存在.class 文件中的 Constant_Pool 表。
举个栗子：
public class Test &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;Hello World!&quot;);    &#125;&#125;

然后使用 javap -v Test.class 命令反编译查看结果。

运行时常量池
类加载时创建：JVM 加载类时，将 .class 文件的常量池转换后放入方法区
动态性：运行时可以添加新常量（如 String.intern()）
真实地址：将符号引用解析为直接引用（内存真实地址）

动态添加栗子：
String s1 = new String(&quot;Hello&quot;);  // 堆中创建对象String s2 = s1.intern();           // 将&quot;Hello&quot;添加到运行时常量池System.out.println(s1 == s2);       // false（不同对象）System.out.println(&quot;Hello&quot; == s2);  // true（指向常量池同一对象）

常量池 vs 运行时常量池


特性
常量池 (Constant Pool)
运行时常量池 (Runtime Constant Pool)



存在位置
.class 文件中
JVM 方法区中（JDK8+ 的元空间）


创建时机
编译期生成
类加载时创建


内容是否可变
静态不可变
动态可变（运行时添加新常量）


存储内容
符号引用 + 字面量
类加载后的真实引用 + 动态常量


生命周期
文件存在即存在
类卸载时销毁


字符串常量池字符串常量池 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。
特点
常量池中的字符串仅是符号，只有在被用到时才会转化为对象
利用字符串常量池的机制，来避免重复创建字符串对象
字符串变量拼接的原理是StringBuilder
字符串常量拼接的原理是编译器优化
可以使用intern方法，主动将串池中还没有的字符串对象放入串池中

存放位置


JDK版本
字符串常量池位置
影响



JDK ≤ 6
运行时常量池（永久代）
容易引发 PermGen OOM


JDK 7+
堆内存 中单独划分区域
减少 OOM 风险，支持更大字符串池


字符串创建流程graph TD
    A[&quot;new String &#x27;hello&#x27;&quot;] --&gt; B&#123;&quot;池中是否存在？&quot;&#125;
    B --&gt;|否| C[&quot;在堆创建新对象&quot;]
    B --&gt;|是| D[&quot;返回池中引用&quot;]
    C --&gt; E&#123;&quot;调用 intern?&quot;&#125;
    E --&gt;|是| F[&quot;将引用加入字符串池&quot;]
    E --&gt;|否| G[&quot;直接使用堆对象&quot;]


intern方法
JDK1.8
调用字符串对象的intern()方法，会将该字符串对象尝试放入到串池中。

如果串池中没有该字符串对象，则放入成功，返回引用的对象
如果有该字符串对象，则放入失败,返回字符串里有的该对象

无论放入是否成功，都会返回串池中的字符串对象。
注意：此时如果调用intern方法成功，堆内存与串池中的字符串对象是同一个对象；如果失败，则不是同一个对象

JDK1.6
调用字符串对象的intern方法，会将该字符串对象尝试放入到串池中

如果串池中没有该字符串对象，会将该字符串对象复制一份，再放入到串池中，返回的是复制的对象
如果有该字符串对象，则放入失败，返回串池原有的该字符串的对象

注意：此时无论调用intern方法成功与否，串池中的字符串对象和堆内存中的字符串对象都不是同一个对象


字符串常量池和运行时常量池有什么关系？早期设计时，字符串常量池是属于运行时常量池的一部分，他们存储的位置也是一致的。后续做出了调整，将字符串常量池和运行时常量池做了拆分。

静态变量存储在哪里呢？
JDK6及之前的版本中，静态变量是存放在方法区中的，也就是永久代。
JDK7及之后的版本中，静态变量是存放在堆中的Class对象中，脱离了永久代。具体源码可参考虚拟机源码：BytecodeInterpreter针对putstatic指令的处理。


直接内存直接内存指的就是Direct Memory，常见于Nio操作，区别于io，在读写操作时有着更高的效率。直接内存并不在《Java虚拟机规范》中存在，所以并不属于Java运行时的内存区域。
特点
常见于 NIO 操作时，用于数据缓冲区
分配回收成本较高，但读写性能高
不受 JVM 内存回收管理




学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 5 - GC 垃圾回收</title>
    <url>/2025/05/25/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%205%20-%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</url>
    <content><![CDATA[垃圾回收JVM 垃圾回收 (Garbage Collection, GC) 是 Java 虚拟机自动管理堆内存的核心机制。它负责识别并回收程序中不再使用的对象所占用的内存，防止内存泄漏，极大地简化了开发人员的内存管理工作。  
垃圾回收器如果发现某个对象不再使用，就可以回收该对象。
.pidbxjspqrxr{zoom: 67%;}

.xgkyoxwyqyop{zoom:67%;}


自动垃圾回收，自动根据对象是否使用由虚拟机来回收对象

优点：降低程序员实现难度、降低对象回收bug的可能性
缺点：程序员无法控制内存回收的及时性


手动垃圾回收，由程序员编程实现对象的删除

优点：回收及时性高，由程序员把控回收的时机
缺点：编写不当容易出现悬空指针、重复释放、内存泄漏等问题




如果需要手动触发垃圾回收，可以调用System.gc()方法。语法： System.gc()注意事项：   调用System.gc()方法并不一定会立即回收垃圾，仅仅是向Java虚拟机发送一个垃圾回收的请求，具体是否需要执行垃圾回收Java虚拟机会自行判断。

如何判断对象可以回收引用计数法引用计数法会为每个对象维护一个引用计数器，当对象被引用时加1，取消引用时减1。当值为 0 时，就表示该对象不被引用，可以被垃圾收集器回收。
缺点：  

每次引用和取消引用都需要维护计数器，对系统性能会有一定的影响
存在循环引用问题，所谓循环引用就是当A引用B，B同时引用A时会出现对象无法回收的问题。如下图：

.hnstjkurfzoy{zoom:80%;}

可达性分析法通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收。


JVM 中的垃圾回收器通过可达性分析来探索所有存活的对象
扫描堆中的对象，看能否沿着 GC Root 对象为起点的引用链找到该对象，如果找不到，则表示可以回收
Java 中可以作为 GC Root 的对象：
虚拟机栈（栈帧中的本地变量表）中引用的对象。
方法区中类静态属性引用的对象
方法区中常量引用的对象
本地方法栈中 JNI（即一般说的Native方法）引用的对象

引用对象.hemehivszvtd{zoom:80%;}

1. 强引用（StrongReference）被强引用关联的对象不会被回收。只有GC Root都不引用该对象时，才会回收强引用对象
2. 软引用（SoftReference）如果一个对象只有软引用引对象时，当程序内存不足时，就会将软引用中的数据进行回收。在JDK 1.2版之后提供了SoftReference类来实现软引用，软引用常用于缓存中。
3. 弱引用（WeakReference）如果一个对象只有弱引用该对象时，在垃圾回收时，无论内存是否充足，就会将弱引用中的数据进行回收。在JDK 1.2版之后提供了WeakReference类来实现弱引用，弱引用主要在ThreadLocal中使用。
4. 虚引用（PhantomReference）（不常见）虚引用也叫幽灵引用&#x2F;幻影引用，不能通过虚引用对象获取到包含的对象。虚引用唯一的用途是当对象被垃圾回收器回收时可以接收到对应的通知。Java中使用PhantomReference实现了虚引用，直接内存中为了及时知道直接内存对象不再使用，从而回收内存，使用了虚引用来实现。
5. 终结器引用（FinalReference）（不常见）终结器引用指的是在对象需要被回收时，终结器引用会关联对象并放置在Finalizer类中的引用队列中，在稍后由一条由FinalizerThread线程从队列中获取对象，然后执行对象的finalize方法，在对象第二次被回收时，该对象才真正的被回收。在这个过程中可以在finalize方法中再将自身对象使用强引用关联上，但是不建议这样做。
垃圾回收算法1. 标记-清除算法
虚拟机执行垃圾回收的过程中，使用可达性分析算法，从GC Root开始通过引用链遍历出所有存活对象。将所有存活的对象进行标记。
然后垃圾收集器根据标识清除没有被标记也就是非存活对象，给堆内存腾出相应的空间


优点：实现简单，只需要在第一阶段给每个对象维护标志位，第二阶段删除对象即可。
缺点：

会产生大量不连续的内存碎片，导致无法给大对象分配内存。由于内存是连续的，所以在对象被删除之后，内存中会出现很多细小的可用内存单元。如果我们需要的是一个比较大的空间，很有可能这些内存单元的大小过小无法进行分配。
分配速度慢。由于内存碎片的存在，需要维护一个空闲链表，极有可能发生每次需要遍历到链表的最后才能获得合适的内存空间。
标记和清除过程效率都不高。

2. 标记-整理算法标记整理算法也叫标记压缩算法，是对标记清理算法中容易产生内存碎片问题的一种解决方案。

标记阶段，将所有存活的对象进行标记。Java中使用可达性分析算法，从GC Root开始通过引用链遍历出所有存活对象。
整理阶段，将存活对象移动到堆的一端。清理掉存活对象的内存空间。


优点：不会产生内存碎片。
缺点：内存变动更频繁，需要整理所有存活对象的引用地址，效率不高。
3. 复制算法将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理，最后会把位置互换。

优点：不会产生内存碎片；吞吐量高，复制算法只需要遍历一次存活对象复制到To空间即可，比标记-整理算法少了一次遍历的过程，因而性能较好，但是不如标记-清除算法，因为标记清除算法不需要进行对象的移动
缺点：内存使用效率低，每次只能让一半的内存空间来为创建对象使用。
4. 分代垃圾回收算法现代优秀的垃圾回收算法，会将上述描述的垃圾回收算法组合进行使用，其中应用最广的就是分代垃圾回收算法(Generational GC)。  
分代垃圾回收将整个内存区域划分为年轻代（复制算法）和老年代（标记 - 清除 或者 标记 - 整理 算法）：
.cvvoluolfpxi{zoom: 80%;}


分代回收时，创建出来的对象，首先会被放入Eden伊甸园区。

随着对象在Eden区越来越多，如果Eden区满，新创建的对象已经无法放入，就会触发年轻代的GC，称为Minor GC或者Young GC。  
Minor GC会把需要eden中和From需要回收的对象回收，把没有回收的对象放入To区。

接下来，S0会变成To区，S1变成From区。当eden区满时再往里放入对象，依然会发生Minor GC。  
此时会回收eden区和S1(from)中的对象，并把eden和from区中剩余的对象放入S0。注意：每次Minor GC中都会为对象记录他的年龄，初始值为0，每次GC完加1。

如果Minor GC后对象的年龄达到阈值（最大15，默认值和垃圾回收器有关），对象就会被晋升至老年代。

当老年代中空间不足，无法放入新的对象时，先尝试minor gc如果还是不足，就会触发Full GC，Full GC会对整个堆进行垃圾回收。
如果Full GC依然无法回收掉老年代的对象，那么当对象继续放入老年代时，就会抛出Out Of Memory异常。

特殊情况：当遇到一个较大的对象时，就算新生代的伊甸园为空，也无法容纳该对象时，会将该对象直接晋升为老年代。


相关 JVM 参数


含义
参数



堆初始大小必须是1024倍数且大于1MB
-Xms


堆最大大小必须是1024倍数且大于1MB
-Xmx 或 -XX:MaxHeapSize&#x3D;size


新生代大小
-Xmn 或 (-XX:NewSize&#x3D;size + -XX:MaxNewSize&#x3D;size )


幸存区比例（动态）
-XX:InitialSurvivorRatio&#x3D;ratio 和 -XX:+UseAdaptiveSizePolicy


伊甸园区和幸存区的比例，默认8，新生代1G，伊甸园区800MB,S0和S1各100MB
-XX:SurvivorRatio&#x3D;ratio


晋升阈值
-XX:MaxTenuringThreshold&#x3D;threshold


晋升详情
-XX:+PrintTenuringDistribution


打印GC日志
-XX:+PrintGCDetails -verbose:gc


FullGC 前 MinorGC
-XX:+ScavengeBeforeFullGC


垃圾回收器为什么分代GC算法要把堆分成年轻代和老年代？首先我们要知道堆内存中对象的特性：

系统中的大部分对象，都是创建出来之后很快就不再使用可以被回收，比如用户获取订单数据，订单数据返回给用户之后就可以释放了。
老年代中会存放长期存活的对象，比如Spring的大部分bean对象，在程序启动之后就不会被回收了。
在虚拟机的默认设置中，新生代大小要远小于老年代的大小。

分代GC算法将堆分成年轻代和老年代主要原因有：

可以通过调整年轻代和老年代的比例来适应不同类型的应用程序，提高内存的利用率和性能。

新生代和老年代使用不同的垃圾回收算法，新生代一般选择复制算法，老年代可以选择标记-清除和标记-整理算法，由程序员来选择灵活度较高。

分代的设计中允许只回收新生代（minor gc），如果能满足对象分配的要求就不需要对整个堆进行回收(full gc),STW时间就会减少。


垃圾回收器是垃圾回收算法的具体实现。
由于垃圾回收器分为年轻代和老年代，除了G1之外其他垃圾回收器必须成对组合进行使用。
具体的关系图如下：


Serial 收集器Serial 收集器是最基本的、发展历史最悠久的收集器。是一种单线程串行回收年轻代的垃圾回收器，只会使用一个线程进行垃圾收集工作，使用标记-复制算法。  
.wolacykoarom{zoom:80%;}

优点：

单线程、简单高效（与其他收集器的单线程相比）。对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程手机效率。收集器进行垃圾回收时，必须暂停其他所有的工作线程（ “Stop The World” ），直到它结束。

 缺点：

多CPU下吞吐量不如其他垃圾回收器，堆如果偏大会让用户线程处于长时间的等待。

适用场景： 

Java编写的客户端程序或者硬件配置有限的场景。


-XX:+UseSerialGC&#x3D;serial + serialOld

SerialOld垃圾回收器SerialOld是Serial垃圾回收器的老年代版本，采用单线程串行回收。使用标记-整理算法。
.lxrfdeybwbkq{zoom:80%;}

ParNew 收集器ParNew 收集器其实就是 Serial 收集器在多CPU下的优化，使用多线程进行垃圾回收。新生代采用标记-复制算法，老年代采用标记-整理算法。
-XX:+UseParNewGC 新生代使用ParNew回收器， 老年代使用串行回收器

优点：

多线程、ParNew 收集器默认开启的收集线程数与CPU的数量相同，在 CPU 非常多的环境中，可以使用 -XX:ParallelGCThreads 参数来限制垃圾收集的线程数。和 Serial 收集器一样存在 Stop The World 问题。

缺点：

吞吐量和停顿时间不如G1，所以在JDK9之后不建议使用。

适用场景：

JDK8及之前的版本中，与CMS老年代垃圾回收器搭配使用

CMS 收集器CMS(Concurrent Mark Sweep)，从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 标记-清除算法实现的。 老年代收集器。参数：XX:+UseConcMarkSweepGC。
CMS垃圾回收器关注的是系统的暂停时间，允许用户线程和垃圾回收线程在某些步骤中同时执行，减少了用户线程的等待时间。

CMS执行步骤：
1.初始标记，用极短的时间标记出GC Roots能直接关联到的对象。速度很快但是仍存在Stop The World问题。
2.并发标记,   标记所有的对象，用户线程不需要暂停。
3.重新标记，由于并发标记阶段有些对象会发生了变化，存在错标、漏标等情况，需要重新标记。存在Stop The World问题。
4.并发清理，清理死亡的对象，用户线程不需要暂停。但是清除的过程中，可能任然会有新的垃圾产生，这些垃圾就叫浮动垃圾，如果当用户需要存入一个很大的对象时，新生代放不下去，老年代由于浮动垃圾过多，就会退化为 serial Old 收集器，将老年代垃圾进行标记-整理，当然这也是很耗费时间的！

在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。
CMS 垃圾回收器在 Java 9 中已经被标记为过时(deprecated)，并在 Java 14 中被移除。

优点：

系统由于垃圾回收出现的停顿时间较短，用户体验好。

缺点：

吞吐量低: 低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。

无法处理在并发清理过程中产生的“浮动垃圾”，不能做到完全的垃圾回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。

标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。


适用场景:

大型的互联网系统中用户请求数据量大、频率高的场景，比如订单接口、商品接口等

Parallel Scavenge垃圾回收器Parallel Scavenge是JDK8默认的年轻代垃圾回收器，多线程并行回收，关注的是系统的吞吐量（指 CPU 用于运行用户代码的时间占总时间的比值）。具备自动调整堆内存大小的特点。使用 标记-复制算法。
优点：

吞吐量高，可以通过一个开关参数打开 GC 自适应的调节策略(GC Ergonomics)。为了提高吞吐量，虚拟机会动态调整堆的参数。

GC自适应调节策略：Parallel Scavenge收集器可设置-XX:+UseAdptiveSizePolicy参数。当开关打开时不需要手动指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRation）、晋升老年代的对象年龄（-XX:PretenureSizeThreshold）等，虚拟机会根据系统的运行状况收集性能监控信息，动态设置这些参数以提供最优的停顿时间和最高的吞吐量，这种调节方式称为GC的自适应调节策略。



缺点：

不能保证单次的停顿时间。

适用场景：

后台任务，不需要与用户交互，并且容易产生大量的对象。比如：大数据的处理，大文件导出。

Parallel Old垃圾回收器Parallel Scavenge 收集器的老年代版本。使用多线程和标记-整理算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。
.jrafvcnnntoi{zoom:80%;}

优点：

并发收集，在多核CPU下效率较高

缺点：

暂停时间会比较长

适用场景：

与Parallel Scavenge配套使用

G1垃圾回收器JDK9之后默认的垃圾回收器是G1（Garbage First）垃圾回收器。Parallel Scavenge关注吞吐量，允许用户设置最大暂停时间 ，但是会减少年轻代可用空间的大小。CMS关注暂停时间，但是吞吐量方面会下降。
而G1设计目标就是将上述两种垃圾回收器的优点融合：
1.支持巨大的堆空间回收，并有较高的吞吐量。
2.支持多CPU并行垃圾回收。
3.允许用户设置最大暂停时间。
G1出现之前的垃圾回收器，年轻代和老年代一般是连续的，如下图：
.bbrhfotcweee{zoom:80%;}

G1的整个堆会被划分成多个大小相等的区域，称之为区Region，区域不要求是连续的。每个 Region 逻辑上可属于 Eden、Survivor、Old或 Humongous（存储大于 Region 一半大小的对象）。Region的大小通过堆空间大小&#x2F;2048计算得到，也可以通过参数-XX:G1HeapRegionSize&#x3D;32m指定(其中32m指定region大小为32M)，Region size必须是2的指数幂，取值范围从1M到32M。
.jycolouqcffd{zoom:80%;}

G1 执行流程1. Young GC（新生代回收）年轻代回收（Young GC），回收Eden区和Survivor区中不用的对象。会导致STW，G1中可以通过参数 -XX:MaxGCPauseMillis=n（默认200）设置每次垃圾回收时的最大暂停时间毫秒数，G1垃圾回收器会尽可能地保证暂停时间。

触发条件：
Eden 区占满，或 G1 预测回收时间接近目标停顿时间。

步骤：

新创建的对象会存放在Eden区。当G1判断年轻代区不足（max默认60%），无法分配对象时需要回收时会执行Young GC。

标记出Eden和Survivor区域中的存活对象。

根据配置的最大暂停时间选择某些区域将存活对象复制到一个新的Survivor区中（年龄+1），清空这些区域。

G1在进行Young GC的过程中会去记录每次垃圾回收时每个Eden区和Survivor区的平均耗时，以作为下次回收时的参考依据。这样就可以根据配置的最大暂停时间计算出本次回收时最多能回收多少个Region区域了。比如 -XX:MaxGCPauseMillis&#x3D;n（默认200），每个Region回收耗时40ms，那么这次回收最多只能回收4个Region。


后续Young GC时与之前相同，只不过Survivor区中存活对象会被搬运到另一个Survivor区。

当某个在Survivor区存活对象的年龄到达阈值（默认15），将被放入老年代。

部分对象如果大小超过Region的一半，会直接放入老年代，这类老年代被称为Humongous区。比如堆内存是4G，每个Region是2M，只要一个大对象超过了1M就被放入Humongous区，如果对象过大会横跨多个Region。

多次回收之后，会出现很多Old老年代区，此时总堆占有率达到阈值时（-XX:InitiatingHeapOccupancyPercent默认45%）会触发混合回收MixedGC。回收所有年轻代和部分老年代的对象以及大对象区。采用复制算法来完成。




2. Mixed GC（混合回收，核心流程）
触发条件：
老年代占用达 45%（默认）或手动触发。G1对老年代的清理会选择存活度最低的区域来进行回收，这样可以保证回收效率最高，这也是G1（Garbage first）名称的由来。最后清理阶段使用复制算法，不会产生内存碎片。

步骤：

初始标记（STW）：采用三色标记法标记从GC Root可直达的对象。 STW时间极短。
并发标记（并行）：递归标记所有存活对象，使用 SATB（快照）记录引用变化，避免漏标。
最终标记（STW）：处理并发标记期间的引用变更，修复漏标。
筛选回收（STW）：
按 “回收收益” 排序 Region，选择回收集合（CSet）。
复制存活对象到新 Region，清空原 Region。






注意：如果清理过程中发现没有足够的空Region存放转移的对象，会出现Full GC。单线程执行标记-整理算法，此时会导致用户线程的暂停。所以尽量保证应该用的堆内存有一定多余的空间。
3. Full GC
触发条件：

G1 在老年代内存不足时（老年代所占内存超过阈值）。
如果垃圾产生速度慢于垃圾回收速度，不会触发 Full GC，还是并发地进行清理
如果垃圾产生速度快于垃圾回收速度，便会触发 Full GC，然后退化成 serial Old 收集器串行的收集，就会导致停顿的时候长。


特点：


单线程全堆扫描，停顿时间极长，需通过调优避免
学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
</search>
