<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>系统升级</title>
    <url>/2025/06/04/RandomNotes/%E7%B3%BB%E7%BB%9F%E5%8D%87%E7%BA%A7/</url>
    <content><![CDATA[SSH框架升级为SpringBoot前言和准备
公司系统使用框架为SSH（Spring + Spring MVC + Hibernate)，现在要求升级为SpringBoot。  
原项目：Spring 3.1.3 + Hibernate 4.2.21 使用jar包方式  
准备升级为：SpringBoot2.7.6 +  使用mavne管理jar包
Spring Boot 2.x需要Spring 5和Hibernate 5.2+，因此我们需要升级这些依赖。

步骤1. 创建Spring Boot项目   使用阿里云地址 https://start.aliyun.com/ 来创建一个新的Spring Boot 项目。选择 JDK8、Maven、Spring Boot 版本2.7.6。
   目录结构为：
   
2. jar包用maven替换将原项目src下的目录复制到新建的项目中。先运行一下@SpringBootApplication 类，根据报错去添加相关依赖。没有去网站[Maven Repository: Search/Browse/Explore (mvnrepository.com)](https://mvnrepository.com/)下载依赖。
1. 集成log4j
Spring Boot 已弃用 spring-boot-starter-log4j：  Spring Boot 从 1.2.x 版本开始，官方推荐使用 Logback 或 Log4j2，不再支持旧版的 Log4j 1.x。  因此，spring-boot-starter-log4j 在较新的 Spring Boot 版本中已被移除。

   因为之前系统使用log4j，为了不用改配置和代码，确定继续使用log4j。下载好依赖后导入 pom.xml 文件中。
   &lt;!--添加log4j依赖模块--&gt;&lt;dependency&gt;   &lt;groupId&gt;log4j&lt;/groupId&gt;   &lt;artifactId&gt;log4j&lt;/artifactId&gt;   &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt;

2. 集成Hibernate    原系统使用的 hibernate  版本 4.2.21。

导入依赖

   &lt;!-- 只需添加 JPA Starter Spring Boot 会自动引入兼容的 Hibernate 版本（无需手动指定）--&gt;&lt;dependency&gt;   &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;   &lt;artifactId&gt;spring-boot-starter-data-jpa&lt;/artifactId&gt;&lt;/dependency&gt;

   spring-boot-starter-data-jpa 已集成 Hibernate 核心依赖，无需单独引入 hibernate-core 等包。  

配置文件

   以前需要在application-context.xml 文件中配置
   .luvnugbeqram{zoom:80%;}

   现在只需要在application.yaml 文件中配置即可。
   
3. 前端代码移植
原系统使用JSP，需要将原项目WebContent 目录下的文件复制到，webapp 目录下。

原系统：



现在系统：



配置视图解析器


mvc:   view:     prefix: /WEB-INF/jsp/ #配置视图解析器     suffix: .jsp web:   resources:     static-locations: classpath:/static/,classpath:/WEB-INF/userData/,classpath:/WEB-INF/temp/ #设置静态资源路径


引入依赖
&lt;!--SpringBoot不推荐使用jsp  加入一个处理jsp的依赖。 负责编译jsp文件--&gt;&lt;dependency&gt;    &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt;    &lt;artifactId&gt;tomcat-embed-jasper&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--jstl 依赖--&gt;&lt;dependency&gt;    &lt;groupId&gt;javax.servlet&lt;/groupId&gt;    &lt;artifactId&gt;jstl&lt;/artifactId&gt;&lt;/dependency&gt;

]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 1 - JVM介绍</title>
    <url>/2025/05/21/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%201%20-%20JVM%E4%BB%8B%E7%BB%8D/</url>
    <content><![CDATA[JVM什么是JVMJVM 全称是 Java Virtual Machine，中文译名 Java虚拟机，是 Java 生态的核心，它负责执行字节码，提供内存管理、垃圾回收、线程管理等功能，使 Java 程序能够实现 “一次编写，到处运行” 的跨平台特性。
JVM的三大核心功能是什么？JVM 包含内存管理、解释执行虚拟机指令、即时编译三大功能。
常见的JVM虚拟机有哪些？
JVM知识体系
学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 4 - JVM 内存结构&#39;</title>
    <url>/2025/05/24/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%204%20-%20JVM%20%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/</url>
    <content><![CDATA[运行时数据区Java虚拟机在运行Java程序过程中管理的内存区域，称之为运行时数据区。《Java虚拟机规范》中规定了每一部分的作用。

根据 Java 虚拟机规范的规定，运行时数据区可以分为以下几个部分：

程序计数器（Program Counter Register）
Java 虚拟机栈（Java Virtual Machine Stacks）
本地方法栈（Native Method Stack）
堆（Heap）
方法区（Method Area）


程序计数器定义|作用程序计数器（Program Counter Register）也叫PC寄存器，用来存储指向下一条指令的地址，即将要执行的指令代码。由执行引擎读取下一条指令。
当我们的java程序被编译成二进制字节码文件后，如下图：

右面，是我们写的代码，左面是二进制字节码形式（.class）
它们将由我们的解释器来将他们转换为机械码，从而让机器运行。
细心的你会发现，每个二进制字节码的前面都有一个类似于索引的数字。他们的作用也跟索引差不多，为当前程序标一个序号，记上他们的地址。
即使有了地址，解释器也不知道他们的顺序是什么样的，他只负责运行。
于是，便有了程序计数器，程序计数器记下了字节码运行的顺序，每当一行字节码走完，他就会立即告诉解释器下一个该走哪里。
双双配合，最终实现全部代码。
这就是程序计数器的作用，不断为解释器寻找下一个要执行的程序。
特点
它是唯一一个在 JVM 规范中没有规定任何 OutOfMemoryError 情况的区域

内存溢出（ OutOfMemoryError ）指的是程序在使用某一块内存区域时，存放的数据需要占用的内存大小超过了虚拟机能提供的内存上限。


它是一块很小的内存空间，几乎可以忽略不计。也是运行速度最快的存储区域

在 JVM 规范中，每个线程都有它自己的程序计数器，是线程私有的，生命周期与线程的生命周期一致

任何时间一个线程都只有一个方法在执行，也就是所谓的当前方法。如果当前线程正在执行的是 Java 方法，程序计数器记录的是 JVM 字节码指令地址，如果是执行 native 方法，则是未指定值（undefined）

它是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成

字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令


Java虚拟机栈定义|作用Java虚拟机栈（Java Virtual Machine Stack）采用栈的数据结构来管理方法调用中的基本数据，先进后出（First In Last Out）,每一个方法的调用使用一个栈帧（Stack Frame）来保存。
Java虚拟机栈的栈帧（Frame）中主要包含以下内容：

局部变量表（Local Variables）：局部变量表的作用是在运行过程中存放所有的局部变量
操作数栈（Operand Stack）：操作数栈是栈帧中虚拟机在执行指令过程中用来存放临时数据的一块区域
帧数据：帧数据主要包含动态链接、方法出口、异常表的引用
动态链接（Dynamic Linking）：指向运行时常量池的方法引用
方法返回地址（Return Address）：方法正常退出或异常退出的地址
异常表



栈帧的内部结构局部变量表
存储基本数据类型 + 对象引用 + returnAddress 类型（指向了一条字节码指令的地址，已被异常表取代）
以**变量槽(Slot)**为最小单位（32位，64位数据占2个Slot）
编译期确定大小，运行期不改变

举个栗子：
以下代码的局部变量表中会占用几个槽？
public void test4(int k,int m)&#123;    &#123;        int a = 1;        int b = 2;    &#125;    &#123;        int c = 1;    &#125;    int i = 0;    long j = 1;&#125;

分析：

为了节省空间，局部变量表中的槽是可以复用的，一旦某个局部变量不再生效，当前槽就可以再次被使用。


方法执行时，实例对象this、k、m 会被放入局部变量表中，占用3个槽



将1的值放入局部变量表下标为3的位置上，相当于给a进行赋值。



将2放入局部变量表下标为4的位置，给b赋值为2。



ab已经脱离了生效范围，所以下标为3和4的这两个位置可以复用。此时c的值1就可以放入下标为3的位置。



脱离c的生效范围之后，给i赋值就可以复用c的位置。



最后放入j，j是一个long类型，占用两个槽。但是可以复用b所在的位置，所以占用4和5这两个位置


所以，局部变量表数值的长度为6。这一点在编译期间就可以确定了，运行过程中只需要在栈帧中创建长度为6的数组即可。

操作数栈
方法执行的工作区（类似CPU寄存器）
存储计算过程的中间结果

举个栗子：
public int calculate() &#123;    int a = 5;    int b = 3;    int c = a + b;  // 操作过程：                   // 1. iload_0 (压入a [将局部变量表中下标为 0 的 int 类型变量加载到操作数栈上])                   // 2. iload_1 (压入b [将局部变量表中下标为 1 的 int 类型变量加载到操作数栈上])                   // 3. iadd   (弹出两个值，相加后压回)                   // 4. istore_2(存储结果)    return c;&#125;

ps：操作数中的数据类型必须与字节码指令匹配，以上面的 iadd 指令为例，该指令只能用于整型数据的加法运算，它在执行的时候，栈顶的两个数据必须是 int 类型的，不能出现一个 long 型和一个 double 型的数据进行 iadd 命令相加的情况。
帧数据帧数据主要包含动态链接、方法返回地址、异常表的引用。
动态链接(Dynamic Linking)当前类的字节码指令引用了其他类的属性或者方法时，需要将符号引用（编号）转换成对应的运行时常量池中的内存地址。动态链接就保存了编号到运行时常量池的内存地址的映射关系。

指向运行时常量池的方法引用
支持多态特性（后期绑定）

方法返回地址(Return Address)方法出口指的是方法在正确或者异常结束时，当前栈帧会被弹出，同时程序计数器应该指向上一个栈帧中的下一条指令的地址。所以在当前栈帧中，需要存储此方法出口的地址。

存储调用者的程序计数器值
包含正常返回和异常返回两种路径

异常表异常表存放的是代码中异常的处理信息，包含了异常捕获的生效范围以及异常发生后跳转到的字节码指令位置。
栈内存异常StackOverflowError
原因：栈深度超过虚拟机限制（通常由无限递归引起）
// 典型示例：无限递归public void infiniteRecursion() &#123;    infiniteRecursion();&#125;

调节栈大小
-Xss256k-XX:ThreadStackSize=1024Windows（64位）下的JDK8测试最小值为180k，最大值为1024m。

OutOfMemoryError
原因：线程创建过多导致栈空间耗尽
场景：大量线程并发执行（通常需数千线程）

本地方法栈Java虚拟机栈存储了Java方法调用时的栈帧，而本地方法栈存储的是native本地方法的栈帧。
在Hotspot虚拟机中，Java虚拟机栈和本地方法栈实现上使用了同一个栈空间。本地方法栈会在栈内存上生成一个栈帧，临时保存方法的参数同时方便出现异常时也把本地方法的栈信息打印出来。

堆对于大多数应用，Java 堆是 Java 虚拟机管理的内存中最大的一块，被所有线程共享。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例以及数据都在这里分配内存。
为了进行高效的垃圾回收，虚拟机把堆内存逻辑上划分成三块区域（分代的唯一理由就是优化 GC 性能）：

新生带（年轻代）：新对象和没达到一定年龄的对象都在新生代
老年代（养老区）：被长时间使用的对象，老年代的内存空间应该要比年轻代更大
元空间（JDK1.8 之前叫永久代）：像一些方法中的操作临时对象等，JDK1.8 之前是占用 JVM 内存，JDK1.8 之后直接使用物理内存

堆内存溢出
**java.lang.OutOfMemoryError: GC Overhead Limit Exceeded**：当 JVM 花太多时间执行垃圾回收并且只能回收很少的堆空间时，就会发生此错误。
java.lang.OutOfMemoryError: Java heap space :假如在创建新的对象时, 堆内存中的空间不足以存放新创建的对象, 就会引发此错误。和本机的物理内存无关，和我们配置的虚拟机内存大小有关！

设置堆的大小要修改堆的大小，可以使用虚拟机参数 –Xmx（max最大值）和-Xms (初始的total)。
语法：-Xmx值 -Xms值
单位：字节（默认，必须是 1024 的倍数）、k或者K(KB)、m或者M(MB)、g或者G(GB)
限制：Xmx必须大于 2 MB，Xms必须大于1MB
堆内存诊断
jps 工具查看当前系统中有哪些 java 进程
jmap 工具查看堆内存占用情况 jmap - heap 进程id
jconsole 工具图形界面的，多功能的监测工具，可以连续监测
jvisualvm 工具

方法区方法区属于是 JVM 运行时数据区域的一块逻辑区域，是各个线程共享的内存区域。在不同的 JDK 版本上有着不同的实现。在 JDK 7 的时候，方法区被称为永久代（PermGen），而在 JDK 8 的时候，永久代被彻底移除，取而代之的是元空间。
它的结构如下：

方法区内存溢出
JDK 1.8 之前永久代还没被彻底移除的时候通常通过下面这些参数来调节方法区大小。

-XX:PermSize=N &#x2F;&#x2F;方法区 (永久代) 初始大小

-XX:MaxPermSize=N &#x2F;&#x2F;方法区 (永久代) 最大大小,超过这个值将会抛出 OutOfMemoryError 异常:java.lang.OutOfMemoryError: PermGen



JDK 1.8 的时候，方法区（HotSpot 的永久代）被彻底移除了（JDK1.7 就已经开始了），取而代之是元空间，元空间使用的是本地内存。

-XX:MetaspaceSize=N &#x2F;&#x2F;设置 Metaspace 的初始（和最小大小）
-XX:MaxMetaspaceSize=N &#x2F;&#x2F;设置 Metaspace 的最大大小



运行时常量池常量池就是一张表，虚拟机指令根据这张常量表找到要执行的类名、方法名、参数类型、字面量信息。存在.class 文件中的 Constant_Pool 表。
举个栗子：
public class Test &#123;    public static void main(String[] args) &#123;        System.out.println(&quot;Hello World!&quot;);    &#125;&#125;

然后使用 javap -v Test.class 命令反编译查看结果。

运行时常量池
类加载时创建：JVM 加载类时，将 .class 文件的常量池转换后放入方法区
动态性：运行时可以添加新常量（如 String.intern()）
真实地址：将符号引用解析为直接引用（内存真实地址）

动态添加栗子：
String s1 = new String(&quot;Hello&quot;);  // 堆中创建对象String s2 = s1.intern();           // 将&quot;Hello&quot;添加到运行时常量池System.out.println(s1 == s2);       // false（不同对象）System.out.println(&quot;Hello&quot; == s2);  // true（指向常量池同一对象）

常量池 vs 运行时常量池


特性
常量池 (Constant Pool)
运行时常量池 (Runtime Constant Pool)



存在位置
.class 文件中
JVM 方法区中（JDK8+ 的元空间）


创建时机
编译期生成
类加载时创建


内容是否可变
静态不可变
动态可变（运行时添加新常量）


存储内容
符号引用 + 字面量
类加载后的真实引用 + 动态常量


生命周期
文件存在即存在
类卸载时销毁


字符串常量池字符串常量池 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。
特点
常量池中的字符串仅是符号，只有在被用到时才会转化为对象
利用字符串常量池的机制，来避免重复创建字符串对象
字符串变量拼接的原理是StringBuilder
字符串常量拼接的原理是编译器优化
可以使用intern方法，主动将串池中还没有的字符串对象放入串池中

存放位置


JDK版本
字符串常量池位置
影响



JDK ≤ 6
运行时常量池（永久代）
容易引发 PermGen OOM


JDK 7+
堆内存 中单独划分区域
减少 OOM 风险，支持更大字符串池


字符串创建流程：graph TD    A[&quot;new String &#x27;hello&#x27;&quot;] --&gt; B&#123;&quot;池中是否存在？&quot;&#125;    B --&gt;|否| C[&quot;在堆创建新对象&quot;]    B --&gt;|是| D[&quot;返回池中引用&quot;]    C --&gt; E&#123;&quot;调用 intern?&quot;&#125;    E --&gt;|是| F[&quot;将引用加入字符串池&quot;]    E --&gt;|否| G[&quot;直接使用堆对象&quot;]


intern方法
JDK1.8
调用字符串对象的intern()方法，会将该字符串对象尝试放入到串池中。

如果串池中没有该字符串对象，则放入成功，返回引用的对象
如果有该字符串对象，则放入失败,返回字符串里有的该对象

无论放入是否成功，都会返回串池中的字符串对象。
注意：此时如果调用intern方法成功，堆内存与串池中的字符串对象是同一个对象；如果失败，则不是同一个对象

JDK1.6
调用字符串对象的intern方法，会将该字符串对象尝试放入到串池中

如果串池中没有该字符串对象，会将该字符串对象复制一份，再放入到串池中，返回的是复制的对象
如果有该字符串对象，则放入失败，返回串池原有的该字符串的对象

注意：此时无论调用intern方法成功与否，串池中的字符串对象和堆内存中的字符串对象都不是同一个对象


字符串常量池和运行时常量池有什么关系？早期设计时，字符串常量池是属于运行时常量池的一部分，他们存储的位置也是一致的。后续做出了调整，将字符串常量池和运行时常量池做了拆分。

静态变量存储在哪里呢？
JDK6及之前的版本中，静态变量是存放在方法区中的，也就是永久代。
JDK7及之后的版本中，静态变量是存放在堆中的Class对象中，脱离了永久代。具体源码可参考虚拟机源码：BytecodeInterpreter针对putstatic指令的处理。


直接内存直接内存指的就是Direct Memory，常见于Nio操作，区别于io，在读写操作时有着更高的效率。直接内存并不在《Java虚拟机规范》中存在，所以并不属于Java运行时的内存区域。
特点：
常见于 NIO 操作时，用于数据缓冲区
分配回收成本较高，但读写性能高
不受 JVM 内存回收管理




学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 3 - Java 类加载机制</title>
    <url>/2025/05/23/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%203%20-%20Java%20%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[Java 类加载机制类的生命周期类从被加载到虚拟机内存中开始到卸载出内存为止，它的整个生命周期可以简单概括为 7 个阶段：加载、验证、准备、解析、初始化、使用和卸载。其中，验证、准备和解析这三个阶段可以统称为链接。

加载（Loading）
类加载器根据类的全限定名通过不同的渠道以二进制流的方式获取字节码信息，程序员可以使用Java代码拓展的不同的渠道。

从本地磁盘上获取文件
运行时通过动态代理生成，比如Spring框架
Applet技术通过网络获取字节码文件


类加载器在加载完类之后，Java虚拟机会将字节码中的信息保存到方法区中，方法区中生成一个InstanceKlass对象，保存类的所有信息，里边还包含实现特定功能比如多态的信息。
 

Java虚拟机同时会在堆上生成与方法区中数据类似的java.lang.Class对象，作用是在Java代码中去获取类的信息以及存储静态字段的数据（JDK8及之后）。
 


链接（Linking）链接阶段将加载的类准备好以供JVM使用，分为以下三个子阶段：
验证（Verification）此阶段会对字节码进行校验，确保其符合 Java 虚拟机规范，不会危害虚拟机的安全。验证过程包括：

文件格式验证：检查类文件的魔数（是否以0xCAFEBABE开头）、版本等基本结构。
元数据验证：检查类的内部结构，如字段、方法的描述符。
字节码验证：通过数据流和控制流分析，确定程序语义是合法的、符合逻辑的。
符号引用验证: 确保解析动作能正确执行。

准备（Preparation）准备阶段主要为类的静态变量分配内存，并设置其初始值（默认值）。注意一下几点：

static 变量分配空间和赋值是两个步骤，分配空间在准备阶段完成，赋值在初始化阶段完成。
这里所设置的初始值通常情况下是数据类型默认的零值(如0、0L、null、false等)。
如果 static 变量是 ﬁnal 的基本类型，以及字符串常量，那么编译阶段值就确定了，赋值在准备阶段完成
如果 static 变量是 ﬁnal 的，但属于引用类型，那么赋值也会在初始化阶段完成

解析（Resolution）解析阶段是虚拟机将常量池内的符号引用替换为直接引用的过程。
初始化(Initialization)初始化阶段是类加载过程的最后一步，主要任务是执行类构造器()方法，该方法由编译器自动生成，用于初始化类的静态变量和执行静态块。初始化阶段包括：

执行静态变量的初始化赋值。
执行静态代码块。

类的初始化的懒惰的

以下情况会初始化

main 方法所在的类，总会被首先初始化
首次访问这个类的静态变量或静态方法时
子类初始化，如果父类还没初始化，会引发
子类访问父类的静态变量，只会触发父类的初始化
反射(如Class.forName)
创建类的实例，也就是new的方式


以下情况不会初始化

访问类的 static ﬁnal 静态常量（基本类型和字符串）
类对象.class 不会触发初始化
创建该类对象的数组
类加载器的.loadClass方法
Class.forNamed的参数2为false时




对上述准则的验证（注释下逐个验证）

public class Load2 &#123;    public static void main(String[] args) &#123;        // 不能初始化，final在准备阶段就已经赋值了        System.out.println(E.a);        // 不能初始化，final在准备阶段就已经赋值了        System.out.println(E.b);        // 会导致 E 类初始化，因为 Integer 是包装类        System.out.println(E.c);    &#125;&#125;class E &#123;    public static final int a = 10;    public static final String b = &quot;hello&quot;;    public static final Integer c = 20;    static &#123;        System.out.println(&quot;E cinit&quot;);    &#125;&#125;

public class Load3 &#123;    static &#123;        //在main类前面的静态代码块会优先初始化        System.out.println(&quot;main init&quot;);    &#125;    public static void main(String[] args) throws ClassNotFoundException &#123;        // 1. 静态常量（基本类型和字符串）不会触发初始化        System.out.println(B.b);        // 2. 类对象.class 不会触发初始化        System.out.println(B.class);        // 3. 创建该类的数组不会触发初始化        System.out.println(new B[0]);        // 4. 不会初始化类 B，但会加载 B、A        ClassLoader cl = Thread.currentThread().getContextClassLoader();        cl.loadClass(&quot;cn.itcast.jvm.t3.B&quot;);        // 5. 不会初始化类 B，但会加载 B、A        ClassLoader c2 = Thread.currentThread().getContextClassLoader();        Class.forName(&quot;cn.itcast.jvm.t3.B&quot;, false, c2);        // 1. 首次访问这个类的静态变量或静态方法时        System.out.println(A.a);        // 2. 子类初始化，如果父类还没初始化，会引发父类的初始化        System.out.println(B.c);        // 3. 子类访问父类静态变量，只触发父类初始化        System.out.println(B.a);        // 4. 会初始化类 B，并先初始化类 A        Class.forName(&quot;cn.itcast.jvm.t3.B&quot;);    &#125;&#125;class A &#123;    static int a = 0;    static &#123;        System.out.println(&quot;a init&quot;);    &#125;&#125;class B extends A &#123;    final static double b = 5.0;    static boolean c = false;    static &#123;        System.out.println(&quot;b init&quot;);    &#125;&#125;

使用类访问方法区内的数据结构的接口， 对象是Heap区的数据。
卸载Java虚拟机将结束生命周期的几种情况：

执行了System.exit()方法
程序正常执行结束
程序在执行过程中遇到了异常或错误而异常终止
由于操作系统出现错误而导致Java虚拟机进程终止

类加载器类加载器从 JDK 1.0 就出现了，最初只是为了满足 Java Applet（已经被淘汰） 的需要。后来，慢慢成为 Java 程序中的一个重要组成部分，赋予了 Java 类可以被动态加载到 JVM 中并执行的能力。
根据官方 API 文档的介绍:

类加载器是一个负责加载类的对象，用于实现类加载过程中的加载这一步。
每个 Java 类都有一个引用指向加载它的 ClassLoader。
数组类不是通过 ClassLoader 创建的（数组类没有对应的二进制字节流），是由 JVM 直接生成的。

简单来说，类加载器的主要作用就是动态加载 Java 类的字节码（ .class 文件）到 JVM 中（在内存中生成一个代表该类的 Class 对象）。
加载规则

动态加载机制
按需加载：Java 类在首次使用时才会被加载（如通过new实例化、调用静态方法 &#x2F; 字段等）。
运行时加载：类加载过程在程序运行期间完成，而非编译时。


类的唯一性
类的唯一性由 类加载器 + 类的全限定名（如java.lang.String） 共同确定。不同类加载器加载的同名类被视为不同的类。



类加载器类型


名称
加载的类
说明



Bootstrap ClassLoader（启动类加载器）
%JAVA_HOME%&#x2F;lib目录下的 rt.jar、resources.jar、charsets.jar等 jar 包和类
由 JVM 底层（C++）实现，Java 代码中无法直接引用。


Extension ClassLoader(拓展类加载器)
JAVA_HOME&#x2F;jre&#x2F;lib&#x2F;ext
由sun.misc.Launcher$ExtClassLoader实现。


Application ClassLoader(应用程序类加载器)
当前应用 classpath 下的所有 jar 包和类
由sun.misc.Launcher$AppClassLoader实现，是ClassLoader类的默认加载器。


自定义类加载器
自定义
继承java.lang.ClassLoader并重写关键方法（如findClass()）。


寻找类加载器每个 ClassLoader 可以通过getParent()获取其父 ClassLoader，如果获取到 ClassLoader 为null的话，那么该类是通过 BootstrapClassLoader 加载的。
寻找类加载器例子如下:
 public class ClassLoaderTest &#123;    public static void main(String[] args) &#123;        ClassLoader loader = Thread.currentThread().getContextClassLoader();        System.out.println(loader);        System.out.println(loader.getParent());        System.out.println(loader.getParent().getParent());    &#125;&#125;   

结果如下:
sun.misc.Launcher$AppClassLoader@18b4aac2sun.misc.Launcher$ExtClassLoader@1b6d3586null

从上面的结果可以看出，并没有获取到ExtClassLoader的父Loader，原因是BootstrapLoader(引导类加载器)是由 C++ 实现，由于这个 C++ 实现的类加载器在 Java 中是没有与之对应的类的，所以拿到的结果是 null。
双亲委派模型Java采用了双亲委派模型来组织类加载器的层次结构。具体来说，当一个类加载器接收到类加载请求时，它会首先将请求委派给父类加载器处理，只有在父类加载器无法完成加载时，子类加载器才会尝试自己加载。这种机制确保了Java核心类库的安全性和一致性，避免了类的重复加载和命名冲突。
双亲委派机制过程

当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 
当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。
如果BootStrapClassLoader加载失败(例如在$JAVA_HOME&#x2F;jre&#x2F;lib里未查找到该class)，会使用ExtClassLoader来尝试加载。
若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。


loadClass源码解析：protected Class&lt;?&gt; loadClass(String name, boolean resolve)        throws ClassNotFoundException    &#123;        synchronized (getClassLoadingLock(name)) &#123;            // First, check if the class has already been loaded            //首先，检查类是否已经加载            Class&lt;?&gt; c = findLoadedClass(name);            if (c == null) &#123;                //说明该类没有被加载过                long t0 = System.nanoTime();                try &#123;                    //判断父类是否为空                    if (parent != null) &#123;                        //当父类的加载器不为空，则通过父类的loadClass来加载该类                        c = parent.loadClass(name, false);                    &#125; else &#123;                        //当父类的加载器为空，则调用启动类加载器来加载该类                        c = findBootstrapClassOrNull(name);                    &#125;                &#125; catch (ClassNotFoundException e) &#123;                    // ClassNotFoundException thrown if class not found                    // from the non-null parent class loader                    // 捕获异常但不处理，表示父类加载失败                &#125;                if (c == null) &#123;                    long t1 = System.nanoTime();                    //如果仍未找到，则调用 findClass 以查找该类。                     //用户可通过覆写该方法，来自定义类加载器                    c = findClass(name);                    // this is the defining class loader; record the stats                    sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0);                    sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);                    sun.misc.PerfCounter.getFindClasses().increment();                &#125;            &#125;            if (resolve) &#123;                resolveClass(c);            &#125;            return c;        &#125;    &#125;

自定义类加载器使用场景
想加载非 classpath 随意路径中的类文件
通过接口来使用实现，希望解耦时，常用在框架设计
这些类希望予以隔离，不同应用的同名类都可以加载，不冲突，常见于 tomcat 容器

步骤
继承ClassLoader父类
要遵从双亲委派机制，重写 ﬁndClass 方法
不是重写loadClass方法，否则不会走双亲委派机制
读取类文件的字节码
调用父类的 deﬁneClass 方法来加载类
使用者调用该类加载器的 loadClass 方法


ClassLoader 类有两个关键的方法：

protected Class loadClass(String name, boolean resolve)：加载指定二进制名称的类，实现了双亲委派机制 。name 为类的二进制名称，resolve 如果为 true，在加载时调用 resolveClass(Class&lt;?&gt; c) 方法解析该类。
protected Class findClass(String name)：根据类的二进制名称来查找类，默认实现是空方法。


学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 2 - Java 类字节码</title>
    <url>/2025/05/22/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%202%20-%20Java%20%E7%B1%BB%E5%AD%97%E8%8A%82%E7%A0%81/</url>
    <content><![CDATA[Java虚拟机的组成Java虚拟机主要分为以下几个组成部分：


ClassLoader：类加载子系统，核心组件类加载器，负责将字节码文件中的内容加载到内存中。
JVM内存结构：运行时数据区，JVM管理的内存，创建出来的对象、类的信息等等内容都会放在这块区域中。
执行引擎：包含了即时编译器、解释器、垃圾回收器，执行引擎使用解释器将字节码指令解释成机器码，使用即时编译器优化性能，使用垃圾回收器回收不再使用的对象。
本地接口：调用本地使用C&#x2F;C++编译好的方法，本地方法在Java中声明时，都会带上native关键字，如下图所示。

字节码文件的组成
字节码文件比较难读，更加详细的请去官网https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-6.html#jvms-6.5阅读。

字节码文件总共可以分为以下几个部分：

基础信息：魔数、字节码文件对应的Java版本号、访问标识(public final等等)、父类和接口信息
常量池：保存了字符串常量、类或接口名、字段名，主要在字节码指令中使用
字段： 当前类或接口声明的字段信息
方法： 当前类或接口声明的方法信息，核心内容为方法的字节码指令
属性： 类的属性，比如源码的文件名、内部类的列表等

通过 javac 类名.java 编译 java 文件后，会生成一个 .class 字节码文件！
以下是字节码文件：
0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09 0000020 00 16 00 17 08 00 18 0a 00 19 00 1a 07 00 1b 07 0000040 00 1c 01 00 06 3c 69 6e 69 74 3e 01 00 03 28 29 0000060 56 01 00 04 43 6f 64 65 01 00 0f 4c 69 6e 65 4e 0000100 75 6d 62 65 72 54 61 62 6c 65 01 00 12 4c 6f 63 0000120 61 6c 56 61 72 69 61 62 6c 65 54 61 62 6c 65 01 0000140 00 04 74 68 69 73 01 00 1d 4c 63 6e 2f 69 74 63 0000160 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c 6f 0000200 57 6f 72 6c 64 3b 01 00 04 6d 61 69 6e 01 00 16 0000220 28 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 72 0000240 69 6e 67 3b 29 56 01 00 04 61 72 67 73 01 00 13 0000260 5b 4c 6a 61 76 61 2f 6c 61 6e 67 2f 53 74 72 69 0000300 6e 67 3b 01 00 10 4d 65 74 68 6f 64 50 61 72 61 0000320 6d 65 74 65 72 73 01 00 0a 53 6f 75 72 63 65 46 0000340 69 6c 65 01 00 0f 48 65 6c 6c 6f 57 6f 72 6c 640000360 2e 6a 61 76 61 0c 00 07 00 08 07 00 1d 0c 00 1e 0000400 00 1f 01 00 0b 68 65 6c 6c 6f 20 77 6f 72 6c 64 0000420 07 00 20 0c 00 21 00 22 01 00 1b 63 6e 2f 69 74 0000440 63 61 73 74 2f 6a 76 6d 2f 74 35 2f 48 65 6c 6c 0000460 6f 57 6f 72 6c 64 01 00 10 6a 61 76 61 2f 6c 61 0000500 6e 67 2f 4f 62 6a 65 63 74 01 00 10 6a 61 76 61 0000520 2f 6c 61 6e 67 2f 53 79 73 74 65 6d 01 00 03 6f 0000540 75 74 01 00 15 4c 6a 61 76 61 2f 69 6f 2f 50 72 0000560 69 6e 74 53 74 72 65 61 6d 3b 01 00 13 6a 61 76 0000600 61 2f 69 6f 2f 50 72 69 6e 74 53 74 72 65 61 6d 0000620 01 00 07 70 72 69 6e 74 6c 6e 01 00 15 28 4c 6a 0000640 61 76 61 2f 6c 61 6e 67 2f 53 74 72 69 6e 67 3b 0000660 29 56 00 21 00 05 00 06 00 00 00 00 00 02 00 01 0000700 00 07 00 08 00 01 00 09 00 00 00 2f 00 01 00 01 0000720 00 00 00 05 2a b7 00 01 b1 00 00 00 02 00 0a 00 0000740 00 00 06 00 01 00 00 00 04 00 0b 00 00 00 0c 00 0000760 01 00 00 00 05 00 0c 00 0d 00 00 00 09 00 0e 00 0001000 0f 00 02 00 09 00 00 00 37 00 02 00 01 00 00 00 0001020 09 b2 00 02 12 03 b6 00 04 b1 00 00 00 02 00 0a 0001040 00 00 00 0a 00 02 00 00 00 06 00 08 00 07 00 0b 0001060 00 00 00 0c 00 01 00 00 00 09 00 10 00 11 00 00 0001100 00 12 00 00 00 05 01 00 10 00 00 00 01 00 13 00 0001120 00 00 02 00 14

根据 JVM 规范，类文件结构如下：

魔数第一行中有一串特殊的字符 cafebabe，它就是一个魔数，是 JVM 识别 class 文件的标志，JVM 会在验证阶段检查 class 文件是否以该魔数开头，如果不是则会抛出 ClassFormatError。
上面截图中
u4 magic对应字节码文件的 0~3 个字节0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 09ca fe ba be ：意思是 .class 文件，不同的东西有不同的魔数，比如 jpg、png 图片等！
版本紧跟着魔数后面的四个字节 00 00 00 34 分别表示副版本号和主版本号。
u2 minor_version;u2 major_version;0000000 ca fe ba be 00 00 00 34 00 23 0a 00 06 00 15 0900 00 00 34：34H（16进制） &#x3D; 52（10进制），代表JDK8对应的版本号，副版本号为 0。
常量池参考地址：· The Java® Virtual Machine Specification (oracle.com) ·
紧跟在版本号之后的是常量池，它包含了类、接口、字段和方法的符号引用，以及字符串字面量和数值常量。这些信息在编译时被创建，并在运行时被Java虚拟机（JVM）使用。

学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>JVM 基础 5 - GC 垃圾回收</title>
    <url>/2025/05/25/Java/JVM/JVM%20%E5%9F%BA%E7%A1%80%205%20-%20%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6/</url>
    <content><![CDATA[垃圾回收JVM 垃圾回收 (Garbage Collection, GC) 是 Java 虚拟机自动管理堆内存的核心机制。它负责识别并回收程序中不再使用的对象所占用的内存，防止内存泄漏，极大地简化了开发人员的内存管理工作。  
垃圾回收器如果发现某个对象不再使用，就可以回收该对象。
.ljqxxbltnoqo{zoom: 67%;}

.kkdqnpgvgwiz{zoom:67%;}


自动垃圾回收，自动根据对象是否使用由虚拟机来回收对象

优点：降低程序员实现难度、降低对象回收bug的可能性
缺点：程序员无法控制内存回收的及时性


手动垃圾回收，由程序员编程实现对象的删除

优点：回收及时性高，由程序员把控回收的时机
缺点：编写不当容易出现悬空指针、重复释放、内存泄漏等问题




如果需要手动触发垃圾回收，可以调用System.gc()方法。语法： System.gc()注意事项：   调用System.gc()方法并不一定会立即回收垃圾，仅仅是向Java虚拟机发送一个垃圾回收的请求，具体是否需要执行垃圾回收Java虚拟机会自行判断。

如何判断对象可以回收引用计数法引用计数法会为每个对象维护一个引用计数器，当对象被引用时加1，取消引用时减1。当值为 0 时，就表示该对象不被引用，可以被垃圾收集器回收。
缺点：  

每次引用和取消引用都需要维护计数器，对系统性能会有一定的影响
存在循环引用问题，所谓循环引用就是当A引用B，B同时引用A时会出现对象无法回收的问题。如下图：

.btnqqfnwjgqd{zoom:80%;}

可达性分析法通过 GC Roots 作为起始点进行搜索，能够到达到的对象都是存活的，不可达的对象可被回收。


JVM 中的垃圾回收器通过可达性分析来探索所有存活的对象
扫描堆中的对象，看能否沿着 GC Root 对象为起点的引用链找到该对象，如果找不到，则表示可以回收
Java 中可以作为 GC Root 的对象：
虚拟机栈（栈帧中的本地变量表）中引用的对象。
方法区中类静态属性引用的对象
方法区中常量引用的对象
本地方法栈中 JNI（即一般说的Native方法）引用的对象

引用对象.oiaqftmqjupv{zoom:80%;}

1. 强引用（StrongReference）被强引用关联的对象不会被回收。只有GC Root都不引用该对象时，才会回收强引用对象
2. 软引用（SoftReference）如果一个对象只有软引用引对象时，当程序内存不足时，就会将软引用中的数据进行回收。在JDK 1.2版之后提供了SoftReference类来实现软引用，软引用常用于缓存中。
3. 弱引用（WeakReference）如果一个对象只有弱引用该对象时，在垃圾回收时，无论内存是否充足，就会将弱引用中的数据进行回收。在JDK 1.2版之后提供了WeakReference类来实现弱引用，弱引用主要在ThreadLocal中使用。
4. 虚引用（PhantomReference）（不常见）虚引用也叫幽灵引用&#x2F;幻影引用，不能通过虚引用对象获取到包含的对象。虚引用唯一的用途是当对象被垃圾回收器回收时可以接收到对应的通知。Java中使用PhantomReference实现了虚引用，直接内存中为了及时知道直接内存对象不再使用，从而回收内存，使用了虚引用来实现。
5. 终结器引用（FinalReference）（不常见）终结器引用指的是在对象需要被回收时，终结器引用会关联对象并放置在Finalizer类中的引用队列中，在稍后由一条由FinalizerThread线程从队列中获取对象，然后执行对象的finalize方法，在对象第二次被回收时，该对象才真正的被回收。在这个过程中可以在finalize方法中再将自身对象使用强引用关联上，但是不建议这样做。
垃圾回收算法1. 标记-清除算法
虚拟机执行垃圾回收的过程中，使用可达性分析算法，从GC Root开始通过引用链遍历出所有存活对象。将所有存活的对象进行标记。
然后垃圾收集器根据标识清除没有被标记也就是非存活对象，给堆内存腾出相应的空间


优点：实现简单，只需要在第一阶段给每个对象维护标志位，第二阶段删除对象即可。
缺点：

会产生大量不连续的内存碎片，导致无法给大对象分配内存。由于内存是连续的，所以在对象被删除之后，内存中会出现很多细小的可用内存单元。如果我们需要的是一个比较大的空间，很有可能这些内存单元的大小过小无法进行分配。
分配速度慢。由于内存碎片的存在，需要维护一个空闲链表，极有可能发生每次需要遍历到链表的最后才能获得合适的内存空间。
标记和清除过程效率都不高。

2. 标记-整理算法标记整理算法也叫标记压缩算法，是对标记清理算法中容易产生内存碎片问题的一种解决方案。

标记阶段，将所有存活的对象进行标记。Java中使用可达性分析算法，从GC Root开始通过引用链遍历出所有存活对象。
整理阶段，将存活对象移动到堆的一端。清理掉存活对象的内存空间。


优点：不会产生内存碎片。
缺点：内存变动更频繁，需要整理所有存活对象的引用地址，效率不高。
3. 复制算法将内存划分为大小相等的两块，每次只使用其中一块，当这一块内存用完了就将还存活的对象复制到另一块上面，然后再把使用过的内存空间进行一次清理，最后会把位置互换。

优点：不会产生内存碎片；吞吐量高，复制算法只需要遍历一次存活对象复制到To空间即可，比标记-整理算法少了一次遍历的过程，因而性能较好，但是不如标记-清除算法，因为标记清除算法不需要进行对象的移动
缺点：内存使用效率低，每次只能让一半的内存空间来为创建对象使用。
4. 分代垃圾回收算法现代优秀的垃圾回收算法，会将上述描述的垃圾回收算法组合进行使用，其中应用最广的就是分代垃圾回收算法(Generational GC)。  
分代垃圾回收将整个内存区域划分为年轻代（复制算法）和老年代（标记 - 清除 或者 标记 - 整理 算法）：
.uygwqqchetwc{zoom: 80%;}


分代回收时，创建出来的对象，首先会被放入Eden伊甸园区。

随着对象在Eden区越来越多，如果Eden区满，新创建的对象已经无法放入，就会触发年轻代的GC，称为Minor GC或者Young GC。  
Minor GC会把需要eden中和From需要回收的对象回收，把没有回收的对象放入To区。

接下来，S0会变成To区，S1变成From区。当eden区满时再往里放入对象，依然会发生Minor GC。  
此时会回收eden区和S1(from)中的对象，并把eden和from区中剩余的对象放入S0。注意：每次Minor GC中都会为对象记录他的年龄，初始值为0，每次GC完加1。

如果Minor GC后对象的年龄达到阈值（最大15，默认值和垃圾回收器有关），对象就会被晋升至老年代。

当老年代中空间不足，无法放入新的对象时，先尝试minor gc如果还是不足，就会触发Full GC，Full GC会对整个堆进行垃圾回收。
如果Full GC依然无法回收掉老年代的对象，那么当对象继续放入老年代时，就会抛出Out Of Memory异常。

特殊情况：当遇到一个较大的对象时，就算新生代的伊甸园为空，也无法容纳该对象时，会将该对象直接晋升为老年代。


相关 JVM 参数


含义
参数



堆初始大小必须是1024倍数且大于1MB
-Xms


堆最大大小必须是1024倍数且大于1MB
-Xmx 或 -XX:MaxHeapSize&#x3D;size


新生代大小
-Xmn 或 (-XX:NewSize&#x3D;size + -XX:MaxNewSize&#x3D;size )


幸存区比例（动态）
-XX:InitialSurvivorRatio&#x3D;ratio 和 -XX:+UseAdaptiveSizePolicy


伊甸园区和幸存区的比例，默认8，新生代1G，伊甸园区800MB,S0和S1各100MB
-XX:SurvivorRatio&#x3D;ratio


晋升阈值
-XX:MaxTenuringThreshold&#x3D;threshold


晋升详情
-XX:+PrintTenuringDistribution


打印GC日志
-XX:+PrintGCDetails -verbose:gc


FullGC 前 MinorGC
-XX:+ScavengeBeforeFullGC


垃圾回收器为什么分代GC算法要把堆分成年轻代和老年代？首先我们要知道堆内存中对象的特性：

系统中的大部分对象，都是创建出来之后很快就不再使用可以被回收，比如用户获取订单数据，订单数据返回给用户之后就可以释放了。
老年代中会存放长期存活的对象，比如Spring的大部分bean对象，在程序启动之后就不会被回收了。
在虚拟机的默认设置中，新生代大小要远小于老年代的大小。

分代GC算法将堆分成年轻代和老年代主要原因有：

可以通过调整年轻代和老年代的比例来适应不同类型的应用程序，提高内存的利用率和性能。

新生代和老年代使用不同的垃圾回收算法，新生代一般选择复制算法，老年代可以选择标记-清除和标记-整理算法，由程序员来选择灵活度较高。

分代的设计中允许只回收新生代（minor gc），如果能满足对象分配的要求就不需要对整个堆进行回收(full gc),STW时间就会减少。


垃圾回收器是垃圾回收算法的具体实现。
由于垃圾回收器分为年轻代和老年代，除了G1之外其他垃圾回收器必须成对组合进行使用。
具体的关系图如下：


Serial 收集器Serial 收集器是最基本的、发展历史最悠久的收集器。是一种单线程串行回收年轻代的垃圾回收器，只会使用一个线程进行垃圾收集工作，使用标记-复制算法。  
.girjaugtmgqk{zoom:80%;}

优点：

单线程、简单高效（与其他收集器的单线程相比）。对于限定单个CPU的环境来说，Serial收集器由于没有线程交互的开销，专心做垃圾收集自然可以获得最高的单线程手机效率。收集器进行垃圾回收时，必须暂停其他所有的工作线程（ “Stop The World” ），直到它结束。

 缺点：

多CPU下吞吐量不如其他垃圾回收器，堆如果偏大会让用户线程处于长时间的等待。

适用场景： 

Java编写的客户端程序或者硬件配置有限的场景。


-XX:+UseSerialGC&#x3D;serial + serialOld

SerialOld垃圾回收器SerialOld是Serial垃圾回收器的老年代版本，采用单线程串行回收。使用标记-整理算法。
.stmkbrrkjbrt{zoom:80%;}

ParNew 收集器ParNew 收集器其实就是 Serial 收集器在多CPU下的优化，使用多线程进行垃圾回收。新生代采用标记-复制算法，老年代采用标记-整理算法。
-XX:+UseParNewGC 新生代使用ParNew回收器， 老年代使用串行回收器

优点：

多线程、ParNew 收集器默认开启的收集线程数与CPU的数量相同，在 CPU 非常多的环境中，可以使用 -XX:ParallelGCThreads 参数来限制垃圾收集的线程数。和 Serial 收集器一样存在 Stop The World 问题。

缺点：

吞吐量和停顿时间不如G1，所以在JDK9之后不建议使用。

适用场景：

JDK8及之前的版本中，与CMS老年代垃圾回收器搭配使用

CMS 收集器CMS(Concurrent Mark Sweep)，从名字中的Mark Sweep这两个词可以看出，CMS 收集器是一种 标记-清除算法实现的。 老年代收集器。参数：XX:+UseConcMarkSweepGC。
CMS垃圾回收器关注的是系统的暂停时间，允许用户线程和垃圾回收线程在某些步骤中同时执行，减少了用户线程的等待时间。

CMS执行步骤：
1.初始标记，用极短的时间标记出GC Roots能直接关联到的对象。速度很快但是仍存在Stop The World问题。
2.并发标记,   标记所有的对象，用户线程不需要暂停。
3.重新标记，由于并发标记阶段有些对象会发生了变化，存在错标、漏标等情况，需要重新标记。存在Stop The World问题。
4.并发清理，清理死亡的对象，用户线程不需要暂停。但是清除的过程中，可能任然会有新的垃圾产生，这些垃圾就叫浮动垃圾，如果当用户需要存入一个很大的对象时，新生代放不下去，老年代由于浮动垃圾过多，就会退化为 serial Old 收集器，将老年代垃圾进行标记-整理，当然这也是很耗费时间的！

在整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，不需要进行停顿。
CMS 垃圾回收器在 Java 9 中已经被标记为过时(deprecated)，并在 Java 14 中被移除。

优点：

系统由于垃圾回收出现的停顿时间较短，用户体验好。

缺点：

吞吐量低: 低停顿时间是以牺牲吞吐量为代价的，导致 CPU 利用率不够高。

无法处理在并发清理过程中产生的“浮动垃圾”，不能做到完全的垃圾回收。如果预留的内存不够存放浮动垃圾，就会出现 Concurrent Mode Failure，这时虚拟机将临时启用 Serial Old 来替代 CMS。

标记 - 清除算法导致的空间碎片，往往出现老年代空间剩余，但无法找到足够大连续空间来分配当前对象，不得不提前触发一次 Full GC。


适用场景:

大型的互联网系统中用户请求数据量大、频率高的场景，比如订单接口、商品接口等

Parallel Scavenge垃圾回收器Parallel Scavenge是JDK8默认的年轻代垃圾回收器，多线程并行回收，关注的是系统的吞吐量（指 CPU 用于运行用户代码的时间占总时间的比值）。具备自动调整堆内存大小的特点。使用 标记-复制算法。
优点：

吞吐量高，可以通过一个开关参数打开 GC 自适应的调节策略(GC Ergonomics)。为了提高吞吐量，虚拟机会动态调整堆的参数。

GC自适应调节策略：Parallel Scavenge收集器可设置-XX:+UseAdptiveSizePolicy参数。当开关打开时不需要手动指定新生代的大小（-Xmn）、Eden与Survivor区的比例（-XX:SurvivorRation）、晋升老年代的对象年龄（-XX:PretenureSizeThreshold）等，虚拟机会根据系统的运行状况收集性能监控信息，动态设置这些参数以提供最优的停顿时间和最高的吞吐量，这种调节方式称为GC的自适应调节策略。



缺点：

不能保证单次的停顿时间。

适用场景：

后台任务，不需要与用户交互，并且容易产生大量的对象。比如：大数据的处理，大文件导出。

Parallel Old垃圾回收器Parallel Scavenge 收集器的老年代版本。使用多线程和标记-整理算法。在注重吞吐量以及 CPU 资源的场合，都可以优先考虑 Parallel Scavenge 收集器和 Parallel Old 收集器。
.rtsizlfpuslz{zoom:80%;}

优点：

并发收集，在多核CPU下效率较高

缺点：

暂停时间会比较长

适用场景：

与Parallel Scavenge配套使用

G1垃圾回收器JDK9之后默认的垃圾回收器是G1（Garbage First）垃圾回收器。Parallel Scavenge关注吞吐量，允许用户设置最大暂停时间 ，但是会减少年轻代可用空间的大小。CMS关注暂停时间，但是吞吐量方面会下降。
而G1设计目标就是将上述两种垃圾回收器的优点融合：
1.支持巨大的堆空间回收，并有较高的吞吐量。
2.支持多CPU并行垃圾回收。
3.允许用户设置最大暂停时间。
G1出现之前的垃圾回收器，年轻代和老年代一般是连续的，如下图：
.hkcxaikufime{zoom:80%;}

G1的整个堆会被划分成多个大小相等的区域，称之为区Region，区域不要求是连续的。每个 Region 逻辑上可属于 Eden、Survivor、Old或 Humongous（存储大于 Region 一半大小的对象）。Region的大小通过堆空间大小&#x2F;2048计算得到，也可以通过参数-XX:G1HeapRegionSize&#x3D;32m指定(其中32m指定region大小为32M)，Region size必须是2的指数幂，取值范围从1M到32M。
.xuoiyufdtkkx{zoom:80%;}

G1 执行流程1. Young GC（新生代回收）年轻代回收（Young GC），回收Eden区和Survivor区中不用的对象。会导致STW，G1中可以通过参数 -XX:MaxGCPauseMillis=n（默认200）设置每次垃圾回收时的最大暂停时间毫秒数，G1垃圾回收器会尽可能地保证暂停时间。

触发条件：
Eden 区占满，或 G1 预测回收时间接近目标停顿时间。

步骤：

新创建的对象会存放在Eden区。当G1判断年轻代区不足（max默认60%），无法分配对象时需要回收时会执行Young GC。

标记出Eden和Survivor区域中的存活对象。

根据配置的最大暂停时间选择某些区域将存活对象复制到一个新的Survivor区中（年龄+1），清空这些区域。

G1在进行Young GC的过程中会去记录每次垃圾回收时每个Eden区和Survivor区的平均耗时，以作为下次回收时的参考依据。这样就可以根据配置的最大暂停时间计算出本次回收时最多能回收多少个Region区域了。比如 -XX:MaxGCPauseMillis&#x3D;n（默认200），每个Region回收耗时40ms，那么这次回收最多只能回收4个Region。


后续Young GC时与之前相同，只不过Survivor区中存活对象会被搬运到另一个Survivor区。

当某个在Survivor区存活对象的年龄到达阈值（默认15），将被放入老年代。

部分对象如果大小超过Region的一半，会直接放入老年代，这类老年代被称为Humongous区。比如堆内存是4G，每个Region是2M，只要一个大对象超过了1M就被放入Humongous区，如果对象过大会横跨多个Region。

多次回收之后，会出现很多Old老年代区，此时总堆占有率达到阈值时（-XX:InitiatingHeapOccupancyPercent默认45%）会触发混合回收MixedGC。回收所有年轻代和部分老年代的对象以及大对象区。采用复制算法来完成。




2. Mixed GC（混合回收，核心流程）
触发条件：
老年代占用达 45%（默认）或手动触发。G1对老年代的清理会选择存活度最低的区域来进行回收，这样可以保证回收效率最高，这也是G1（Garbage first）名称的由来。最后清理阶段使用复制算法，不会产生内存碎片。

步骤：

初始标记（STW）：采用三色标记法标记从GC Root可直达的对象。 STW时间极短。
并发标记（并行）：递归标记所有存活对象，使用 SATB（快照）记录引用变化，避免漏标。
最终标记（STW）：处理并发标记期间的引用变更，修复漏标。
筛选回收（STW）：
按 “回收收益” 排序 Region，选择回收集合（CSet）。
复制存活对象到新 Region，清空原 Region。






注意：如果清理过程中发现没有足够的空Region存放转移的对象，会出现Full GC。单线程执行标记-整理算法，此时会导致用户线程的暂停。所以尽量保证应该用的堆内存有一定多余的空间。
3. Full GC
触发条件：

G1 在老年代内存不足时（老年代所占内存超过阈值）。
如果垃圾产生速度慢于垃圾回收速度，不会触发 Full GC，还是并发地进行清理
如果垃圾产生速度快于垃圾回收速度，便会触发 Full GC，然后退化成 serial Old 收集器串行的收集，就会导致停顿的时候长。


特点：


单线程全堆扫描，停顿时间极长，需通过调优避免
学习文献

https://blog.csdn.net/weixin_50280576/article/details/113775575
https://lisxpq12rl7.feishu.cn/wiki/F2AFw0doOiW89Fkr8kGcCTyVnLh
https://pdai.tech/md/java/jvm/java-jvm-x-overview.html
https://javaguide.cn/java/jvm/jvm-garbage-collection.html
https://javabetter.cn/jvm/jit.html

]]></content>
      <categories>
        <category>JAVA</category>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>Java进阶 学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title>MySql进阶</title>
    <url>/2025/06/10/MySQL/MySql%E8%BF%9B%E9%98%B6/</url>
    <content><![CDATA[MySql进阶
此笔记由本人学习 B 站黑马程序员 MySQL 数据库视频进阶篇内容后，总结提取摘要制成。视频地址：黑马程序员 MySQL数据库入门到精通，从mysql安装到mysql高级、mysql优化全囊括

MySQL体系结构MySQL体系结构：连接层，服务层，引擎层，存储层。


连接层：处理客户端连接、认证和线程管理。
连接器（Connector）：
处理客户端连接请求，支持 TCP&#x2F;IP、Unix Socket、命名管道等连接方式。
验证用户身份（用户名、密码、主机权限）。
为每个连接分配线程（或从线程池获取）。


线程池（Thread Pool）：
管理数据库连接线程，减少频繁创建 &#x2F; 销毁线程的开销。
适用于高并发场景（如 MySQL Enterprise Edition）。




服务层：包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。
SQL 接口（SQL Interface）：
接收 SQL 请求（SELECT、INSERT 等），返回查询结果。


查询解析器（Parser）：
对 SQL 语句进行词法和语法分析，生成解析树（Parse Tree）。
验证语句语法正确性（如关键字拼写、表名 &#x2F; 列名是否存在）。


预处理器（Preprocessor）：
进一步检查解析树的合法性（如权限检查、外键约束验证）。
替换别名、展开视图等操作。


查询优化器（Optimizer）：
生成最优执行计划（如选择索引、表连接顺序）。
支持成本优化（Cost-Based Optimization, CBO）和规则优化（Rule-Based Optimization, RBO）。


查询执行引擎（Execution Engine）：
根据执行计划调用存储引擎 API 执行查询。


缓存（Query Cache）：
缓存 SQL 语句及其结果（5.7 版本后逐渐弃用，8.0 版本移除）。
当数据发生变更时，相关缓存会被自动清除。




引擎层：负责数据的存储和检索。架构模式是插件式，服务器通过API和存储引擎进行通信。支持 InnoDB、MyISAM、Memory 等多个存储引擎。
插件式架构：支持多种存储引擎，通过统一接口与上层交互。
常见引擎：
InnoDB：默认引擎，支持事务、外键、行级锁。
MyISAM：不支持事务，表级锁，适合读多写少场景。
Memory：数据存储在内存，读写极快，重启丢失数据。
Archive：高度压缩，仅支持 INSERT&#x2F;SELECT，适合历史数据归档。


核心功能：
数据存储与检索（如 B + 树索引、哈希索引）。
事务处理（InnoDB）。
锁机制（行锁、表锁）。




存储层：MYSQL的物理存储部分，负责将数据(如: redolog、undolog、数据、索引、二进制日志、错误日志、查询 日志、慢查询日志等)存储在磁盘上。
数据文件：
.frm：存储表结构定义。
.ibd：InnoDB 独立表空间文件（存储数据和索引）。
.MYD&#x2F;.MYI：MyISAM 数据文件和索引文件。


日志文件：
二进制日志（Binlog）：记录数据变更，用于主从复制和恢复。
重做日志（Redo Log）：确保事务持久性，崩溃恢复。
回滚日志（Undo Log）：支持事务回滚和 MVCC。
错误日志（Error Log）：记录启动、运行时错误信息。
慢查询日志（Slow Query Log）：记录执行时间超过阈值的 SQL。


配置文件：
my.cnf&#x2F;my.ini：存储 MySQL 配置参数（如内存分配、字符集）。





存储引擎他是mysql数据库的核心，我们也需要在合适的场景选择合适的存储引擎。存储引擎是存储数据、建立索引、更新&#x2F;查询数据等技术的实现方式 。存储引擎是基于表的，而不是 基于库的，所以存储引擎也可被称为表类型。可以在创建表的时指定选择的存储引擎，没有指定将自动选择默认的存储引擎。

建表时指定存储引擎

CREATE TABLE 表名(字段1 字段1类型 [ COMMENT 字段1注释 ] ,......字段n 字段n类型 [COMMENT 字段n注释 ]) ENGINE = INNODB [ COMMENT 表注释 ] ;


查询当前数据库支持的存储引擎

show engines;

MySQL 支持多种存储引擎，每种引擎都有其独特的特性和适用场景。以下是常见存储引擎的对比及选择建议。
InnoDB介绍InnoDB是一种兼顾高可靠性和高性能的通用存储引擎，在 MySQL 5.5 之后，InnoDB是默认的 MySQL 存储引擎。
特点
DML操作遵循ACID模型，支持事务；
行级锁，提高并发访问性能；
支持外键FOREIGN KEY约束，保证数据的完整性和正确性；

文件结构
xxx.ibd：xxx代表的是表名，innoDB引擎的每张表都会对应这样一个表空间文件，存储该表的表结构（frm-早期的 、sdi-新版的）、数据和索引。

参数：innodb_file_per_table


  show variables like &#x27;innodb_file_per_table&#x27;


  如果该参数开启，代表对于InnoDB引擎的表，每一张表都对应一个ibd文件。ibd文件中不仅存放表结构、数据还会存放该表对应的索引信息。 而该文件是基于二进制存储的，不能直接基于记事本打开，我们可以使用mysql提供的一个指令 ibd2sdi ，通过该指令就可以从ibd文件中提取sdi信息，而sdi数据字典信息中就包含该表的表结构。
逻辑存储结构

表空间 : InnoDB存储引擎逻辑结构的最高层，ibd文件其实就是表空间文件，在表空间中可以包含多个Segment段。
段 : 表空间是由各个段组成的， 常见的段有数据段、索引段、回滚段等。InnoDB中对于段的管理，都是引擎自身完成，不需要人为对其控制，一个段中包含多个区。
区 : 区是表空间的单元结构，每个区的大小为1M。 默认情况下， InnoDB存储引擎页大小为16K， 即一个区中一共有64个连续的页。
页 : 页是组成区的最小单元，页也是InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区。
行 : InnoDB 存储引擎是面向行的，也就是说数据是按行进行存放的，在每一行中除了定义表时所指定的字段以外，还包含两个隐藏字段(后面会详细介绍)。

适用场景
事务性应用（如电商、金融系统）。
高并发读写场景。
需要外键约束的表。

MyISAM介绍MyISAM是MySQL早期的默认存储引擎。
特点
不支持事务，不支持外键
支持表锁，不支持行锁
优点：更少的存储空间，支持全文索引，适用于读取频率较高、写入频率较低的应用场景

文件结构
xxx.sdi：存储表结构信息

xxx.MYD: 存储数据

xxx.MYI: 存储索引



适用场景
只读或写入少、查询多的场景（如日志表、统计数据）。
不需要事务支持的场景。

Memory介绍Memory引擎的表数据时存储在内存中的，由于受到硬件问题、或断电问题的影响，只能将这些表作为临时表或缓存使用。
特点
数据存储在内存：读写速度极快，但重启后数据丢失。
支持哈希索引：适合快速查找。
表级锁：并发性能有限。

文件结构
xxx.sdi：存储表结构信息
数据， 都在内存中

适用场景
临时表&#x2F;中间结果集： MySQL 内部自动使用。
高速缓存： 存储频繁访问的小型、非关键、可丢失的只读&#x2F;低频写数据（如会话信息、配置）。
需要极低延迟访问的只读查询。

重要警告： 绝对不要用于存储重要或持久化数据。内存有限，大表易导致 OOM。
InnoDB, MyISAM, Memory的区别，使用场景

面试题:InnoDB引擎与MyISAM引擎的区别 ?①. InnoDB引擎, 支持事务, 而MyISAM不支持。②. InnoDB引擎, 支持行锁和表锁, 而MyISAM仅支持表锁, 不支持行锁。③. InnoDB引擎, 支持外键, 而MyISAM是不支持的。

索引介绍索引（index）是帮助MySQL高效获取数据的数据结构(有序)。在数据之外，数据库系统还维护着满足 特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据， 这样就可以在这些数据结构 上实现高级查找算法，这种数据结构就是索引。它类似于书籍的目录，允许数据库快速定位特定数据，避免全表扫描。

特点


优势
劣势



提高数据检索的效率，降低数据库 的IO成本
索引列也是要占用空间的。


通过索引列对数据进行排序，降低 数据排序的成本，降低CPU的消耗。
索引大大提高了查询效率，同时却也降低更新表的速度， 如对表进行INSERT、UPDATE、DELETE时，效率降低。






索引结构概述MySQL的索引是在存储引擎层实现的，不同的存储引擎有不同的索引结构，主要包含以下几种：

上述是MySQL中所支持的所有的索引结构，接下来，我们再来看看不同的存储引擎对于索引结构的支持 情况。


注意： 我们平常所说的索引，如果没有特别指明，都是指B+树结构组织的索引。

二叉树假如说MySQL的索引结构采用二叉树的数据结构，比较理想的结构如下：

如果主键是顺序插入的，则会形成一个单向链表，结构如下：

所以，如果选择二叉树作为索引结构，会存在以下缺点：

顺序插入时，会形成一个链表，查询性能大大降低。
大数据量情况下，层级较深，检索速度慢。

此时大家可能会想到，我们可以选择红黑树，红黑树是一颗自平衡二叉树，那这样即使是顺序插入数 据，最终形成的数据结构也是一颗平衡的二叉树,结构如下:

但是，即使如此，由于红黑树也是一颗二叉树，所以也会存在一个缺点：

解决二叉树的顺序插入后，树不平衡的问题。
大数据量情况下，层级较深，检索速度慢。

B-TreeB-Tree，B树是一种多叉路衡查找树，相对于二叉树，B树每个节点可以有多个分支，即多叉。 以一颗最大度数（max-degree）为5(5阶)的b-tree为例，那这个B树每个节点最多存储4个key，5 个指针：


知识小贴士: 树的度数指的是一个节点的子节点个数。

我们可以通过一个数据结构可视化的网站来简单演示一下。B-Tree Visualization (usfca.edu)

插入一组数据： 100 65 169 368 900 556 780 35 215 1200 234 888 158 90 1000 88 120 268 250 。然后观察一些数据插入过程中，节点的变化情况。

特点：

5阶的B树，每一个节点最多存储4个key，对应5个指针。
一旦节点存储的key数量到达5，就会裂变，中间元素向上分裂。
在B树中，非叶子节点和叶子节点都会存放数据。

B+TreeB+Tree是B-Tree的变种，我们以一颗最大度数（max-degree）为4（4阶）的b+tree为例，来看一 下其结构示意图：

我们可以看到，两部分： 

绿色框框起来的部分，是索引部分，仅仅起到索引数据的作用，不存储数据。 
红色框框起来的部分，是数据存储部分，在其叶子节点中要存储具体的数据。

通过一个数据结构可视化的网站来简单演示一下。[B+ Tree Visualization (usfca.edu)

插入一组数据： 100 65 169 368 900 556 780 35 215 1200 234 888 158 90 1000 88 120 268 250 。然后观察一些数据插入过程中，节点的变化情况。

最终我们看到，B+Tree 与 B-Tree相比，主要有以下三点区别： 

所有的数据都会出现在叶子节点。 
叶子节点形成一个单向链表。
非叶子节点仅仅起到索引数据作用，具体的数据都是在叶子节点存放的。

MySQL优化后的B+ Tree：
上述我们所看到的结构是标准的B+Tree的数据结构，接下来，我们再来看看MySQL中优化之后的 B+Tree。 MySQL索引数据结构对经典的B+Tree进行了优化。在原B+Tree的基础上，增加一个指向相邻叶子节点 的链表指针，就形成了带有顺序指针的B+Tree，提高区间访问的性能，利于排序。

Hash哈希索引就是采用一定的hash算法，将键值换算成新的hash值，映射到对应的槽位上，然后存储在hash表中。

如果两个(或多个)键值，映射到一个相同的槽位上，他们就产生了hash冲突（也称为hash碰撞），可 以通过链表来解决。

特点：

Hash索引只能用于对等比较(&#x3D;，in)，不支持范围查询（between，&gt;，&lt; ，…）。
无法利用索引完成排序操作。
查询效率高，通常(不存在hash冲突的情况)只需要一次检索就可以了，效率通常要高于B+tree索引。

在MySQL中，支持hash索引的是Memory存储引擎。 而InnoDB中具有自适应hash功能，hash索引是 InnoDB存储引擎根据B+Tree索引在指定条件下自动构建的。

为什么 InnoDB 存储引擎选择使用 B+tree 索引结构?

相对于二叉树，层级更少，搜索效率高；
对于B-tree，无论是叶子节点还是非叶子节点，都会保存数据，这样导致一页中存储 的键值减少，指针跟着减少，要同样保存大量数据，只能增加树的高度，导致性能降低；
相对Hash索引，B+tree支持范围匹配及排序操作；


索引分类在MySQL数据库，将索引的具体类型主要分为以下几类：主键索引、唯一索引、常规索引、全文索引。

而在InnoDB存储引擎中，根据索引的存储形式，又可以分为以下两种：

聚集索引选取规则：

如果存在主键，主键索引就是聚集索引。 
如果不存在主键，将使用第一个唯一（UNIQUE）索引作为聚集索引。
如果表没有主键，或没有合适的唯一索引，则InnoDB会自动生成一个rowid作为隐藏的聚集索引。

聚集索引和二级索引的具体结构如下：


聚集索引的叶子节点下挂的是这一行的数据 。
二级索引的叶子节点下挂的是该字段值对应的主键值。

回表查询先到二级索引中查找数据，找到主键值，然后再到聚集索引中根据主键值，获取 数据的方式，就称之为回表查询。
当我们执行如下的SQL语句时，具体的查找过程是什么样子的。

具体过程如下:
①. 由于是根据name字段进行查询，所以先根据name&#x3D;’Arm’到name字段的二级索引中进行匹配查 找。但是在二级索引中只能查找到 Arm 对应的主键值 10。
②. 由于查询返回的数据是*，所以此时，还需要根据主键值10，到聚集索引中查找10对应的记录，最 终找到10对应的行row。
③. 最终拿到这一行的数据，直接返回即可。
思考题
以下两条SQL语句，那个执行效率高? 为什么?

​	A. select * from user where id &#x3D; 10 ;​	B. select * from user where name &#x3D; ‘Arm’ ; 备注: id为主键，name字段创建的有索引；
解答： A 语句的执行性能要高于B 语句。 因为A语句直接走聚集索引，直接返回数据。 而B语句需要先查询name字段的二级索引，然 后再查询聚集索引，也就是需要进行回表查询。

InnoDB主键索引的B+tree高度为多高呢?

假设: 一行数据大小为1k，一页中可以存储16行这样的数据。InnoDB的指针占用6个字节的空 间，主键即使为bigint，占用字节数为8。 
关键公式：每个非叶子节点的索引条目数 n 需满足：n × 主键大小 + (n + 1) × 指针大小 ≤ 页大小。

n × 8 ：n 个主键值的总字节数；
(n + 1) × 6 ：n+1 个指针的总字节数（每个节点至少有 n+1 个指针指向子节点）。
算出n约为 1170，也就是说每个非叶子节点最多存储 1170 个索引条目，对应 1171 个子节点（n+1）。

B + 树高度为 2 时的最大数据量：

树结构：非叶子节点（根节点）+ 叶子节点。
叶子节点数量：根节点的子节点数 &#x3D; 1171 个。
每个叶子节点存储数据量：16 行（由页大小决定）。
总数据量：1170 × 16 = 18,720条。可以存储 18000 多条记录。

B + 树高度为 3 时的最大数据量：

树结构：根节点 + 中间层 + 叶子层。
叶子节点数量：根节点的子节点数 &#x3D; 1171 个。
每个叶子节点存储数据量：16 行（由页大小决定）。
总数据量：1170 × 1170 × 16 = 21,902,400条。可以存储 2190w 多条记录。

索引语法
创建索引

CREATE [ UNIQUE | FULLTEXT ] INDEX index_name ON table_name (index_col_name,... ) ;


查看索引

SHOW INDEX FROM table_name ;


删除索引

DROP INDEX index_name ON table_name ;

SQL性能分析SQL执行频率MySQL 客户端连接成功后，通过 show [session|global] status 命令可以提供服务器状态信 息。通过如下指令，可以查看当前数据库的INSERT、UPDATE、DELETE、SELECT的访问频次：

– session 是查看当前会话 ; 
– global 是查询全局数据 ; 
SHOW GLOBAL STATUS LIKE ‘Com_______’

通过查询SQL的执行频次，我们就能够知道当前数据库到底是增删改为主，还是查询为主。 那假 如说是以查询为主，我们又该如何定位针对于那些查询语句进行优化呢？ 次数我们可以借助于慢查询 日志。
慢查询日志慢查询日志记录了所有执行时间超过指定参数（long_query_time，单位：秒，默认10秒）的所有 SQL语句的日志。
MySQL的慢查询日志默认没有开启，我们可以查看一下系统变量 slow_query_log。（默认是关闭的）。
show variables like &#x27;slow_query_log&#x27;;

如果要开启慢查询日志，需要在MySQL的配置文件中配置如下信息：

Windows 下通常位于 MySQL 安装目录或 C:\ProgramData\MySQL\MySQL Server X.Y。
Linux 下（&#x2F;etc&#x2F;my.cnf）。

[mysqld]# 启用慢查询日志slow_query_log = 1# 指定慢查询日志文件路径slow_query_log_file = &quot;C:/ProgramData/MySQL/MySQL Server 8.0/slow_query.log&quot;# 设置慢查询阈值（单位：秒）long_query_time = 10# 可选：记录未使用索引的查询# log_queries_not_using_indexes = 1# 可选：记录管理语句（如 OPTIMIZE TABLE）# log_slow_admin_statements = 1

重启MySQL 服务，然后，再次查看开关情况，慢查询日志就已经打开了。
测试：

执行如下SQL语句 ：
SELECT SLEEP(11);

打开慢日志文件，检查慢查询日志 ：
# Time: 2025-06-16T08:26:30.451314Z# User@Host: root[root] @ localhost [::1]  Id:     4# Query_time: 11.007434  Lock_time: 0.000000 Rows_sent: 1  Rows_examined: 0use huanyuan2;SET timestamp=1750062390;SELECT SLEEP(11);

那这样，通过慢查询日志，就可以定位出执行效率比较低的SQL，从而有针对性的进行优化。


profile详情show profiles 能够在做SQL优化时帮助我们了解时间都耗费到哪里去了。

通过have_profiling 参数，能够看到当前MySQL是否支持profile操作：
SELECT @@have_profiling ;



查看当前数据库是否打开了 profiling ：
select @@profiling;




可以看到，当前MySQL是支持 profile操作的，但是开关是关闭的。可以通过set语句在 session/global级别开启profiling：
SET profiling = 1;

profile 开关打开后，我们所执行的SQL语句，都会被MySQL记录，并记录执行时间消耗到哪儿去 了。
可以通过如下指令查看指令的执行耗时：
-- 查看每一条SQL的耗时基本情况show profiles;-- 查看指定query_id的SQL语句各个阶段的耗时情况show profile for query query_id;-- 查看指定query_id的SQL语句CPU的使用情况show profile cpu for query query_id;

explainEXPLAIN 或者 DESC命令获取 MySQL 如何执行 SELECT 语句的信息，包括在 SELECT 语句执行 过程中表如何连接和连接的顺序。
-- 直接在select语句之前加上关键字 explain / descEXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件 ;


Explain 执行计划中各个字段的含义:



字段
含义



id
select查询的序列号，表示查询中执行select子句或者是操作表的顺序 (id相同，执行顺序从上到下；id不同，值越大，越先执行)。


select_type
表示 SELECT 的类型，常见的取值有 SIMPLE（简单表，即不使用表连接 或者子查询）、PRIMARY（主查询，即外层的查询）、 UNION（UNION 中的第二个或者后面的查询语句）、 SUBQUERY（SELECT&#x2F;WHERE之后包含了子查询）等


type
表示连接类型，性能由好到差的连接类型为NULL、system、const、 eq_ref、ref、range、 index、all 。


possible_key
显示可能应用在这张表上的索引，一个或多个。


key
实际使用的索引，如果为NULL，则没有使用索引。


key_len
表示索引中使用的字节数， 该值为索引字段最大可能长度，并非实际使用长 度，在不损失精确性的前提下， 长度越短越好 。


rows
MySQL认为必须要执行查询的行数，在innodb引擎的表中，是一个估计值， 可能并不总是准确的。


filtered
表示返回结果的行数占需读取行数的百分比， filtered 的值越大越好。


索引使用优化单列索引与联合索引单列索引：即一个索引只包含单个列。
联合索引：即一个索引包含了多个列。
我们先来看看 tb_user 表中目前的索引情况:

在查询出来的索引中，既有单列索引，又有联合索引。
接下来，我们来执行一条SQL语句，看看其执行计划：

通过上述执行计划我们可以看出来，在and连接的两个字段 phone、name上都是有单列索引的，但是最终mysql只会选择一个索引，也就是说，只能走一个字段的索引，此时是会回表查询的。
接着，我们再来创建一个phone和name字段的联合索引来查询一下执行计划。
create unique index idx_user_phone_name on tb_user(phone,name);


此时，查询时，就走了联合索引，而在联合索引中包含 phone、name的信息，在叶子节点下挂的是对 应的主键id，所以查询是无需回表查询的。

在业务场景中，如果存在多个查询条件，考虑针对于查询字段建立索引时，建议建立联合索引， 而非单列索引。

.pqtslirpxbry{zoom:67%;}

前缀索引当字段类型为字符串（varchar，text，longtext等）时，有时候需要索引很长的字符串，这会让 索引变得很大，查询时，浪费大量的磁盘IO， 影响查询效率。此时可以只将字符串的一部分前缀，建立索引，这样可以大大节约索引空间，从而提高索引效率。

语法
create index idx_xxxx on table_name(column(n)) ;

前缀长度
可以根据索引的选择性来决定，而选择性是指不重复的索引值（基数）和数据表的记录总数的比值， 索引选择性越高则查询效率越高， 唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。
# 查询使用email整个字符串的索引选择比   1.0000select count(distinct email) / count(*) from tb_user;# 查询使用email 使用前缀5个字符串的索引选择比  0.9583select count(distinct substring(email,1,5)) / count(*) from tb_user ;# 查询使用email 使用前缀2个字符串的索引选择比   0.9167select count(distinct substring(email,1,2)) / count(*) from tb_user ;# 对字段email建立前缀索引，前缀长度为5  create index email_idx on tb_user(email(5));# 查看使用email前缀索引进行查询的执行结构explain select * from tb_user where email = &#x27;xiaoyu666@qq.com&#x27;; 

前缀索引的查询流程



最左前缀法则如果索引了多列（联合索引），要遵守最左前缀法则。最左前缀法则指的是查询条件必须从复合索引的最左列开始，并且不能跳过中间列。如果跳跃某一列，索引将会部分失效(后面的字段索引失效)。
🧩 四种典型使用场景分析CREATE INDEX idx_name_age_city ON users (    last_name,  -- 最左列    age,        -- 中间列    city        -- 最右列);

✅ 场景 1：完整使用索引 (最佳)SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;   AND age = 30   AND city = &#x27;New York&#x27;;

索引使用：(last_name, age, city) 三列全使用👉 查询效率最高
✅ 场景 2：使用最左连续列SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;   AND age = 30;

索引使用：(last_name, age) 两列👉 有效使用索引
✅ 场景 3：仅使用最左列SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;;

索引使用：(last_name) 单列👉 有效但非最优
❌ 场景 4：违反最左前缀（常见错误）-- 错误1：跳过最左列SELECT * FROM users WHERE age = 30;-- 错误2：缺少中间列SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;   AND city = &#x27;New York&#x27;; -- 跳过age列

索引使用：无法使用索引或仅部分使用👉 全表扫描风险
✅ 场景 5：条件编写的先后顺序以下代码索引会失效吗？
SELECT * FROM users WHERE  age = 30  AND  city = &#x27;New York&#x27;  AND  last_name = &#x27;Smith&#x27;;

答案：不会，MySQL 优化器会自动重排条件顺序：
-- 优化器重写后的等效查询SELECT * FROM users WHERE last_name = &#x27;Smith&#x27;  -- 最左列  AND age = 30            -- 第二列  AND city = &#x27;New York&#x27;;  -- 第三列


注意 ： 最左前缀法则中指的最左边的列，是指在查询时，联合索引的最左边的字段(即是 第一个字段)必须存在，与我们编写SQL时，条件编写的先后顺序无关。

索引失效情况🚫 1. 违反最左前缀法则（复合索引）-- 复合索引: (last_name, age, city)SELECT * FROM users WHERE age = 30; -- 缺少最左列SELECT * FROM users WHERE city = &#x27;New York&#x27;; -- 缺少最左列SELECT * FROM users WHERE last_name = &#x27;Smith&#x27; AND city = &#x27;New York&#x27;; -- 跳过中间列

✅ 解决方案：

调整查询条件顺序
创建新索引：CREATE INDEX idx_age_city ON users(age, city)

🚫 2. 在索引列上使用函数或计算-- 索引: created_atSELECT * FROM orders WHERE YEAR(created_at) = 2023; -- 函数操作SELECT * FROM products WHERE price * 1.1 &gt; 100; -- 计算操作

✅ 解决方案：

使用范围查询替代：
SELECT * FROM orders WHERE created_at BETWEEN &#x27;2023-01-01&#x27; AND &#x27;2023-12-31&#x27;;

预先计算存储：
ALTER TABLE products ADD COLUMN price_with_tax DECIMAL(10,2) AS (price * 1.1);CREATE INDEX idx_price_tax ON products(price_with_tax);

🚫 3. 隐式类型转换-- phone 是 VARCHAR 索引列SELECT * FROM customers WHERE phone = 13800138000; -- 数字 vs 字符串

✅ 解决方案：
SELECT * FROM customers WHERE phone = &#x27;13800138000&#x27;; -- 保持类型一致

🚫 4. 使用 OR 连接非索引列-- 只有 name 有索引SELECT * FROM users WHERE name = &#x27;John&#x27; OR email = &#x27;john@example.com&#x27;; -- email 无索引

用or分割开的条件， 如果or前的条件中的列有索引，而后面的列中没有索引，那么涉及的索引都不会 被用到。
✅ 解决方案：

创建联合索引

拆分为两个查询 UNION：
SELECT * FROM users WHERE name = &#x27;John&#x27;UNIONSELECT * FROM users WHERE email = &#x27;john@example.com&#x27;;

🚫 5. LIKE 以通配符开头如果仅仅是尾部模糊匹配，索引不会失效。如果是头部模糊匹配，索引失效。
-- 索引: emailSELECT * FROM users WHERE email LIKE &#x27;@gmail.com%&#x27;; -- 后导通配符SELECT * FROM users WHERE email LIKE &#x27;%@gmail.com&#x27;; -- 前导通配符 索引失效

🚫 6. 范围查询后的列失效联合索引中，出现范围查询(&gt;,&lt;)，范围查询右侧的列索引失效。
-- 复合索引: (category, price, rating)SELECT * FROM products WHERE category = &#x27;Electronics&#x27;   AND price &gt; 1000   AND rating &gt; 4; -- rating 无法使用索引

✅ 解决方案：

调整索引列顺序：
CREATE INDEX idx_category_rating_price ON products(category, rating, price); -- 让等值条件和高选择性范围查询优先使用索引

使用覆盖索引：
CREATE INDEX idx_cover ON products(category, price, rating, product_id);

使用 &gt;&#x3D;：
SELECT * FROM products WHERE category = &#x27;Electronics&#x27;   AND price &gt;= 1000   AND rating &gt; 4; -- 在业务允许的情况下，尽可能的使用类似于 &gt;= 或 &lt;= 这类的范围查询，而避免使用 &gt; 或 &lt; 。

🚫 7. 使用 != 或 &lt;&gt;-- 索引: statusSELECT * FROM orders WHERE status != &#x27;completed&#x27;;

✅ 解决方案：

改为范围查询：
SELECT * FROM orders WHERE status &lt; &#x27;completed&#x27; OR status &gt; &#x27;completed&#x27;;

使用特定值列表：
SELECT * FROM orders WHERE status IN (&#x27;pending&#x27;, &#x27;processing&#x27;, &#x27;cancelled&#x27;);

🚫 8. 索引列使用 IS NULL&#x2F;IS NOT NULL-- 索引: phoneSELECT * FROM customers WHERE phone IS NOT NULL; -- 可能失效

✅ 解决方案：

添加条件限制：
SELECT * FROM customers WHERE phone IS NOT NULL AND phone &gt; &#x27;&#x27;; -- 利用索引扫描

使用覆盖索引：
CREATE INDEX idx_phone_cover ON customers(phone) INCLUDE (name, email);

🚫 9. 数据分布不均导致优化器放弃索引-- 索引: status (90% 值为 &#x27;active&#x27;)SELECT * FROM products WHERE status = &#x27;active&#x27;; -- 可能全表扫描

✅ 解决方案：

强制使用索引：
SELECT * FROM products FORCE INDEX(idx_status) WHERE status = &#x27;active&#x27;;

调整优化器设置：
SET optimizer_switch=&#x27;index_condition_pushdown=off&#x27;;

🚫 10. 使用 NOT IN-- 索引: categorySELECT * FROM products WHERE category NOT IN (&#x27;Books&#x27;, &#x27;Clothing&#x27;);

✅ 解决方案：

改用 NOT EXISTS：
SELECT * FROM products pWHERE NOT EXISTS (  SELECT 1 FROM excluded_categories e   WHERE e.category = p.category);

使用左连接：
SELECT p.* FROM products pLEFT JOIN excluded_categories e ON p.category = e.categoryWHERE e.category IS NULL;

SQL提示SQL提示，是优化数据库的一个重要手段，简单来说，就是在SQL语句中加入一些人为的提示来达到优化操作的目的。

use index ： 建议MySQL使用哪一个索引完成此次查询（仅仅是建议，mysql内部还会再次进 行评估）。

   explain select * from tb_user use index(idx_user_pro) where profession = &#x27;软件工程&#x27;;


ignore index ： 忽略指定的索引。

   explain select * from tb_user ignore index(idx_user_pro) where profession = &#x27;软件工程&#x27;;


force index ： 强制使用索引。
explain select * from tb_user force index(idx_user_pro) where profession = &#x27;软件工程&#x27;;

覆盖索引尽量使用覆盖索引，减少select *。 那么什么是覆盖索引呢？ 覆盖索引是指查询使用了索引，并且需要返回的列，在该索引中已经全部能够找到 。
执行计划 EXPLAIN SELECT 字段列表 FROM 表名 WHERE 条件  查询结果中 Extra 的含义：



Extra
含义



Using where; Using Index
查找使用了索引，但是需要的数据都在索引列中能找到，所以不需要回表查询数据


Using index condition
查找使用了索引，但是需要回表查询数据


为了更清楚理解，什么是覆盖索引，什么是回表查询，我们一起再来看下面的这组SQL的执行过程。





思考题：
​	一张表, 有四个字段(id, username, password, status), 由于数据量大, 需要对以下SQL语句进行优化, 该如何进行才是最优方案?
​	select id,username,password from tb_user where username &#x3D; ‘itcast’
​	答案: 
​		针对于 username, password建立联合索引, sql为: create index idx_user_name_pass on tb_user(username,password);
​	这样可以避免上述的SQL语句，在查询的过程中，出现回表查询。

索引设计原则
针对于数据量较大，且查询比较频繁的表建立索引。
针对于常作为查询条件（where）、排序（order by）、分组（group by）操作的字段建立索引。
尽量选择区分度高的列作为索引，尽量建立唯一索引，区分度越高，使用索引的效率越高。
如果是字符串类型的字段，字段的长度较长，可以针对于字段的特点，建立前缀索引。
尽量使用联合索引，减少单列索引，查询时，联合索引很多时候可以覆盖索引，节省存储空间， 避免回表，提高查询效率。
要控制索引的数量，索引并不是多多益善，索引越多，维护索引结构的代价也就越大，会影响增 删改的效率。
如果索引列不能存储NULL值，请在创建表时使用NOT NULL约束它。当优化器知道每列是否包含 NULL值时，它可以更好地确定哪个索引最有效地用于查询。

SQL优化（后面在做）视图&#x2F;存储过程&#x2F;触发器视图视图（View）是一种虚拟存在的表。视图中的数据并不在数据库中实际存在，行和列数据来自定义视 图的查询中使用的表，并且是在使用视图时动态生成的。 通俗的讲，视图只保存了查询的SQL逻辑，不保存查询结果。所以我们在创建视图的时候，主要的工作 就落在创建这条SQL查询语句上。
基本语法
创建
CREATE [OR REPLACE] VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [CASCADED | LOCAL ] CHECK OPTION ]

查询
查看创建视图语句：SHOW CREATE VIEW 视图名称;查看视图数据：SELECT * FROM 视图名称 ...... ;

修改
方式一：CREATE [OR REPLACE] VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]方式二：ALTER VIEW 视图名称[(列名列表)] AS SELECT语句 [ WITH [ CASCADED | LOCAL ] CHECK OPTION ]

删除
DROP VIEW [IF EXISTS] 视图名称 [,视图名称] ...

检查选项当使用WITH CHECK OPTION子句创建视图时，MySQL会通过视图检查正在更改的每个行，例如插 入，更新，删除，以使其符合视图的定义。 MySQL允许基于另一个视图创建视图，它还会检查依赖视 图中的规则以保持一致性。为了确定检查的范围，mysql提供了两个选项： CASCADED 和 LOCAL ，默认值为 CASCADED 。

CASCADED 级联

   比如，v2视图是基于v1视图的，如果在v2视图创建的时候指定了检查选项为 cascaded，但是v1视图 创建时未指定检查选项。 则在执行检查时，不仅会检查v2，还会级联检查v2的关联视图v1。
   

LOCAL 本地
比如，v2视图是基于v1视图的，如果在v2视图创建的时候指定了检查选项为 local ，但是v1视图创 建时未指定检查选项。 则在执行检查时，只会检查v2，不会检查v2的关联视图v1。



视图的更新要使视图可更新，视图中的行与基础表中的行之间必须存在一对一的关系。如果视图包含以下任何一 项，则该视图不可更新：

聚合函数或窗口函数（SUM()、 MIN()、 MAX()、 COUNT()等）

DISTINCT

GROUP BY

HAVING

UNION 或者 UNION ALL



视图的作用
简单：视图不仅可以简化用户对数据的理解，也可以简化他们的操作。那些被经常使用的查询可以被定义为视图，从而使得用户不必为以后的操作每次指定全部的条件。
安全：数据库可以授权，但不能授权到数据库特定行和特定的列上。通过视图用户只能查询和修改他们所能见到的数据。
数据独立：视图可帮助用户屏蔽真实表结构变化带来的影响。

存储过程存储过程是事先经过编译并存储在数据库中的一段 SQL 语句的集合，调用存储过程可以简化应用开发 人员的很多工作，减少数据在数据库和应用服务器之间的传输，对于提高数据处理的效率是有好处的。 存储过程思想上很简单，就是数据库 SQL 语言层面的代码封装与重用。
特点
封装，复用：可以把某一业务SQL封装在存储过程中，需要用到 的时候直接调用即可。
可以接收参数，也可以返回数据：在存储过程中，可以传递参数，也可以接收返回值。
减少网络交互，效率提升：如果涉及到多条SQL，每执行一次都是一次网络传输。 而如果封装在存储过程中，我们只需要网络交互一次可能就可以了。

基本语法
创建
CREATE PROCEDURE 存储过程名称 ([ 参数列表 ])BEGIN-- SQL语句END ;

调用
CALL 名称 ([ 参数 ]);

查看
SELECT * FROM INFORMATION_SCHEMA.ROUTINES WHERE ROUTINE_SCHEMA = &#x27;xxx&#x27;; -- 查询指定数据库的存储过程及状态信息SHOW CREATE PROCEDURE 存储过程名称 ; -- 查询某个存储过程的定义

删除
1 DROP PROCEDURE [ IF EXISTS ] 存储过程名称 ；

案例

注意: 在命令行中，执行创建存储过程的SQL时，需要通过关键字 delimiter 指定SQL语句的 结束符。

-- 存储过程基本语法-- 创建create procedure p1()beginselect count(*) from student;end;-- 调用call p1();-- 查看select * from information_schema.ROUTINES where ROUTINE_SCHEMA = &#x27;itcast&#x27;;show create procedure p1;-- 删除drop procedure if exists p1;

变量在MySQL中变量分为三种类型: 系统变量、用户定义变量、局部变量。

系统变量
系统变量是MySQL服务器提供，不是用户定义的，属于服务器层面。分为全局变量（GLOBAL）、会话变量（SESSION）。

全局变量(GLOBAL): 全局变量针对于所有的会话。

会话变量(SESSION): 会话变量针对于单个会话，在另外一个会话窗口就不生效了。

如果没有指定SESSION&#x2F;GLOBAL，默认是SESSION会话变量。

mysql服务重新启动之后，所设置的全局参数会失效，要想不失效，可以在 &#x2F;etc&#x2F;my.cnf 中配置。



查看&amp;设置 系统变量
# 查看系统变量SHOW [ SESSION | GLOBAL ] VARIABLES ; -- 查看所有系统变量SHOW [ SESSION | GLOBAL ] VARIABLES LIKE &#x27;......&#x27;; -- 可以通过LIKE模糊匹配方式查找变量SELECT @@[SESSION | GLOBAL] 系统变量名; -- 查看指定变量的值# 设置系统变量SET [ SESSION | GLOBAL ] 系统变量名 = 值 ;SET @@[SESSION | GLOBAL]系统变量名 = 值 ;

用户定义变量
用户定义变量是用户根据需要自己定义的变量，用户变量不用提前声明，在用的时候直接用 “@变量 名” 使用就可以。其作用域为当前连接。

赋值，可以使用 &#x3D; ，也可以使用 :&#x3D; 。
方式一:	SET @var_name = expr [, @var_name = expr] ... ;	SET @var_name := expr [, @var_name := expr] ... ;方式一:	SELECT @var_name := expr [, @var_name := expr] ... ;	SELECT 字段名 INTO @var_name FROM 表名;

使用
SELECT @var_name ;


注意: 用户定义的变量无需对其进行声明或初始化，只不过获取到的值为NULL。


局部变量
局部变量 是根据需要定义的在局部生效的变量，访问之前，需要DECLARE声明。可用作存储过程内的局部变量和输入参数，局部变量的范围是在其内声明的BEGIN … END块。

声明
DECLARE 变量名 变量类型 [DEFAULT ... ] ;-- 变量类型就是数据库字段类型：INT、BIGINT、CHAR、VARCHAR、DATE、TIME等。

赋值
SET 变量名 = 值 ;SET 变量名 := 值 ;SELECT 字段名 INTO 变量名 FROM 表名 ... ;

使用
select 变量名;



ifif 用于做条件判断，具体的语法结构为：
IF 条件1 THEN.....ELSEIF 条件2 THEN -- 可选.....ELSE -- 可选.....END IF;# ---------------------举例：根据定义参数score，判定当前分数对应等级--------------------drop procedure if exists p3;create procedure p3()begin    declare score int default 58; #声明变量score为58，判断其分数等级    declare grade varchar(10); #用于接收等级    if score &gt;= 85 then        set grade := &#x27;优秀&#x27;;    elseif score &gt;= 60 then        set grade := &#x27;及格&#x27;;    else        set grade := &#x27;不及格&#x27;;    end if;    select grade;end;call p3; # 不及格


在if条件判断的结构中，ELSE IF 结构可以有多个，也可以没有。 ELSE结构可以有，也可以没有。

参数参数的类型，主要分为以下三种：IN、OUT、INOUT。 具体的含义如下：



类型
含义
备注



IN
该类参数作为输入，也就是需要调用时传入值
默认


OUT
该类参数作为输出，也就是该参数可以作为返回值



INOUT
既可以作为输入参数，也可以作为输出参数



用法：
CREATE PROCEDURE 存储过程名称 ([ IN/OUT/INOUT 参数名 参数类型 ])BEGIN	-- SQL语句END ;

案例
-- 案例一 根据传入参数score，判定当前分数对应的分数等级，并返回。-- score &gt;= 85分，等级为优秀。-- score &gt;= 60分 且 score &lt; 85分，等级为及格。-- score &lt; 60分，等级为不及格。DROP PROCEDURE if EXISTS p1;CREATE PROCEDURE p1(IN score INT,OUT result VARCHAR(10))BEGIN		if score &gt;= 85 THEN		SET result = &#x27;优秀&#x27;;	ELSEIF score &gt; 60 THEN		SET result := &#x27;及格&#x27;;	ELSE 		SET result = &#x27;不及格&#x27;;	END if;END;-- 定义用户变量 @result来接收返回的数据, 用户变量可以不用声明call p1(99, @result);select @result; -- 优秀-- 案例二 将传入的200分制的分数，进行换算，换算成百分制，然后返回。DROP PROCEDURE if EXISTS p2;CREATE PROCEDURE p2(INOUT score DOUBLE)BEGIN	set score := score * 0.5;END;SET @score = 60;call p2(@score);SELECT @score; -- 30

casecase结构及作用，和我们在基础篇中所讲解的流程控制函数很类似。有两种语法格式：

语法1：
-- 含义： 当case_value的值为 when_value1时，执行statement_list1，当值为 when_value2时，执行statement_list2， 否则就执行 statement_listCASE case_value	WHEN when_value1 THEN statement_list1	[ WHEN when_value2 THEN statement_list2] ...	[ ELSE statement_list ]END CASE;

语法2：
-- 含义： 当条件search_condition1成立时，执行statement_list1，当条件search_condition2成立时，执行statement_list2， 否则就执行 statement_listCASE	WHEN search_condition1 THEN statement_list1	[WHEN search_condition2 THEN statement_list2] ...	[ELSE statement_list]END CASE;

案例：
# 根据传入的月份，判定月份所属的季节（要求采用case结构）。# 1-3月份，为第一季度# 4-6月份，为第二季度# 7-9月份，为第三季度# 10-12月份，为第四季度DROP PROCEDURE if EXISTS p3;CREATE PROCEDURE p3(IN month INT)BEGIN	DECLARE season VARCHAR(10);	CASE 		WHEN month &gt;= 1 and month &lt;= 3 THEN			SET season := &#x27;第一季度&#x27;;		WHEN month &gt;= 4 and month &lt;= 6 THEN			SET season := &#x27;第二季度&#x27;;		WHEN month &gt;= 7 and month &lt;= 9 THEN			SET season := &#x27;第三季度&#x27;;		WHEN month &gt;= 10 and month &lt;= 12 THEN			SET season := &#x27;第四季度&#x27;;		ELSE			SET season := &#x27;非法参数&#x27;;	END CASE;	select concat(&#x27;您输入的月份为: &#x27;,month, &#x27;, 所属的季度为: &#x27;,season);END;call p3(10);# 您输入的月份为: 10, 所属的季度为: 第四季度


注意：如果判定条件有多个，多个条件之间，可以使用 and 或 or 进行连接。

whilewhile 循环是有条件的循环控制语句。满足条件后，再执行循环体中的SQL语句。具体语法为：
-- 先判定条件，如果条件为true，则执行逻辑，否则，不执行逻辑WHILE 条件 DO	SQL逻辑...END WHILE;

案例
# 计算从1累加到n的值，n为传入的参数值。-- A. 定义局部变量, 记录累加之后的值;-- B. 每循环一次, 就会对n进行减1 , 如果n减到0, 则退出循环DROP PROCEDURE if EXISTS p4;CREATE PROCEDURE p4(IN num INT)BEGIN	declare result INT DEFAULT 0; 	WHILE num &gt; 0 DO		set result := result + num;		set num := num - 1;	END WHILE;	SELECT result;END;call p4(10); # 55

repeatrepeat是有条件的循环控制语句, 当满足until声明的条件的时候，则退出循环 。具体语法为：
-- 先执行一次逻辑，然后判定UNTIL条件是否满足，如果满足，则退出。如果不满足，则继续下一次循环REPEAT	SQL逻辑...	UNTIL 条件END REPEAT;

案例
# 计算从1累加到n的值，n为传入的参数值。(使用repeat实现)-- A. 定义局部变量, 记录累加之后的值;-- B. 每循环一次, 就会对n进行减1 , 如果n减到0, 则退出循环DROP PROCEDURE if EXISTS p5;CREATE PROCEDURE p5(IN num INT)BEGIN	declare result INT DEFAULT 0; 	REPEAT		set result := result + num;		set num := num - 1;		UNTIL num &lt;= 0	END REPEAT;	SELECT result;END;call p5(10); # 

loopLOOP 实现简单的循环，如果不在SQL逻辑中增加退出循环的条件，可以用其来实现简单的死循环。 LOOP可以配合一下两个语句使用：

LEAVE ：配合循环使用，退出循环。
ITERATE：必须用在循环中，作用是跳过当前循环剩下的语句，直接进入下一次循环。

[begin_label:] LOOP	SQL逻辑...END LOOP [end_label];LEAVE label; -- 退出指定标记的循环体ITERATE label; -- 直接进入下一次循环-- 上述语法中出现的 begin_label，end_label，label 指的都是我们所自定义的标记。

案例
#  案例一# 计算从1累加到n的值，n为传入的参数值。-- A. 定义局部变量, 记录累加之后的值;-- B. 每循环一次, 就会对n进行-1 , 如果n减到0, 则退出循环 ----&gt; leave xxDROP PROCEDURE if EXISTS p6;CREATE PROCEDURE p6(IN num INT)BEGIN	DECLARE result INT DEFAULT 0; 	getSum: LOOP		IF num &lt;= 0 THEN			LEAVE getSum; 		END IF; 		set result := result + num;		set num := num - 1;	END LOOP getSum;	SELECT result;END;call p6(10); # 55#  案例二# 计算从1到n之间的偶数累加的值，n为传入的参数值。-- A. 定义局部变量, 记录累加之后的值;-- B. 每循环一次, 就会对n进行-1 , 如果n减到0, 则退出循环 ----&gt; leave xx-- C. 如果当次累加的数据是奇数, 则直接进入下一次循环. --------&gt; iterate xxDROP PROCEDURE if EXISTS p7;CREATE PROCEDURE p7(IN num INT)BEGIN	DECLARE result INT DEFAULT 0; 	getSum: LOOP		IF num &lt;= 0 THEN			LEAVE getSum; 		END IF; 				if num%2 = 1 then			set num := num - 1;			iterate getSum;		end if;		set result := result + num;		set num := num - 1;			END LOOP getSum;	SELECT result;END;call p7(10); # 30

游标游标（CURSOR）是用来存储查询结果集的数据类型 , 在存储过程和函数中可以使用游标对结果集进行循环的处理。游标的使用包括游标的声明、OPEN、FETCH 和 CLOSE，其语法分别如下。
# 声明游标DECLARE 游标名称 CURSOR FOR 查询语句 ;# 打开游标OPEN 游标名称 ;# 获取游标记录FETCH 游标名称 INTO 变量 [, 变量 ] ;# 关闭游标CLOSE 游标名称 ;

案例
#  根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名#（name）和专业（profession），并将用户的姓名和专业插入到所创建的一张新表# (id,name,profession)中。-- 逻辑:-- A. 声明游标, 存储查询结果集-- B. 准备: 创建表结构-- C. 开启游标-- D. 获取游标中的记录-- E. 插入数据到新表中-- F. 关闭游标DROP PROCEDURE if EXISTS p8;CREATE PROCEDURE p8(IN iage INT)BEGIN	# 有先后顺序：先声明普通变量，再声明游标	declare uname varchar(100);	declare upro varchar(100);	# 1.声明游标 存储查询结果集	DECLARE u_cursor CURSOR FOR SELECT `name`,profession FROM tb_user WHERE age &lt;= iage;	# 2.创建新表的 表结构	drop table if exists tb_user_pro;	create table if not exists tb_user_pro(		id int primary key auto_increment,		name varchar(100),		profession varchar(100)	);	# 3.开启游标	OPEN u_cursor;	# 4.获取游标中的记录	while true do		fetch u_cursor into uname,upro;		# 5.插入数据到新表中		insert into tb_user_pro values (null, uname, upro);	end while;	# 6.关闭游标	CLOSE u_cursor;END;call p8(30);

上述的存储过程，最终我们在调用的过程中，会报错，之所以报错是因为上面的while循环中，并没有 退出条件。当游标的数据集获取完毕之后，再次获取数据，就会报错，从而终止了程序的执行。

但是此时，tb_user_pro表结构及其数据都已经插入成功了，我们可以直接刷新表结构，检查表结构中的数据。上述的功能，虽然我们实现了，但是逻辑并不完善，而且程序执行完毕，获取不到数据，数据库还报 错。 接下来，我们就需要来完成这个存储过程，并且解决这个问题。 要想解决这个问题，就需要通过MySQL中提供的条件处理程序 Handler 来解决。
条件处理程序条件处理程序（Handler）可以用来定义在流程控制结构执行过程中遇到问题时相应的处理步骤。具体语法为：
DECLARE handler_action HANDLER FOR condition_value [, condition_value] ... statement ;handler_action 的取值：    CONTINUE: 继续执行当前程序    EXIT: 终止执行当前程序condition_value 的取值：    SQLSTATE sqlstate_value: 状态码，如 02000    SQLWARNING: 所有以01开头的SQLSTATE代码的简写    NOT FOUND: 所有以02开头的SQLSTATE代码的简写    SQLEXCEPTION: 所有没有被SQLWARNING 或 NOT FOUND捕获的SQLSTATE代码的简写

案例

通过SQLSTATE指定具体的状态码
# 我们继续来完成在上一小节提出的这个需求，并解决其中的问题。#  根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名#（name）和专业（profession），并将用户的姓名和专业插入到所创建的一张新表# (id,name,profession)中。-- 逻辑:-- A. 声明游标, 存储查询结果集-- B. 准备: 创建表结构-- C. 开启游标-- D. 获取游标中的记录-- E. 插入数据到新表中-- F. 关闭游标DROP PROCEDURE if EXISTS p8;CREATE PROCEDURE p8(IN iage INT)BEGIN	# 有先后顺序：先声明普通变量，再声明游标	declare uname varchar(100);	declare upro varchar(100);	# 1.声明游标 存储查询结果集	DECLARE u_cursor CURSOR FOR SELECT `name`,profession FROM tb_user WHERE age &lt;= iage;		-- 声明条件处理程序 ： 当SQL语句执行抛出的状态码为02000时，将关闭游标u_cursor，并退出	declare exit handler for SQLSTATE &#x27;02000&#x27; close u_cursor;		# 2.创建新表的 表结构	drop table if exists tb_user_pro;	create table if not exists tb_user_pro(		id int primary key auto_increment,		name varchar(100),		profession varchar(100)	);	# 3.开启游标	OPEN u_cursor;	# 4.获取游标中的记录	while true do		fetch u_cursor into uname,upro;		# 5.插入数据到新表中		insert into tb_user_pro values (null, uname, upro);	end while;	# 6.关闭游标	CLOSE u_cursor;END;call p8(30);

通过SQLSTATE的代码简写方式 NOT FOUND。02 开头的状态码，代码简写为 NOT FOUND
# 我们继续来完成在上一小节提出的这个需求，并解决其中的问题。#  根据传入的参数uage，来查询用户表tb_user中，所有的用户年龄小于等于uage的用户姓名#（name）和专业（profession），并将用户的姓名和专业插入到所创建的一张新表# (id,name,profession)中。-- 逻辑:-- A. 声明游标, 存储查询结果集-- B. 准备: 创建表结构-- C. 开启游标-- D. 获取游标中的记录-- E. 插入数据到新表中-- F. 关闭游标DROP PROCEDURE if EXISTS p8;CREATE PROCEDURE p8(IN iage INT)BEGIN	# 有先后顺序：先声明普通变量，再声明游标	declare uname varchar(100);	declare upro varchar(100);	# 1.声明游标 存储查询结果集	DECLARE u_cursor CURSOR FOR SELECT `name`,profession FROM tb_user WHERE age &lt;= iage;		-- 声明条件处理程序 ： 当SQL语句执行抛出的状态码为02开头时，将关闭游标u_cursor，并退出	declare exit handler for not found close u_cursor;		# 2.创建新表的 表结构	drop table if exists tb_user_pro;	create table if not exists tb_user_pro(		id int primary key auto_increment,		name varchar(100),		profession varchar(100)	);	# 3.开启游标	OPEN u_cursor;	# 4.获取游标中的记录	while true do		fetch u_cursor into uname,upro;		# 5.插入数据到新表中		insert into tb_user_pro values (null, uname, upro);	end while;	# 6.关闭游标	CLOSE u_cursor;END;call p8(30);


具体的错误状态码，可以参考官方文档：https://dev.mysql.com/doc/refman/8.0/en/declare-handler.htmlhttps://dev.mysql.com/doc/mysql-errors/8.0/en/server-error-reference.html

存储函数存储函数是有返回值的存储过程，存储函数的参数只能是IN类型的。具体语法如下：
CREATE FUNCTION 存储函数名称 ([ 参数列表 ])RETURNS type [characteristic ...]BEGIN    -- SQL语句    RETURN ...;END ;

characteristic说明：

DETERMINISTIC：相同的输入参数总是产生相同的结果
NO SQL ：不包含 SQL 语句
READS SQL DATA：包含读取数据的语句，但不包含写入数据的语句

案例
# 计算从1累加到n的值，n为传入的参数值。CREATE FUNCTION fun1 (n INT)RETURNS INT DETERMINISTICBEGIN    declare sum int default 0;    while n &gt; 0 do        set sum := sum + n;        set n := n - 1;    end while;    return sum;END ;select fun1(100); # 5050

触发器触发器是与表有关的数据库对象，指在insert&#x2F;update&#x2F;delete之前(BEFORE)或之后(AFTER)，触发并执行触发器中定义的SQL语句集合。触发器的这种特性可以协助应用在数据库端确保数据的完整性 , 日志记录 , 数据校验等操作 。
使用别名OLD和NEW来引用触发器中发生变化的记录内容，这与其他的数据库是相似的。现在触发器还 只支持行级触发，不支持语句级触发。



触发器类型
NEW 和 OLD



INSERT 型触发器
NEW 表示将要或者已经新增的数据


UPDATE 型触发器
OLD 表示修改之前的数据 , NEW 表示将要或已经修改后的数据


DELETE 型触发器
OLD 表示将要或者已经删除的数据


基本语法
创建
CREATE TRIGGER trigger_nameBEFORE/AFTER INSERT/UPDATE/DELETEON tbl_name FOR EACH ROW -- 行级触发器BEGIN	trigger_stmt ;END;

查看
SHOW TRIGGERS ;

删除
DROP TRIGGER [schema_name.]trigger_name ; -- 如果没有指定 schema_name，默认为当前数据库。

案例
通过触发器记录 tb_user 表的数据变更日志，将变更日志插入到日志表user_logs中, 包含增加, 修改 , 删除 。
表结构准备:
-- 准备工作 : 日志表 user_logscreate table user_logs(    id int(11) not null auto_increment,    operation varchar(20) not null comment &#x27;操作类型, insert/update/delete&#x27;,    operate_time datetime not null comment &#x27;操作时间&#x27;,    operate_id int(11) not null comment &#x27;操作的ID&#x27;,    operate_params varchar(500) comment &#x27;操作参数&#x27;,    primary key(`id`))engine=innodb default charset=utf8;


插入数据触发器
-- 创建插入触发器CREATE TRIGGER tb_user_insert_trigger AFTER INSERT ON tb_user FOR EACH ROWBEGIN		INSERT INTO user_logs ( id, operation, operate_time, operate_id, operate_params )	VALUES		(NULL,&#x27;insert&#x27;,now(),new.id,		concat(&#x27;插入的数据内容为:id=&#x27;,new.id,&#x27;name=&#x27;,new.NAME,&#x27;, phone=&#x27;,NEW.phone,&#x27;, email=&#x27;,NEW.email,&#x27;,profession=&#x27;,NEW.profession ));END;-- 查看触发器SHOW TRIGGERS;-- 插入数据到tb_userinsert into tb_user(id, name, phone, email, profession, age, gender, status,createtime) VALUES (26,&#x27;三皇子&#x27;,&#x27;18809091212&#x27;,&#x27;erhuangzi@163.com&#x27;,&#x27;软件工程&#x27;,23,&#x27;1&#x27;,&#x27;1&#x27;,now());-- 查询插入触发器SELECT * FROM user_logs;

修改数据触发器
-- 创建更新触发器CREATE TRIGGER tb_user_update_trigger AFTER UPDATE ON tb_user FOR EACH ROWBEGIN		INSERT INTO user_logs ( id, operation, operate_time, operate_id, operate_params )	VALUES		(NULL,&#x27;update&#x27;,now(),new.id,		concat(&#x27;更新前的数据内容为:id=&#x27;,old.id,&#x27;name=&#x27;,old.NAME,&#x27;, phone=&#x27;,old.phone,&#x27;, email=&#x27;,old.email,&#x27;,profession=&#x27;,old.profession,					&#x27;,更新后的数据内容为:id=&#x27;,new.id,&#x27;name=&#x27;,new.NAME,&#x27;, phone=&#x27;,new.phone,&#x27;, email=&#x27;,new.email,&#x27;,profession=&#x27;,new.profession));END;-- 查看触发器SHOW TRIGGERS;-- 更新tb_user数据update tb_user set profession = &#x27;会计&#x27; where id = 23;-- 查询更新触发器SELECT * FROM user_logs;

删除数据触发器
-- 创建删除触发器CREATE TRIGGER tb_user_delete_trigger AFTER DELETE ON tb_user FOR EACH ROWBEGIN		INSERT INTO user_logs ( id, operation, operate_time, operate_id, operate_params )	VALUES		(NULL,&#x27;delete&#x27;,now(),old.id,		concat(&#x27;删除的数据内容为:id=&#x27;,old.id,&#x27;name=&#x27;,old.NAME,&#x27;, phone=&#x27;,old.phone,&#x27;, email=&#x27;,old.email,&#x27;,profession=&#x27;,old.profession));END;-- 查看触发器SHOW TRIGGERS;-- 删除tb_user数据delete from tb_user WHERE id=26;-- 查询删除触发器SELECT * FROM user_logs;

锁锁是计算机协调多个进程或线程并发访问某一资源的机制。在数据库中，除传统的计算资源（CPU、 RAM、I&#x2F;O）的争用以外，数据也是一种供许多用户共享的资源。如何保证数据并发访问的一致性、有效性是所有数据库必须解决的一个问题，锁冲突也是影响数据库并发访问性能的一个重要因素。从这个角度来说，锁对数据库而言显得尤其重要，也更加复杂。
MySQL中的体系全景图
graph TD    A[MySQL 锁体系] --&gt; B[按粒度划分]    A --&gt; C[按功能划分]    A --&gt; D[按模式划分]        B --&gt; B1[全局锁]    B --&gt; B2[表级锁]    B --&gt; B3[行级锁]    B --&gt; B4[页级锁]        C --&gt; C1[共享锁 S]    C --&gt; C2[排他锁 X]    C --&gt; C3[意向共享锁 IS]    C --&gt; C4[意向排他锁 IX]        D --&gt; D1[悲观锁]    D --&gt; D2[乐观锁]

共享锁 (S Lock)一个事务已获取共享锁，当另一个事务尝试对具备共享锁的数据进行读操作时，可正常读；进行写操作时，会被共享锁排斥。

特性：允许多事务并发读取

兼容性：兼容其他 S 锁，排斥 X 锁

使用场景：
-- 保证读取期间数据不变SELECT * FROM table WHERE ... LOCK IN SHARE MODE;-- MySQL8.0之后也优化了写法，如下：SELECT ... FOR SHARE;

排他锁 (X Lock)当一个线程获取到独占锁后，会排斥其他线程（进行读写操作），如若其他线程也想对共享资源&#x2F;同一数据进行操作，必须等到当前线程释放锁并竞争到锁资源才行。

特性：独占资源，禁止其他操作

兼容性：排斥所有其他锁

使用场景：
SELECT * FROM table WHERE ... FOR UPTATE;

全局锁 (Global Lock)全局锁就是对整个数据库实例加锁，加锁后整个实例就处于只读状态，后续的DML的写语句，DDL语句，已经更新操作的事务提交语句都将被阻塞。
典型的使用场景是做全库的逻辑备份。

不加全局锁：进行数据备份时，对数据进行DML语句，会导致备份前后数据不一致问题。
加了全局锁：对数据库进行进行逻辑备份之前，先对整个数据库加上全局锁，一旦加了全局锁之后，其他的DDL、 DML全部都处于阻塞状态，但是可以执行DQL语句，也就是处于只读状态，而数据备份就是查询操作。 那么数据在进行逻辑备份的过程中，数据库中的数据就是不会发生变化的，这样就保证了数据的一致性和完整性。

基本语法加全局锁
flush tables with read lock;

数据备份
mysqldump -u username -p database_name &gt; backup.sql -- （备份指定数据库到 backup.sql，执行后输入密码 ）

释放全局锁
unlock tables;

特点数据库中加全局锁，是一个比较重的操作，存在以下问题：

如果在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆。
如果在从库上备份，那么在备份期间从库不能执行主库同步过来的二进制日志（binlog），会导致主从延迟。


在InnoDB引擎中，我们可以在备份时加上参数 –single-transaction 参数来完成不加锁的一致 性数据备份。
mysqldump –single-transaction -u username -p database_name &gt; backup.sql

表级锁 (Table Lock)表级锁，每次操作锁住整张表。锁定粒度大，发生锁冲突的概率最高，并发度最低。应用在MyISAM、InnoDB、BDB等存储引擎中。
使用表锁的开销相对较小，加锁快，不会产生死锁；但是加锁粒度大，发生锁冲突的概率更高，并发度更低。在innoDB存储引擎中不推荐使用表锁，只有在没有事务支持的存储引擎中才会使用，如MyISAM
对于表级锁，主要分为以下三类：

表锁
元数据锁
意向锁

表锁对于表锁，分为两类：

表共享读锁（read lock）
表独占写锁（write lock）

基本语法
加锁
lock tables 表名... read/write。

释放锁
unlock tables / 客户端断开连接 。

特点
读锁：


写锁：



结论: 读锁不会阻塞其他客户端的读，但是会阻塞写。写锁既会阻塞其他客户端的读，又会阻塞其他客户端的写。
元数据锁（meta data lock, MDL）MDL加锁过程是系统自动控制，无需显式使用，在访问一张表的时候会自动加上。MDL锁主要作用是维护表元数据的数据一致性，在表上有活动事务的时候，不可以对元数据进行写入操作。为了避免DML与 DDL冲突，保证读写的正确性。
这里的元数据，大家可以简单理解为就是一张表的表结构。 也就是说，某一张表涉及到未提交的事务时，是不能够修改这张表的表结构的。
在MySQL5.5中引入了MDL，当对一张表进行增删改查的时候，加MDL读锁(共享)；当对表结构进行变更操作的时候，加MDL写锁(排他)。
常见的SQL操作时，所添加的元数据锁：



对应SQL
锁类型
说明



lock tables xxx read &#x2F; write（表锁）
SHARED_READ_ONLY &#x2F; SHARED_NO_READ_WRITE



select 、select … lock in share mode（普通读、共享锁）
SHARED_READ（元数据共享锁）
与SHARED_READ、 SHARED_WRITE兼容，与 EXCLUSIVE互斥


insert 、update、 delete、select … for update（增、改、删、排他锁）
SHARED_WRITE（元数据共享锁）
与SHARED_READ、 SHARED_WRITE兼容，与 EXCLUSIVE互斥


alter table …（修改表结构）
EXCLUSIVE（元数据排他锁）
与其他的MDL都互斥


案例
当执行SELECT、INSERT、UPDATE、DELETE等语句时，添加的是元数据共享锁（SHARED_READ &#x2F; SHARED_WRITE），之间是兼容的。

当执行SELECT语句时，添加的是元数据共享锁（SHARED_READ），会阻塞元数据排他锁 （EXCLUSIVE），之间是互斥的。

我们可以通过下面的SQL，来查看数据库中的元数据锁的情况：
select object_type,object_schema,object_name,lock_type,lock_duration from performance_schema.metadata_locks ;

我们在操作过程中，可以通过上述的SQL语句，来查看元数据锁的加锁情况。

意向锁（Intention Lock）为了避免DML在执行时，加的行锁与表锁的冲突，在InnoDB中引入了意向锁，使得表锁不用检查每行数据是否加锁，使用意向锁来减少表锁的检查。

.skqkpsmmsjar{zoom: 75%;}
.ulmxoprpkvzp{zoom:102%;}

分类

意向共享锁（IS）：由语句select … lock in share mode添加，与表锁共享锁（read）兼容，与表锁排他锁（write）互斥。在准备给表数据添加一个S锁时，需要先获得该表的IS锁
意向排他锁（IX）：由insert、update、delete、select…for update添加 。与表锁共享锁(read)及排他锁(write)都互斥，意向锁之间不会互斥。在准备给表数据添加一个X锁时，需要先获得该表的IX锁


一旦事务提交了，意向共享锁、意向排他锁，都会自动释放。

可以通过以下SQL，查看意向锁及行锁的加锁情况：
select object_schema,object_name,index_name,lock_type,lock_mode,lock_data from performance_schema.data_locks;

案例
A.意向共享锁与表读锁是兼容的

B.意向排他锁与表读锁、写锁都是互斥的

兼容矩阵：



请求\持有
X
IX
S
IS



X（共享锁）
❌
❌
❌
❌


IX（意向排他锁）
❌
✅
❌
✅


S（排他锁）
❌
❌
✅
✅


IS（意向共享锁）
❌
✅
✅
✅


行级锁 (Row Lock)行级锁，每次操作锁住对应的行数据。锁定粒度最小，发生锁冲突的概率最低，并发度最高。应用在 InnoDB存储引擎中。InnoDB的数据是基于索引组织的，行锁是通过对索引上的索引项加锁来实现的，而不是对记录加的锁。对于行级锁，主要分为以下三类：

行锁（Record Lock）

间隙锁（Gap Lock）

临键锁（Next-Key Lock）


行锁 &#x2F; 记录锁（Record Lock）锁定单个行记录的锁，防止其他事务对此行进行update和delete。在RC、RR隔离级别下都支持。

InnoDB实现了以下两种类型的行锁：

共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排它锁。
排他锁（X）：允许获取排他锁的事务更新数据，阻止其他事务获得相同数据集的共享锁和排他锁。

两种行锁的兼容情况如下:

常见的SQL语句，在执行时，所加的行锁如下：

案例
默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。

针对唯一索引进行检索时，对已存在的记录进行等值匹配时，将会自动优化为行锁。
InnoDB的行锁是针对于索引加的锁，不通过索引条件检索数据，那么InnoDB将对表中的所有记录加锁，此时就会升级为表锁。

可以通过以下SQL，查看意向锁及行锁的加锁情况：
select object_schema,object_name,index_name,lock_type,lock_mode,lock_data from performance_schema.data_locks;

间隙锁（Gap Lock）锁定索引记录间隙（不含该记录），左右开区间，确保索引记录间隙不变，防止其他事务在这个间隙进行insert，产生幻读。在RR隔离级别下都支持。

默认情况下，InnoDB在 REPEATABLE READ事务隔离级别运行，InnoDB使用 next-key 锁进行搜索和索引扫描，以防止幻读。
加间隙锁的规则

索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁 。
索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。
索引上的范围查询(唯一索引)–会访问到不满足条件的第一个值为止。


注意：间隙锁唯一目的是防止其他事务插入间隙。间隙锁可以共存，一个事务采用的间隙锁不会阻止另一个事务在同一间隙上采用间隙锁。

临键锁（Next-Key Lock）行锁和间隙锁组合，同时锁住数据，并锁住数据前面的间隙Gap，左开右闭。 在RR隔离级别下支持。
 
案例
A. 索引上的等值查询(唯一索引)，给不存在的记录加锁时, 优化为间隙锁 

B. 索引上的等值查询(非唯一普通索引)，向右遍历时最后一个值不满足查询需求时，next-key lock 退化为间隙锁。 
分析： InnoDB的B+树索引，叶子节点是有序的双向链表。 假如，我们要根据这个二级索引查询值为18的数据，并加上共享锁，我们是只锁定18这一行就可以了吗？ 并不是，因为是非唯一索引，这个结构中可能有多个18的存在，所以，在加锁时会继续往后找，找到一个不满足条件的值（当前案例中也 就是29）。此时会对18加临键锁，并对29之前的间隙加锁。

C. 索引上的范围查询(唯一索引)–会访问到不满足条件的第一个值为止。

查询的条件为id&gt;&#x3D;19，并添加共享锁。此时我们可以根据数据库表中现有的数据，将数据分为三个部分： [19] (19,25] (25,+∞] 所以数据库数据在加锁是，就是将19加了行锁，25的临键锁（包含25及25之前的间隙），正无穷的临键锁(正无穷及之前的间隙)。
乐观锁&#x2F;悲观锁悲观锁（Pessimistic Locking）
假设冲突必然发生，因此在访问数据前先加锁，阻止其他事务同时修改。
适用场景：写操作频繁、并发冲突概率高的场景（如库存扣减、金融转账）。

实现方式：
-- 行级锁-- 共享锁（S锁）：允许多事务同时读SELECT * FROM products WHERE id = 1 LOCK IN SHARE MODE;-- 排他锁（X锁）：阻止其他事务读写SELECT * FROM products WHERE id = 1 FOR UPDATE;-- 表级锁LOCK TABLES products WRITE;  -- 写锁（排他）UNLOCK TABLES;


优点：确保数据一致性，避免脏写。
缺点：
增加锁等待时间，降低并发性能。
可能导致死锁（如事务循环等待锁）。



乐观锁（Optimistic Locking）
假设冲突很少发生，不提前加锁，而是在提交时检查数据是否被修改。
适用场景：读操作频繁、冲突概率低的场景（如商品浏览量统计）。

实现方式：

版本号（Version）：
-- 表结构增加 version 字段CREATE TABLE products (  id INT PRIMARY KEY,  stock INT,  version INT DEFAULT 0);-- 事务1：读取数据SELECT stock, version FROM products WHERE id = 1;-- 事务1：更新时校验 versionUPDATE products SET stock = stock - 1, version = version + 1 WHERE id = 1 AND version = 上次读取的version;

时间戳（Timestamp）：类似版本号，使用时间戳字段记录数据修改时间。

优点：

无需加锁，提升并发性能。
避免死锁。


缺点：

需要应用层处理冲突（如重试机制）。
不适合高冲突场景（重试频繁会降低效率）。



InnoDB引擎InnoDB的逻辑存储结构

表空间
表空间是InnoDB存储引擎逻辑结构的最高层， 如果用户启用了参数 innodb_file_per_table(在 8.0版本中默认开启) ，则每张表都会有一个表空间（xxx.ibd），一个mysql实例可以对应多个表空间，用于存储记录、索引等数据。

段
段，分为数据段（Leaf node segment）、索引段（Non-leaf node segment）、回滚段 （Rollback segment），InnoDB是索引组织表，数据段就是B+树的叶子节点， 索引段即为B+树的 非叶子节点。段用来管理多个Extent（区）。

区
区，表空间的单元结构，每个区的大小为1M。 默认情况下，InnoDB存储引擎页大小为16K， 即一 个区中一共有64个连续的页。

页
页，是InnoDB 存储引擎磁盘管理的最小单元，每个页的大小默认为 16KB。为了保证页的连续性，InnoDB 存储引擎每次从磁盘申请 4-5 个区。

行
行，InnoDB 存储引擎数据是按行进行存放的。 
在行中，默认有两个隐藏字段：

Trx_id：每次对某条记录进行改动时，都会把对应的事务id赋值给trx_id隐藏列。
Roll_pointer：每次对某条引记录进行改动时，都会把旧的版本写入到undo日志中，然后这个隐藏列就相当于一个指针，可以通过它来找到该记录修改前的信息。



架构MySQL5.5 版本开始，默认使用InnoDB存储引擎，它擅长事务处理，具有崩溃恢复特性，在日常开发中使用非常广泛。下面是InnoDB架构图，左侧为内存结构，右侧为磁盘结构。

内存结构在左侧的内存结构中，主要分为这么四大块儿： Buffer Pool、Change Buffer、Adaptive Hash Index、Log Buffer。 接下来介绍一下这四个部分。

Buffer Pool
InnoDB存储引擎基于磁盘文件存储，访问物理硬盘和在内存中进行访问，速度相差很大，为了尽可能弥补这两者之间的I&#x2F;O效率的差值，就需要把经常使用的数据加载到缓冲池中，避免每次访问都进行磁盘I&#x2F;O。
在InnoDB的缓冲池中不仅缓存了索引页和数据页，还包含了undo页、插入缓存、自适应哈希索引以及 InnoDB的锁信息等等。
缓冲池 Buffer Pool，是主内存中的一个区域，里面可以缓存磁盘上经常操作的真实数据，在执行增、删、改、查操作时，先操作缓冲池中的数据（若缓冲池没有数据，则从磁盘加载并缓存），然后再以一定频率刷新到磁盘，从而减少磁盘IO，加快处理速度。
缓冲池以Page页为单位，底层采用链表数据结构管理Page。根据状态，将Page分为三种类型：

free page：空闲page，未被使用
clean page：被使用page，数据没有被修改过
dirty page：脏页，被使用page，数据被修改过，页中数据与磁盘的数据产生了不一致


在专用服务器上，通常将多达80％的物理内存分配给缓冲池 。参数设置： show variables like ‘innodb_buffer_pool_size’;


Change Buffer
Change Buffer，更改缓冲区（针对于非唯一二级索引页），在执行DML语句时，如果这些数据Page 没有在Buffer Pool中，是不会直接操作磁盘，而是会将数据变更存在更改缓冲区 Change Buffer 中，在以后数据被读取时，再将数据合并恢复到Buffer Pool中，再将合并后的数据刷新到磁盘中。
意义：与聚集索引不同，二级索引通常是非唯一的，并且以相对随机的顺序插入二级索引。同样，删除和更新可能会影响索引树中不相邻的二级索引页，如果每一次都操作磁盘，会造成大量的磁盘IO。有了 ChangeBuffer 之后，我们可以在缓冲池中进行合并处理，减少磁盘IO。

Adaptive Hash Index


   自适应hash索引，用于优化对Buffer Pool数据的查询。MySQL的innoDB引擎中虽然没有直接支持 hash索引，但是给我们提供了一个功能就是这个自适应hash索引。hash索引在 进行等值匹配时，一般性能是要高于B+树的，因为hash索引一般只需要一次IO即可，而B+树，可能需要几次匹配，所以hash索引的效率要高，但是hash索引又不适合做范围查询、模糊匹配等。
   InnoDB存储引擎会监控对表上各索引页的查询，如果观察到在特定的条件下hash索引可以提升速度， 则建立hash索引，称之为自适应hash索引。自适应哈希索引，无需人工干预，是系统根据情况自动完成。
   参数： adaptive_hash_index


Log Buffer
日志缓冲区，用来保存要写入到磁盘中的log日志数据（redo log 、undo log）， 默认大小为 16MB，日志缓冲区的日志会定期刷新到磁盘中。如果需要更新、插入或删除许多行的事务，增加日志缓冲区的大小可以节省磁盘 I&#x2F;O。
参数

innodb_log_buffer_size：缓冲区大小
innodb_flush_log_at_trx_commit：日志刷新到磁盘时机，取值主要包含以下三个：
1：日志在每次事务提交时写入并刷新到磁盘，默认值
0: 每秒将日志写入并刷新到磁盘一次
2: 日志在每次事务提交后写入，并每秒刷新到磁盘一次





磁盘结构

System Tablespace
系统表空间是更改缓冲区的存储区域。如果表是在系统表空间而不是每个表文件或通用表空间中创建的，它也可能包含表和索引数据。(在MySQL5.x版本中还包含InnoDB数据字典、undolog等)。参数：innodb_data_file_path。系统表空间，默认的文件名叫 ibdata1。

File-Per-Table Tablespaces
如果开启了innodb_file_per_table开关 ，则每个表的文件表空间包含单个InnoDB表的数据和索 引 ，并存储在文件系统上的单个数据文件中。 开关参数：innodb_file_per_table ，该参数默认开启。我们每创建一个表，都会产生一个表空间文件（.ibd）。

General Tablespaces


   通用表空间，需要通过 CREATE TABLESPACE 语法创建通用表空间，在创建表时，可以指定该表空间。

创建表空间
CREATE TABLESPACE ts_name ADD DATAFILE &#x27;file_name&#x27; ENGINE = engine_name;

创建表时指定表空间
CREATE TABLE xxx ... TABLESPACE ts_name;


Undo Tablespaces
撤销表空间，MySQL实例在初始化时会自动创建两个默认的undo表空间（初始大小16M），用于存储 undo log日志。

Temporary Tablespaces
InnoDB 使用会话临时表空间和全局临时表空间。存储用户创建的临时表等数据。

Doublewrite Buffer Files
双写缓冲区，innoDB引擎将数据页从Buffer Pool刷新到磁盘前，先将数据页写入双写缓冲区文件 中，便于系统异常时恢复数据。


Redo Log
重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都会存到该日志中, 用于在刷新脏页到磁盘时,发生错误时, 进行数据恢复使用。以循环方式写入重做日志文件，涉及两个文件：



后台线程在Innodb存储引擎中，后台线程的主要作用是负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据。此外它会将已经修改的数据文件刷新到磁盘文件中，保证在不发生异常的情况下，Innodb能够恢复到正常的运行状态。
.iqpnypkusoxs{zoom:80%;}

Master Thread核心后台线程，负责调度其他线程，还负责将缓冲池中的数据异步刷新到磁盘中, 保持数据的一致性， 还包括脏页的刷新、合并插入缓存、undo页的回收 。
IO Thread在InnoDB存储引擎中大量使用了AIO来处理IO请求, 这样可以极大地提高数据库的性能，而IO Thread主要负责这些IO请求的回调。



线程类型
默认个数
职责



Read thread
4
负责读操作


Write thread
4
负责写操作


Log thread
1
负责将日志缓冲区刷新到磁盘


Insert buffer thread
1
负责将写缓冲区内容刷新到磁盘


我们可以通过以下的这条指令，查看到InnoDB的状态信息，其中就包含IO Thread信息。
show engine innodb status \G;


Purge Thread主要用于回收事务已经提交了的undo log，在事务提交之后，undo log可能不用了，就用它来回收。
Page Cleaner Thread协助 Master Thread 刷新脏页到磁盘的线程，它可以减轻 Master Thread 的工作压力，减少阻塞。
事务原理事务：是一组操作的集合，它是一个不可分割的工作单位，事务会把所有的操作作为一个整体一起向系统提交或撤销操作请求，即这些操作要么同时成功，要么同时失败。
事务特性：

原子性（Atomicity）：事务是不可分割的最小操作单元，要么全部成功，要么全部失败。 
一致性（Consistency）：事务完成时，必须使所有的数据都保持一致状态。
隔离性（Isolation）：数据库系统提供的隔离机制，保证事务在不受外部并发操作影响的独立环境下运行。
持久性（Durability）：事务一旦提交或回滚，它对数据库中的数据的改变就是永久的。



redo log重做日志，记录的是事务提交时数据页的物理修改，是用来实现事务的持久性。
该日志文件由两部分组成：重做日志缓冲（redo log buffer）以及重做日志文件（redo log file）,前者是在内存中，后者在磁盘中。当事务提交之后会把所有修改信息都存到该日志文件中,用于在刷新脏页到磁盘,发生错误时,进行数据恢复使用。

没有redo log，可能会存在什么问题

在InnoDB引擎中的内存结构中，主要的内存区域就是缓冲池，在缓冲池中缓存了很多的数据页。 

当我们在一个事务中，执行多个增删改的操作时，InnoDB引擎会先操作缓冲池中的数据，如果缓冲区没有对应的数据，会通过后台线程将磁盘中的数据加载出来，存放在缓冲区中。

然后将缓冲池中的数据修改，修改后的数据页我们称为脏页。

脏页会在一定的时机，通过后台线程将缓冲区的数据刷新到磁盘中，从而保证缓冲区与磁盘的数据一致。 

但是缓冲区的脏页数据并不是实时刷新的，而是一段时间之后将缓冲区的数据刷新到磁盘中，假如刷新到磁盘的过程出错了，而提示给用户事务提交成功，而数据却没有持久化下来，这就出现问题了，没有保证事务的持久性。




InnoDB中提供了一份日志 redo log

有了redolog之后，当对缓冲区的数据进行增删改之后，会首先将操作的数据页的变化，记录在redo log buffer中。

在事务提交时，会将redo log buffer中的数据刷新到redo log磁盘文件中。

过一段时间之后，如果刷新缓冲区的脏页到磁盘时，发生错误，此时就可以借助于redo log进行数据恢复，这样就保证了事务的持久性。

而如果脏页成功刷新到磁盘或者涉及到的数据已经落盘，此时redolog就没有作用了，就可以删除了，所以存在的两个redolog文件是循环写的。

为什么每一次提交事务，要刷新redo log 到磁盘中呢，而不是直接将buffer pool中的脏页刷新到磁盘呢 ?
因为在业务操作中，我们操作数据一般都是随机读写磁盘的，而不是顺序读写磁盘。 而redo log在往磁盘文件中写入数据时，由于是日志文件，所以都是顺序写的。顺序写的效率，要远大于随机写。 这种先写日志的方式，称之为 WAL（Write-Ahead Logging）。






undo log回滚日志，用于记录数据被修改前的信息 , 作用包含两个 : 提供回滚(保证事务的原子性) 和 MVCC(多版本并发控制) 。
undo log和redo log记录物理日志不一样，它是逻辑日志。可以认为当delete一条记录时，undo log中会记录一条对应的insert记录，反之亦然，当update一条记录时，它记录一条对应相反的 update记录。当执行rollback时，就可以从undo log中的逻辑记录读取到相应的内容并进行回滚。

Undo log存储：undo log采用段的方式进行管理和记录，存放在前面介绍的 rollback segment 回滚段中，内部包含1024个undo log segment。
Undo log销毁：undo log在事务执行时产生，事务提交时，并不会立即删除undo log，因为这些日志可能还用于MVCC。

MVCC基本概念
当前读
读取的是记录的最新版本，读取时还要保证其他并发事务不能修改当前记录，会对读取的记录进行加锁。对于我们日常的操作，如：select … lock in share mode(共享锁)，select … for update、update、insert、delete(排他锁)都是一种当前读。
案例


上面案例中当前隔离级别是RC（可重复读）中，同时开启两个事务。在事务A中，使用普通select 查询语句无法查询事务B中修改的数据。
但是在查询语句后面加上了 lock in share mode 共享锁，此时是当前读操作。当然，我们加排他锁的时候，也是当前读操作。可以读取到事务B最新提交的内容。


快照读
简单的select（不加锁）就是快照读，快照读，读取的是记录数据的可见版本，有可能是历史数据，不加锁，是非阻塞读。

Read Committed 读已提交：每次select，都生成一个快照读
Repeatable Read 可重复高读：开启事务后第一个select语句才是快照读的地方。即第一次select查询产生快照读，后面的select查询直接使用前面的快照数据
Serializable 串行化：快照读会退化为当前读，每次读取都需要加锁

案例

在测试中,我们看到即使事务B提交了数据,事务A中也查询不到。原因就是因为普通的select是快照读，而在当前默认的RR隔离级别下，开启事务后第一个select语句才是快照读的地方，后面执行相同的select语句都是从快照中获取数据，可能不是当前的最新数据，这样也就保证了可重复读。

MVCC


   全称 Multi-Version Concurrency Control，多版本并发控制。指维护一个数据的多个版本， 使得读写操作没有冲突，快照读为MySQL实现MVCC提供了一个非阻塞读功能。MVCC的具体实现，还需要依赖于数据库记录中的三个隐式字段、undo log日志、readView。
隐藏字段当我们创建表的时候，除了我们自己定义的字段以为，InnoDB还会自动的给我们添加三个隐藏字段。


 前两个字段是肯定会添加的，是否添加最后一个字段DB_ROW_ID，得看当前表有没有主键，如果有主键，则不会添加该隐藏字段。

undo log
回滚日志，在insert、update、delete的时候产生的便于数据回滚的日志。
当insert的时候，产生的undo log日志只在回滚时需要，在事务提交后，可被立即删除。
而update、delete的时候，产生的undo log日志不仅在回滚时需要，在快照读时也需要，不会立即被删除。

undo log 版本链
演示：如果四个事务需要同时访问同一条记录时。


DB_TRX_ID : 代表最近修改事务ID，记录插入这条记录或最后一次修改该记录的事务ID，是自增的。 DB_ROLL_PTR ： 由于这条数据是才插入的，没有被更新过，所以该字段值为null。



不同事务或相同事务对同一条记录进行修改，会导致该记录的undolog生成一条 记录版本链表，链表的头部是最新的旧记录，链表尾部是最早的旧记录。

readviewReadView（读视图）是 快照读 SQL执行时MVCC提取数据的依据，记录并维护系统当前活跃的事务（未提交的）id。


不同的隔离级别，生成ReadView的时机不同： 

READ COMMITTED：在事务中每一次执行快照读时生成ReadView。 
REPEATABLE READ：仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。

原理分析
RC隔离级别
RC隔离级别下，在事务中每一次执行快照读时生成ReadView。

分析：

将左下记录根据 DB_TRX_ID （当前事务id  为4）带入右下版本链规则 ①②③④ 中，发现都不成立。说明本次快照读查找的数据不是事务id为4的记录。
按照版本链往下找（根据表尾地址查找）下一条记录，找到事务id为3的记录，在 ①②③④ 都不成立，继续向下寻找。
找到一条事务id为2的记录，发现②成立。说明本次快照读查找的数据&#x3D;是事务id为2的记录。


RR隔离级别
RR隔离级别下，仅在事务中第一次执行快照读时生成ReadView，后续复用该ReadView。 而RR 是可重复读，在一个事务中，执行两次相同的select语句，查询到的结果是一样的。

在RR隔离级别下，只是在事务中第一次快照读时生成ReadView，后续都是复用该 ReadView，那么既然ReadView都一样， ReadView的版本链匹配规则也一样， 那么最终快照读返回的结果也是一样的。


结论：MVCC的实现原理就是通过 InnoDB表的隐藏字段、UndoLog 版本链、ReadView来实现的。 而MVCC + 锁，则实现了事务的隔离性。 而一致性则是由redolog 与 undolog保证。

]]></content>
      <categories>
        <category>MySql</category>
        <category>MySql进阶</category>
      </categories>
      <tags>
        <tag>MySql进阶 学习笔记</tag>
      </tags>
  </entry>
</search>
